{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ7hTF-JAiwV"
      },
      "source": [
        "# **PROJECT 2: MLPs, CNNs, and Keras**\n",
        "# Spring 2022\n",
        "---\n",
        "\n",
        "Group 1:\n",
        "\n",
        "Justin Drouin\n",
        "\n",
        "Cesar Martinez Melgoza\n",
        "\n",
        "Michael Nguyen\n",
        "\n",
        "Cody Shook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-6WRJwcLcOm"
      },
      "source": [
        "# **===== PART 1 =====**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idc7TjaiApNr"
      },
      "source": [
        "**1.   As with Project 1, convert the images in TRAINING_SET, TEST_SET, and MESSAGE into two-dimensional NumPy arrays of size (# examples Ã— # features).**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUghOtwA0gcs"
      },
      "outputs": [],
      "source": [
        "from dataset import *\n",
        "seed = 1\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def convertimages(dataset):\n",
        "  imageArray = []\n",
        "  for num in range(0, len(dataset)):\n",
        "    imageArray.append(dataset[num][1])\n",
        "  numpyArray = np.array(imageArray, dtype = np.float32)\n",
        "  return numpyArray\n",
        "\n",
        "train_set = convertimages(TRAINING_SET)\n",
        "test_set = convertimages(TEST_SET)\n",
        "msg_set = np.array(MESSAGE, dtype = np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aI95ETEA6DQ"
      },
      "source": [
        "**2.   Rather than training 26 different perceptrons as you did in Project 1, this time you will use a single network with 26 possible outputs.\n",
        "In order to use the character labels in TRAINING_SET and TEST_SET, convert them into integer class vectors using ord(), then into 26 one-hot encoded categorical features.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IMDFaS83lPw"
      },
      "outputs": [],
      "source": [
        "ord_charset = []\n",
        "for num in range(0, 52):\n",
        "  ord_charset.append(ord(TRAINING_SET[num][0]))\n",
        "one_hot = tf.keras.utils.to_categorical(ord_charset, max(ord_charset) + 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxi2N3Q0BMuo"
      },
      "source": [
        "\n",
        "\n",
        "**3.   Create a Sequential Keras model with a Dense hidden layer and a Dense output layer with softmax activation and categorical cross-entropy loss.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXiS299T_kWz",
        "outputId": "0153c8aa-1468-4024-fdf3-20093127bef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 91)                23387     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 91)                8372      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,759\n",
            "Trainable params: 31,759\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(91, input_shape = (256,), activation = 'relu'))\n",
        "model.add(Dense(91, activation = 'softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LQU7fiEBTeh"
      },
      "source": [
        "**4. Compile and fit the model to the training set. Train the model until the accuracy is as high as possible. You may wish to use an EarlyStopping callback.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a_fTlnzBM5V",
        "outputId": "ff7a069e-43c9-405a-e206-cfa5fccdf191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 - 0s - loss: 4.6760 - accuracy: 0.0385 - 433ms/epoch - 433ms/step\n",
            "Epoch 2/1000\n",
            "1/1 - 0s - loss: 4.6620 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 3/1000\n",
            "1/1 - 0s - loss: 4.6482 - accuracy: 0.0385 - 7ms/epoch - 7ms/step\n",
            "Epoch 4/1000\n",
            "1/1 - 0s - loss: 4.6345 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 5/1000\n",
            "1/1 - 0s - loss: 4.6208 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 6/1000\n",
            "1/1 - 0s - loss: 4.6074 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 7/1000\n",
            "1/1 - 0s - loss: 4.5940 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 8/1000\n",
            "1/1 - 0s - loss: 4.5808 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 9/1000\n",
            "1/1 - 0s - loss: 4.5676 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 10/1000\n",
            "1/1 - 0s - loss: 4.5546 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 11/1000\n",
            "1/1 - 0s - loss: 4.5416 - accuracy: 0.0385 - 7ms/epoch - 7ms/step\n",
            "Epoch 12/1000\n",
            "1/1 - 0s - loss: 4.5288 - accuracy: 0.0385 - 10ms/epoch - 10ms/step\n",
            "Epoch 13/1000\n",
            "1/1 - 0s - loss: 4.5161 - accuracy: 0.0385 - 7ms/epoch - 7ms/step\n",
            "Epoch 14/1000\n",
            "1/1 - 0s - loss: 4.5035 - accuracy: 0.0385 - 9ms/epoch - 9ms/step\n",
            "Epoch 15/1000\n",
            "1/1 - 0s - loss: 4.4910 - accuracy: 0.0385 - 9ms/epoch - 9ms/step\n",
            "Epoch 16/1000\n",
            "1/1 - 0s - loss: 4.4785 - accuracy: 0.0385 - 7ms/epoch - 7ms/step\n",
            "Epoch 17/1000\n",
            "1/1 - 0s - loss: 4.4661 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 18/1000\n",
            "1/1 - 0s - loss: 4.4537 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 19/1000\n",
            "1/1 - 0s - loss: 4.4414 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 20/1000\n",
            "1/1 - 0s - loss: 4.4291 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 21/1000\n",
            "1/1 - 0s - loss: 4.4169 - accuracy: 0.0385 - 7ms/epoch - 7ms/step\n",
            "Epoch 22/1000\n",
            "1/1 - 0s - loss: 4.4049 - accuracy: 0.0385 - 7ms/epoch - 7ms/step\n",
            "Epoch 23/1000\n",
            "1/1 - 0s - loss: 4.3929 - accuracy: 0.0385 - 7ms/epoch - 7ms/step\n",
            "Epoch 24/1000\n",
            "1/1 - 0s - loss: 4.3810 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 25/1000\n",
            "1/1 - 0s - loss: 4.3691 - accuracy: 0.0385 - 7ms/epoch - 7ms/step\n",
            "Epoch 26/1000\n",
            "1/1 - 0s - loss: 4.3572 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 27/1000\n",
            "1/1 - 0s - loss: 4.3453 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 28/1000\n",
            "1/1 - 0s - loss: 4.3334 - accuracy: 0.0192 - 7ms/epoch - 7ms/step\n",
            "Epoch 29/1000\n",
            "1/1 - 0s - loss: 4.3217 - accuracy: 0.0192 - 7ms/epoch - 7ms/step\n",
            "Epoch 30/1000\n",
            "1/1 - 0s - loss: 4.3101 - accuracy: 0.0192 - 8ms/epoch - 8ms/step\n",
            "Epoch 31/1000\n",
            "1/1 - 0s - loss: 4.2984 - accuracy: 0.0192 - 7ms/epoch - 7ms/step\n",
            "Epoch 32/1000\n",
            "1/1 - 0s - loss: 4.2868 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 33/1000\n",
            "1/1 - 0s - loss: 4.2752 - accuracy: 0.0577 - 8ms/epoch - 8ms/step\n",
            "Epoch 34/1000\n",
            "1/1 - 0s - loss: 4.2635 - accuracy: 0.0769 - 8ms/epoch - 8ms/step\n",
            "Epoch 35/1000\n",
            "1/1 - 0s - loss: 4.2520 - accuracy: 0.0769 - 8ms/epoch - 8ms/step\n",
            "Epoch 36/1000\n",
            "1/1 - 0s - loss: 4.2403 - accuracy: 0.0769 - 8ms/epoch - 8ms/step\n",
            "Epoch 37/1000\n",
            "1/1 - 0s - loss: 4.2287 - accuracy: 0.0769 - 7ms/epoch - 7ms/step\n",
            "Epoch 38/1000\n",
            "1/1 - 0s - loss: 4.2171 - accuracy: 0.0769 - 10ms/epoch - 10ms/step\n",
            "Epoch 39/1000\n",
            "1/1 - 0s - loss: 4.2055 - accuracy: 0.0769 - 7ms/epoch - 7ms/step\n",
            "Epoch 40/1000\n",
            "1/1 - 0s - loss: 4.1940 - accuracy: 0.0769 - 7ms/epoch - 7ms/step\n",
            "Epoch 41/1000\n",
            "1/1 - 0s - loss: 4.1826 - accuracy: 0.0769 - 7ms/epoch - 7ms/step\n",
            "Epoch 42/1000\n",
            "1/1 - 0s - loss: 4.1711 - accuracy: 0.0962 - 7ms/epoch - 7ms/step\n",
            "Epoch 43/1000\n",
            "1/1 - 0s - loss: 4.1597 - accuracy: 0.0962 - 9ms/epoch - 9ms/step\n",
            "Epoch 44/1000\n",
            "1/1 - 0s - loss: 4.1482 - accuracy: 0.0962 - 8ms/epoch - 8ms/step\n",
            "Epoch 45/1000\n",
            "1/1 - 0s - loss: 4.1367 - accuracy: 0.0962 - 7ms/epoch - 7ms/step\n",
            "Epoch 46/1000\n",
            "1/1 - 0s - loss: 4.1252 - accuracy: 0.0962 - 11ms/epoch - 11ms/step\n",
            "Epoch 47/1000\n",
            "1/1 - 0s - loss: 4.1137 - accuracy: 0.0962 - 10ms/epoch - 10ms/step\n",
            "Epoch 48/1000\n",
            "1/1 - 0s - loss: 4.1023 - accuracy: 0.1154 - 7ms/epoch - 7ms/step\n",
            "Epoch 49/1000\n",
            "1/1 - 0s - loss: 4.0909 - accuracy: 0.1346 - 10ms/epoch - 10ms/step\n",
            "Epoch 50/1000\n",
            "1/1 - 0s - loss: 4.0794 - accuracy: 0.1346 - 8ms/epoch - 8ms/step\n",
            "Epoch 51/1000\n",
            "1/1 - 0s - loss: 4.0679 - accuracy: 0.1346 - 7ms/epoch - 7ms/step\n",
            "Epoch 52/1000\n",
            "1/1 - 0s - loss: 4.0564 - accuracy: 0.1346 - 7ms/epoch - 7ms/step\n",
            "Epoch 53/1000\n",
            "1/1 - 0s - loss: 4.0448 - accuracy: 0.1346 - 10ms/epoch - 10ms/step\n",
            "Epoch 54/1000\n",
            "1/1 - 0s - loss: 4.0333 - accuracy: 0.1346 - 9ms/epoch - 9ms/step\n",
            "Epoch 55/1000\n",
            "1/1 - 0s - loss: 4.0217 - accuracy: 0.1346 - 8ms/epoch - 8ms/step\n",
            "Epoch 56/1000\n",
            "1/1 - 0s - loss: 4.0101 - accuracy: 0.1731 - 9ms/epoch - 9ms/step\n",
            "Epoch 57/1000\n",
            "1/1 - 0s - loss: 3.9986 - accuracy: 0.1731 - 6ms/epoch - 6ms/step\n",
            "Epoch 58/1000\n",
            "1/1 - 0s - loss: 3.9870 - accuracy: 0.1731 - 6ms/epoch - 6ms/step\n",
            "Epoch 59/1000\n",
            "1/1 - 0s - loss: 3.9755 - accuracy: 0.1731 - 8ms/epoch - 8ms/step\n",
            "Epoch 60/1000\n",
            "1/1 - 0s - loss: 3.9639 - accuracy: 0.1731 - 7ms/epoch - 7ms/step\n",
            "Epoch 61/1000\n",
            "1/1 - 0s - loss: 3.9524 - accuracy: 0.1731 - 7ms/epoch - 7ms/step\n",
            "Epoch 62/1000\n",
            "1/1 - 0s - loss: 3.9409 - accuracy: 0.1731 - 7ms/epoch - 7ms/step\n",
            "Epoch 63/1000\n",
            "1/1 - 0s - loss: 3.9294 - accuracy: 0.1731 - 6ms/epoch - 6ms/step\n",
            "Epoch 64/1000\n",
            "1/1 - 0s - loss: 3.9178 - accuracy: 0.1731 - 7ms/epoch - 7ms/step\n",
            "Epoch 65/1000\n",
            "1/1 - 0s - loss: 3.9063 - accuracy: 0.1923 - 6ms/epoch - 6ms/step\n",
            "Epoch 66/1000\n",
            "1/1 - 0s - loss: 3.8947 - accuracy: 0.1923 - 7ms/epoch - 7ms/step\n",
            "Epoch 67/1000\n",
            "1/1 - 0s - loss: 3.8831 - accuracy: 0.1923 - 7ms/epoch - 7ms/step\n",
            "Epoch 68/1000\n",
            "1/1 - 0s - loss: 3.8715 - accuracy: 0.1923 - 6ms/epoch - 6ms/step\n",
            "Epoch 69/1000\n",
            "1/1 - 0s - loss: 3.8599 - accuracy: 0.1923 - 8ms/epoch - 8ms/step\n",
            "Epoch 70/1000\n",
            "1/1 - 0s - loss: 3.8482 - accuracy: 0.1923 - 7ms/epoch - 7ms/step\n",
            "Epoch 71/1000\n",
            "1/1 - 0s - loss: 3.8364 - accuracy: 0.1923 - 13ms/epoch - 13ms/step\n",
            "Epoch 72/1000\n",
            "1/1 - 0s - loss: 3.8246 - accuracy: 0.1923 - 8ms/epoch - 8ms/step\n",
            "Epoch 73/1000\n",
            "1/1 - 0s - loss: 3.8128 - accuracy: 0.1923 - 8ms/epoch - 8ms/step\n",
            "Epoch 74/1000\n",
            "1/1 - 0s - loss: 3.8009 - accuracy: 0.1923 - 8ms/epoch - 8ms/step\n",
            "Epoch 75/1000\n",
            "1/1 - 0s - loss: 3.7890 - accuracy: 0.2115 - 7ms/epoch - 7ms/step\n",
            "Epoch 76/1000\n",
            "1/1 - 0s - loss: 3.7770 - accuracy: 0.2115 - 7ms/epoch - 7ms/step\n",
            "Epoch 77/1000\n",
            "1/1 - 0s - loss: 3.7649 - accuracy: 0.2115 - 8ms/epoch - 8ms/step\n",
            "Epoch 78/1000\n",
            "1/1 - 0s - loss: 3.7528 - accuracy: 0.2115 - 8ms/epoch - 8ms/step\n",
            "Epoch 79/1000\n",
            "1/1 - 0s - loss: 3.7407 - accuracy: 0.2115 - 7ms/epoch - 7ms/step\n",
            "Epoch 80/1000\n",
            "1/1 - 0s - loss: 3.7284 - accuracy: 0.2115 - 7ms/epoch - 7ms/step\n",
            "Epoch 81/1000\n",
            "1/1 - 0s - loss: 3.7161 - accuracy: 0.2115 - 6ms/epoch - 6ms/step\n",
            "Epoch 82/1000\n",
            "1/1 - 0s - loss: 3.7038 - accuracy: 0.2308 - 6ms/epoch - 6ms/step\n",
            "Epoch 83/1000\n",
            "1/1 - 0s - loss: 3.6915 - accuracy: 0.2308 - 7ms/epoch - 7ms/step\n",
            "Epoch 84/1000\n",
            "1/1 - 0s - loss: 3.6792 - accuracy: 0.2308 - 14ms/epoch - 14ms/step\n",
            "Epoch 85/1000\n",
            "1/1 - 0s - loss: 3.6668 - accuracy: 0.2308 - 12ms/epoch - 12ms/step\n",
            "Epoch 86/1000\n",
            "1/1 - 0s - loss: 3.6543 - accuracy: 0.2308 - 7ms/epoch - 7ms/step\n",
            "Epoch 87/1000\n",
            "1/1 - 0s - loss: 3.6418 - accuracy: 0.2308 - 8ms/epoch - 8ms/step\n",
            "Epoch 88/1000\n",
            "1/1 - 0s - loss: 3.6293 - accuracy: 0.2308 - 7ms/epoch - 7ms/step\n",
            "Epoch 89/1000\n",
            "1/1 - 0s - loss: 3.6167 - accuracy: 0.2500 - 7ms/epoch - 7ms/step\n",
            "Epoch 90/1000\n",
            "1/1 - 0s - loss: 3.6040 - accuracy: 0.2500 - 7ms/epoch - 7ms/step\n",
            "Epoch 91/1000\n",
            "1/1 - 0s - loss: 3.5914 - accuracy: 0.2500 - 6ms/epoch - 6ms/step\n",
            "Epoch 92/1000\n",
            "1/1 - 0s - loss: 3.5787 - accuracy: 0.2500 - 7ms/epoch - 7ms/step\n",
            "Epoch 93/1000\n",
            "1/1 - 0s - loss: 3.5660 - accuracy: 0.2500 - 7ms/epoch - 7ms/step\n",
            "Epoch 94/1000\n",
            "1/1 - 0s - loss: 3.5534 - accuracy: 0.2692 - 7ms/epoch - 7ms/step\n",
            "Epoch 95/1000\n",
            "1/1 - 0s - loss: 3.5407 - accuracy: 0.2692 - 8ms/epoch - 8ms/step\n",
            "Epoch 96/1000\n",
            "1/1 - 0s - loss: 3.5279 - accuracy: 0.2692 - 8ms/epoch - 8ms/step\n",
            "Epoch 97/1000\n",
            "1/1 - 0s - loss: 3.5151 - accuracy: 0.2692 - 8ms/epoch - 8ms/step\n",
            "Epoch 98/1000\n",
            "1/1 - 0s - loss: 3.5023 - accuracy: 0.2885 - 6ms/epoch - 6ms/step\n",
            "Epoch 99/1000\n",
            "1/1 - 0s - loss: 3.4893 - accuracy: 0.2885 - 7ms/epoch - 7ms/step\n",
            "Epoch 100/1000\n",
            "1/1 - 0s - loss: 3.4764 - accuracy: 0.2885 - 6ms/epoch - 6ms/step\n",
            "Epoch 101/1000\n",
            "1/1 - 0s - loss: 3.4634 - accuracy: 0.2885 - 8ms/epoch - 8ms/step\n",
            "Epoch 102/1000\n",
            "1/1 - 0s - loss: 3.4504 - accuracy: 0.2885 - 9ms/epoch - 9ms/step\n",
            "Epoch 103/1000\n",
            "1/1 - 0s - loss: 3.4374 - accuracy: 0.2885 - 7ms/epoch - 7ms/step\n",
            "Epoch 104/1000\n",
            "1/1 - 0s - loss: 3.4244 - accuracy: 0.2885 - 10ms/epoch - 10ms/step\n",
            "Epoch 105/1000\n",
            "1/1 - 0s - loss: 3.4115 - accuracy: 0.3077 - 8ms/epoch - 8ms/step\n",
            "Epoch 106/1000\n",
            "1/1 - 0s - loss: 3.3986 - accuracy: 0.3269 - 6ms/epoch - 6ms/step\n",
            "Epoch 107/1000\n",
            "1/1 - 0s - loss: 3.3857 - accuracy: 0.3269 - 6ms/epoch - 6ms/step\n",
            "Epoch 108/1000\n",
            "1/1 - 0s - loss: 3.3727 - accuracy: 0.3269 - 7ms/epoch - 7ms/step\n",
            "Epoch 109/1000\n",
            "1/1 - 0s - loss: 3.3598 - accuracy: 0.3269 - 9ms/epoch - 9ms/step\n",
            "Epoch 110/1000\n",
            "1/1 - 0s - loss: 3.3468 - accuracy: 0.3269 - 7ms/epoch - 7ms/step\n",
            "Epoch 111/1000\n",
            "1/1 - 0s - loss: 3.3338 - accuracy: 0.3269 - 7ms/epoch - 7ms/step\n",
            "Epoch 112/1000\n",
            "1/1 - 0s - loss: 3.3208 - accuracy: 0.3269 - 7ms/epoch - 7ms/step\n",
            "Epoch 113/1000\n",
            "1/1 - 0s - loss: 3.3077 - accuracy: 0.3269 - 9ms/epoch - 9ms/step\n",
            "Epoch 114/1000\n",
            "1/1 - 0s - loss: 3.2946 - accuracy: 0.3654 - 7ms/epoch - 7ms/step\n",
            "Epoch 115/1000\n",
            "1/1 - 0s - loss: 3.2815 - accuracy: 0.3654 - 6ms/epoch - 6ms/step\n",
            "Epoch 116/1000\n",
            "1/1 - 0s - loss: 3.2684 - accuracy: 0.3654 - 7ms/epoch - 7ms/step\n",
            "Epoch 117/1000\n",
            "1/1 - 0s - loss: 3.2552 - accuracy: 0.3654 - 6ms/epoch - 6ms/step\n",
            "Epoch 118/1000\n",
            "1/1 - 0s - loss: 3.2420 - accuracy: 0.3654 - 6ms/epoch - 6ms/step\n",
            "Epoch 119/1000\n",
            "1/1 - 0s - loss: 3.2288 - accuracy: 0.3654 - 7ms/epoch - 7ms/step\n",
            "Epoch 120/1000\n",
            "1/1 - 0s - loss: 3.2155 - accuracy: 0.3654 - 7ms/epoch - 7ms/step\n",
            "Epoch 121/1000\n",
            "1/1 - 0s - loss: 3.2023 - accuracy: 0.3654 - 7ms/epoch - 7ms/step\n",
            "Epoch 122/1000\n",
            "1/1 - 0s - loss: 3.1890 - accuracy: 0.3654 - 7ms/epoch - 7ms/step\n",
            "Epoch 123/1000\n",
            "1/1 - 0s - loss: 3.1758 - accuracy: 0.3654 - 8ms/epoch - 8ms/step\n",
            "Epoch 124/1000\n",
            "1/1 - 0s - loss: 3.1627 - accuracy: 0.3654 - 7ms/epoch - 7ms/step\n",
            "Epoch 125/1000\n",
            "1/1 - 0s - loss: 3.1496 - accuracy: 0.3846 - 6ms/epoch - 6ms/step\n",
            "Epoch 126/1000\n",
            "1/1 - 0s - loss: 3.1364 - accuracy: 0.3846 - 7ms/epoch - 7ms/step\n",
            "Epoch 127/1000\n",
            "1/1 - 0s - loss: 3.1232 - accuracy: 0.3846 - 8ms/epoch - 8ms/step\n",
            "Epoch 128/1000\n",
            "1/1 - 0s - loss: 3.1101 - accuracy: 0.3846 - 8ms/epoch - 8ms/step\n",
            "Epoch 129/1000\n",
            "1/1 - 0s - loss: 3.0971 - accuracy: 0.3846 - 7ms/epoch - 7ms/step\n",
            "Epoch 130/1000\n",
            "1/1 - 0s - loss: 3.0841 - accuracy: 0.4038 - 7ms/epoch - 7ms/step\n",
            "Epoch 131/1000\n",
            "1/1 - 0s - loss: 3.0711 - accuracy: 0.4038 - 10ms/epoch - 10ms/step\n",
            "Epoch 132/1000\n",
            "1/1 - 0s - loss: 3.0582 - accuracy: 0.4038 - 10ms/epoch - 10ms/step\n",
            "Epoch 133/1000\n",
            "1/1 - 0s - loss: 3.0454 - accuracy: 0.4038 - 6ms/epoch - 6ms/step\n",
            "Epoch 134/1000\n",
            "1/1 - 0s - loss: 3.0325 - accuracy: 0.4038 - 6ms/epoch - 6ms/step\n",
            "Epoch 135/1000\n",
            "1/1 - 0s - loss: 3.0196 - accuracy: 0.4231 - 9ms/epoch - 9ms/step\n",
            "Epoch 136/1000\n",
            "1/1 - 0s - loss: 3.0068 - accuracy: 0.4231 - 9ms/epoch - 9ms/step\n",
            "Epoch 137/1000\n",
            "1/1 - 0s - loss: 2.9940 - accuracy: 0.4231 - 8ms/epoch - 8ms/step\n",
            "Epoch 138/1000\n",
            "1/1 - 0s - loss: 2.9813 - accuracy: 0.4231 - 9ms/epoch - 9ms/step\n",
            "Epoch 139/1000\n",
            "1/1 - 0s - loss: 2.9686 - accuracy: 0.4231 - 8ms/epoch - 8ms/step\n",
            "Epoch 140/1000\n",
            "1/1 - 0s - loss: 2.9559 - accuracy: 0.4231 - 13ms/epoch - 13ms/step\n",
            "Epoch 141/1000\n",
            "1/1 - 0s - loss: 2.9432 - accuracy: 0.4231 - 8ms/epoch - 8ms/step\n",
            "Epoch 142/1000\n",
            "1/1 - 0s - loss: 2.9306 - accuracy: 0.4231 - 11ms/epoch - 11ms/step\n",
            "Epoch 143/1000\n",
            "1/1 - 0s - loss: 2.9181 - accuracy: 0.4231 - 10ms/epoch - 10ms/step\n",
            "Epoch 144/1000\n",
            "1/1 - 0s - loss: 2.9056 - accuracy: 0.4231 - 7ms/epoch - 7ms/step\n",
            "Epoch 145/1000\n",
            "1/1 - 0s - loss: 2.8932 - accuracy: 0.4231 - 11ms/epoch - 11ms/step\n",
            "Epoch 146/1000\n",
            "1/1 - 0s - loss: 2.8808 - accuracy: 0.4231 - 7ms/epoch - 7ms/step\n",
            "Epoch 147/1000\n",
            "1/1 - 0s - loss: 2.8685 - accuracy: 0.4231 - 8ms/epoch - 8ms/step\n",
            "Epoch 148/1000\n",
            "1/1 - 0s - loss: 2.8562 - accuracy: 0.4231 - 10ms/epoch - 10ms/step\n",
            "Epoch 149/1000\n",
            "1/1 - 0s - loss: 2.8438 - accuracy: 0.4423 - 7ms/epoch - 7ms/step\n",
            "Epoch 150/1000\n",
            "1/1 - 0s - loss: 2.8315 - accuracy: 0.4423 - 7ms/epoch - 7ms/step\n",
            "Epoch 151/1000\n",
            "1/1 - 0s - loss: 2.8192 - accuracy: 0.4423 - 12ms/epoch - 12ms/step\n",
            "Epoch 152/1000\n",
            "1/1 - 0s - loss: 2.8068 - accuracy: 0.4423 - 9ms/epoch - 9ms/step\n",
            "Epoch 153/1000\n",
            "1/1 - 0s - loss: 2.7943 - accuracy: 0.4423 - 13ms/epoch - 13ms/step\n",
            "Epoch 154/1000\n",
            "1/1 - 0s - loss: 2.7819 - accuracy: 0.4615 - 7ms/epoch - 7ms/step\n",
            "Epoch 155/1000\n",
            "1/1 - 0s - loss: 2.7696 - accuracy: 0.4615 - 7ms/epoch - 7ms/step\n",
            "Epoch 156/1000\n",
            "1/1 - 0s - loss: 2.7573 - accuracy: 0.4615 - 12ms/epoch - 12ms/step\n",
            "Epoch 157/1000\n",
            "1/1 - 0s - loss: 2.7449 - accuracy: 0.4615 - 7ms/epoch - 7ms/step\n",
            "Epoch 158/1000\n",
            "1/1 - 0s - loss: 2.7327 - accuracy: 0.4615 - 10ms/epoch - 10ms/step\n",
            "Epoch 159/1000\n",
            "1/1 - 0s - loss: 2.7205 - accuracy: 0.4808 - 11ms/epoch - 11ms/step\n",
            "Epoch 160/1000\n",
            "1/1 - 0s - loss: 2.7085 - accuracy: 0.5192 - 7ms/epoch - 7ms/step\n",
            "Epoch 161/1000\n",
            "1/1 - 0s - loss: 2.6965 - accuracy: 0.5192 - 9ms/epoch - 9ms/step\n",
            "Epoch 162/1000\n",
            "1/1 - 0s - loss: 2.6845 - accuracy: 0.5192 - 7ms/epoch - 7ms/step\n",
            "Epoch 163/1000\n",
            "1/1 - 0s - loss: 2.6725 - accuracy: 0.5192 - 9ms/epoch - 9ms/step\n",
            "Epoch 164/1000\n",
            "1/1 - 0s - loss: 2.6606 - accuracy: 0.5192 - 8ms/epoch - 8ms/step\n",
            "Epoch 165/1000\n",
            "1/1 - 0s - loss: 2.6488 - accuracy: 0.5192 - 7ms/epoch - 7ms/step\n",
            "Epoch 166/1000\n",
            "1/1 - 0s - loss: 2.6369 - accuracy: 0.5385 - 16ms/epoch - 16ms/step\n",
            "Epoch 167/1000\n",
            "1/1 - 0s - loss: 2.6251 - accuracy: 0.5577 - 8ms/epoch - 8ms/step\n",
            "Epoch 168/1000\n",
            "1/1 - 0s - loss: 2.6132 - accuracy: 0.5577 - 10ms/epoch - 10ms/step\n",
            "Epoch 169/1000\n",
            "1/1 - 0s - loss: 2.6014 - accuracy: 0.5769 - 17ms/epoch - 17ms/step\n",
            "Epoch 170/1000\n",
            "1/1 - 0s - loss: 2.5897 - accuracy: 0.5769 - 9ms/epoch - 9ms/step\n",
            "Epoch 171/1000\n",
            "1/1 - 0s - loss: 2.5781 - accuracy: 0.6154 - 10ms/epoch - 10ms/step\n",
            "Epoch 172/1000\n",
            "1/1 - 0s - loss: 2.5665 - accuracy: 0.6154 - 7ms/epoch - 7ms/step\n",
            "Epoch 173/1000\n",
            "1/1 - 0s - loss: 2.5549 - accuracy: 0.6346 - 10ms/epoch - 10ms/step\n",
            "Epoch 174/1000\n",
            "1/1 - 0s - loss: 2.5434 - accuracy: 0.6346 - 7ms/epoch - 7ms/step\n",
            "Epoch 175/1000\n",
            "1/1 - 0s - loss: 2.5319 - accuracy: 0.6346 - 11ms/epoch - 11ms/step\n",
            "Epoch 176/1000\n",
            "1/1 - 0s - loss: 2.5205 - accuracy: 0.6346 - 7ms/epoch - 7ms/step\n",
            "Epoch 177/1000\n",
            "1/1 - 0s - loss: 2.5091 - accuracy: 0.6538 - 6ms/epoch - 6ms/step\n",
            "Epoch 178/1000\n",
            "1/1 - 0s - loss: 2.4979 - accuracy: 0.6923 - 8ms/epoch - 8ms/step\n",
            "Epoch 179/1000\n",
            "1/1 - 0s - loss: 2.4866 - accuracy: 0.7115 - 11ms/epoch - 11ms/step\n",
            "Epoch 180/1000\n",
            "1/1 - 0s - loss: 2.4755 - accuracy: 0.7115 - 7ms/epoch - 7ms/step\n",
            "Epoch 181/1000\n",
            "1/1 - 0s - loss: 2.4643 - accuracy: 0.7308 - 11ms/epoch - 11ms/step\n",
            "Epoch 182/1000\n",
            "1/1 - 0s - loss: 2.4533 - accuracy: 0.7308 - 7ms/epoch - 7ms/step\n",
            "Epoch 183/1000\n",
            "1/1 - 0s - loss: 2.4423 - accuracy: 0.7308 - 10ms/epoch - 10ms/step\n",
            "Epoch 184/1000\n",
            "1/1 - 0s - loss: 2.4313 - accuracy: 0.7308 - 12ms/epoch - 12ms/step\n",
            "Epoch 185/1000\n",
            "1/1 - 0s - loss: 2.4204 - accuracy: 0.7308 - 8ms/epoch - 8ms/step\n",
            "Epoch 186/1000\n",
            "1/1 - 0s - loss: 2.4096 - accuracy: 0.7308 - 8ms/epoch - 8ms/step\n",
            "Epoch 187/1000\n",
            "1/1 - 0s - loss: 2.3989 - accuracy: 0.7308 - 14ms/epoch - 14ms/step\n",
            "Epoch 188/1000\n",
            "1/1 - 0s - loss: 2.3881 - accuracy: 0.7308 - 12ms/epoch - 12ms/step\n",
            "Epoch 189/1000\n",
            "1/1 - 0s - loss: 2.3774 - accuracy: 0.7308 - 7ms/epoch - 7ms/step\n",
            "Epoch 190/1000\n",
            "1/1 - 0s - loss: 2.3668 - accuracy: 0.7308 - 7ms/epoch - 7ms/step\n",
            "Epoch 191/1000\n",
            "1/1 - 0s - loss: 2.3562 - accuracy: 0.7500 - 7ms/epoch - 7ms/step\n",
            "Epoch 192/1000\n",
            "1/1 - 0s - loss: 2.3457 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
            "Epoch 193/1000\n",
            "1/1 - 0s - loss: 2.3352 - accuracy: 0.7500 - 6ms/epoch - 6ms/step\n",
            "Epoch 194/1000\n",
            "1/1 - 0s - loss: 2.3247 - accuracy: 0.7692 - 7ms/epoch - 7ms/step\n",
            "Epoch 195/1000\n",
            "1/1 - 0s - loss: 2.3144 - accuracy: 0.7885 - 9ms/epoch - 9ms/step\n",
            "Epoch 196/1000\n",
            "1/1 - 0s - loss: 2.3041 - accuracy: 0.7885 - 7ms/epoch - 7ms/step\n",
            "Epoch 197/1000\n",
            "1/1 - 0s - loss: 2.2939 - accuracy: 0.7885 - 10ms/epoch - 10ms/step\n",
            "Epoch 198/1000\n",
            "1/1 - 0s - loss: 2.2836 - accuracy: 0.7885 - 7ms/epoch - 7ms/step\n",
            "Epoch 199/1000\n",
            "1/1 - 0s - loss: 2.2735 - accuracy: 0.7885 - 13ms/epoch - 13ms/step\n",
            "Epoch 200/1000\n",
            "1/1 - 0s - loss: 2.2634 - accuracy: 0.7885 - 7ms/epoch - 7ms/step\n",
            "Epoch 201/1000\n",
            "1/1 - 0s - loss: 2.2534 - accuracy: 0.7885 - 18ms/epoch - 18ms/step\n",
            "Epoch 202/1000\n",
            "1/1 - 0s - loss: 2.2434 - accuracy: 0.7885 - 11ms/epoch - 11ms/step\n",
            "Epoch 203/1000\n",
            "1/1 - 0s - loss: 2.2334 - accuracy: 0.7885 - 7ms/epoch - 7ms/step\n",
            "Epoch 204/1000\n",
            "1/1 - 0s - loss: 2.2235 - accuracy: 0.7885 - 8ms/epoch - 8ms/step\n",
            "Epoch 205/1000\n",
            "1/1 - 0s - loss: 2.2136 - accuracy: 0.7885 - 10ms/epoch - 10ms/step\n",
            "Epoch 206/1000\n",
            "1/1 - 0s - loss: 2.2037 - accuracy: 0.7885 - 10ms/epoch - 10ms/step\n",
            "Epoch 207/1000\n",
            "1/1 - 0s - loss: 2.1939 - accuracy: 0.7885 - 10ms/epoch - 10ms/step\n",
            "Epoch 208/1000\n",
            "1/1 - 0s - loss: 2.1841 - accuracy: 0.7885 - 15ms/epoch - 15ms/step\n",
            "Epoch 209/1000\n",
            "1/1 - 0s - loss: 2.1744 - accuracy: 0.7885 - 9ms/epoch - 9ms/step\n",
            "Epoch 210/1000\n",
            "1/1 - 0s - loss: 2.1647 - accuracy: 0.7885 - 12ms/epoch - 12ms/step\n",
            "Epoch 211/1000\n",
            "1/1 - 0s - loss: 2.1550 - accuracy: 0.7885 - 9ms/epoch - 9ms/step\n",
            "Epoch 212/1000\n",
            "1/1 - 0s - loss: 2.1454 - accuracy: 0.7885 - 7ms/epoch - 7ms/step\n",
            "Epoch 213/1000\n",
            "1/1 - 0s - loss: 2.1358 - accuracy: 0.7885 - 7ms/epoch - 7ms/step\n",
            "Epoch 214/1000\n",
            "1/1 - 0s - loss: 2.1263 - accuracy: 0.7885 - 7ms/epoch - 7ms/step\n",
            "Epoch 215/1000\n",
            "1/1 - 0s - loss: 2.1168 - accuracy: 0.7885 - 11ms/epoch - 11ms/step\n",
            "Epoch 216/1000\n",
            "1/1 - 0s - loss: 2.1073 - accuracy: 0.7885 - 7ms/epoch - 7ms/step\n",
            "Epoch 217/1000\n",
            "1/1 - 0s - loss: 2.0979 - accuracy: 0.7885 - 6ms/epoch - 6ms/step\n",
            "Epoch 218/1000\n",
            "1/1 - 0s - loss: 2.0885 - accuracy: 0.7885 - 7ms/epoch - 7ms/step\n",
            "Epoch 219/1000\n",
            "1/1 - 0s - loss: 2.0792 - accuracy: 0.7885 - 11ms/epoch - 11ms/step\n",
            "Epoch 220/1000\n",
            "1/1 - 0s - loss: 2.0699 - accuracy: 0.7885 - 8ms/epoch - 8ms/step\n",
            "Epoch 221/1000\n",
            "1/1 - 0s - loss: 2.0606 - accuracy: 0.7885 - 5ms/epoch - 5ms/step\n",
            "Epoch 222/1000\n",
            "1/1 - 0s - loss: 2.0514 - accuracy: 0.7885 - 8ms/epoch - 8ms/step\n",
            "Epoch 223/1000\n",
            "1/1 - 0s - loss: 2.0422 - accuracy: 0.7885 - 9ms/epoch - 9ms/step\n",
            "Epoch 224/1000\n",
            "1/1 - 0s - loss: 2.0330 - accuracy: 0.7885 - 9ms/epoch - 9ms/step\n",
            "Epoch 225/1000\n",
            "1/1 - 0s - loss: 2.0239 - accuracy: 0.8077 - 11ms/epoch - 11ms/step\n",
            "Epoch 226/1000\n",
            "1/1 - 0s - loss: 2.0149 - accuracy: 0.8077 - 13ms/epoch - 13ms/step\n",
            "Epoch 227/1000\n",
            "1/1 - 0s - loss: 2.0060 - accuracy: 0.8077 - 8ms/epoch - 8ms/step\n",
            "Epoch 228/1000\n",
            "1/1 - 0s - loss: 1.9970 - accuracy: 0.8077 - 10ms/epoch - 10ms/step\n",
            "Epoch 229/1000\n",
            "1/1 - 0s - loss: 1.9881 - accuracy: 0.8077 - 10ms/epoch - 10ms/step\n",
            "Epoch 230/1000\n",
            "1/1 - 0s - loss: 1.9792 - accuracy: 0.8077 - 5ms/epoch - 5ms/step\n",
            "Epoch 231/1000\n",
            "1/1 - 0s - loss: 1.9703 - accuracy: 0.8077 - 9ms/epoch - 9ms/step\n",
            "Epoch 232/1000\n",
            "1/1 - 0s - loss: 1.9615 - accuracy: 0.8077 - 7ms/epoch - 7ms/step\n",
            "Epoch 233/1000\n",
            "1/1 - 0s - loss: 1.9527 - accuracy: 0.8462 - 13ms/epoch - 13ms/step\n",
            "Epoch 234/1000\n",
            "1/1 - 0s - loss: 1.9439 - accuracy: 0.8462 - 10ms/epoch - 10ms/step\n",
            "Epoch 235/1000\n",
            "1/1 - 0s - loss: 1.9352 - accuracy: 0.8462 - 11ms/epoch - 11ms/step\n",
            "Epoch 236/1000\n",
            "1/1 - 0s - loss: 1.9265 - accuracy: 0.8462 - 9ms/epoch - 9ms/step\n",
            "Epoch 237/1000\n",
            "1/1 - 0s - loss: 1.9178 - accuracy: 0.8462 - 13ms/epoch - 13ms/step\n",
            "Epoch 238/1000\n",
            "1/1 - 0s - loss: 1.9091 - accuracy: 0.8462 - 8ms/epoch - 8ms/step\n",
            "Epoch 239/1000\n",
            "1/1 - 0s - loss: 1.9005 - accuracy: 0.8462 - 10ms/epoch - 10ms/step\n",
            "Epoch 240/1000\n",
            "1/1 - 0s - loss: 1.8920 - accuracy: 0.8462 - 8ms/epoch - 8ms/step\n",
            "Epoch 241/1000\n",
            "1/1 - 0s - loss: 1.8835 - accuracy: 0.8654 - 11ms/epoch - 11ms/step\n",
            "Epoch 242/1000\n",
            "1/1 - 0s - loss: 1.8750 - accuracy: 0.8654 - 8ms/epoch - 8ms/step\n",
            "Epoch 243/1000\n",
            "1/1 - 0s - loss: 1.8666 - accuracy: 0.8654 - 8ms/epoch - 8ms/step\n",
            "Epoch 244/1000\n",
            "1/1 - 0s - loss: 1.8582 - accuracy: 0.8654 - 18ms/epoch - 18ms/step\n",
            "Epoch 245/1000\n",
            "1/1 - 0s - loss: 1.8498 - accuracy: 0.8654 - 7ms/epoch - 7ms/step\n",
            "Epoch 246/1000\n",
            "1/1 - 0s - loss: 1.8414 - accuracy: 0.8654 - 8ms/epoch - 8ms/step\n",
            "Epoch 247/1000\n",
            "1/1 - 0s - loss: 1.8331 - accuracy: 0.8654 - 8ms/epoch - 8ms/step\n",
            "Epoch 248/1000\n",
            "1/1 - 0s - loss: 1.8249 - accuracy: 0.8654 - 8ms/epoch - 8ms/step\n",
            "Epoch 249/1000\n",
            "1/1 - 0s - loss: 1.8167 - accuracy: 0.8654 - 6ms/epoch - 6ms/step\n",
            "Epoch 250/1000\n",
            "1/1 - 0s - loss: 1.8085 - accuracy: 0.8654 - 16ms/epoch - 16ms/step\n",
            "Epoch 251/1000\n",
            "1/1 - 0s - loss: 1.8003 - accuracy: 0.8654 - 7ms/epoch - 7ms/step\n",
            "Epoch 252/1000\n",
            "1/1 - 0s - loss: 1.7922 - accuracy: 0.8654 - 7ms/epoch - 7ms/step\n",
            "Epoch 253/1000\n",
            "1/1 - 0s - loss: 1.7841 - accuracy: 0.8654 - 10ms/epoch - 10ms/step\n",
            "Epoch 254/1000\n",
            "1/1 - 0s - loss: 1.7761 - accuracy: 0.8654 - 13ms/epoch - 13ms/step\n",
            "Epoch 255/1000\n",
            "1/1 - 0s - loss: 1.7681 - accuracy: 0.8654 - 10ms/epoch - 10ms/step\n",
            "Epoch 256/1000\n",
            "1/1 - 0s - loss: 1.7602 - accuracy: 0.8654 - 11ms/epoch - 11ms/step\n",
            "Epoch 257/1000\n",
            "1/1 - 0s - loss: 1.7522 - accuracy: 0.8846 - 11ms/epoch - 11ms/step\n",
            "Epoch 258/1000\n",
            "1/1 - 0s - loss: 1.7444 - accuracy: 0.8846 - 13ms/epoch - 13ms/step\n",
            "Epoch 259/1000\n",
            "1/1 - 0s - loss: 1.7365 - accuracy: 0.8846 - 7ms/epoch - 7ms/step\n",
            "Epoch 260/1000\n",
            "1/1 - 0s - loss: 1.7287 - accuracy: 0.8846 - 14ms/epoch - 14ms/step\n",
            "Epoch 261/1000\n",
            "1/1 - 0s - loss: 1.7210 - accuracy: 0.8846 - 13ms/epoch - 13ms/step\n",
            "Epoch 262/1000\n",
            "1/1 - 0s - loss: 1.7133 - accuracy: 0.8846 - 13ms/epoch - 13ms/step\n",
            "Epoch 263/1000\n",
            "1/1 - 0s - loss: 1.7057 - accuracy: 0.8846 - 7ms/epoch - 7ms/step\n",
            "Epoch 264/1000\n",
            "1/1 - 0s - loss: 1.6980 - accuracy: 0.8846 - 7ms/epoch - 7ms/step\n",
            "Epoch 265/1000\n",
            "1/1 - 0s - loss: 1.6904 - accuracy: 0.8846 - 9ms/epoch - 9ms/step\n",
            "Epoch 266/1000\n",
            "1/1 - 0s - loss: 1.6828 - accuracy: 0.8846 - 9ms/epoch - 9ms/step\n",
            "Epoch 267/1000\n",
            "1/1 - 0s - loss: 1.6752 - accuracy: 0.8846 - 13ms/epoch - 13ms/step\n",
            "Epoch 268/1000\n",
            "1/1 - 0s - loss: 1.6676 - accuracy: 0.8846 - 12ms/epoch - 12ms/step\n",
            "Epoch 269/1000\n",
            "1/1 - 0s - loss: 1.6600 - accuracy: 0.8846 - 8ms/epoch - 8ms/step\n",
            "Epoch 270/1000\n",
            "1/1 - 0s - loss: 1.6526 - accuracy: 0.8846 - 6ms/epoch - 6ms/step\n",
            "Epoch 271/1000\n",
            "1/1 - 0s - loss: 1.6451 - accuracy: 0.8846 - 11ms/epoch - 11ms/step\n",
            "Epoch 272/1000\n",
            "1/1 - 0s - loss: 1.6377 - accuracy: 0.9038 - 17ms/epoch - 17ms/step\n",
            "Epoch 273/1000\n",
            "1/1 - 0s - loss: 1.6303 - accuracy: 0.9038 - 12ms/epoch - 12ms/step\n",
            "Epoch 274/1000\n",
            "1/1 - 0s - loss: 1.6230 - accuracy: 0.9038 - 12ms/epoch - 12ms/step\n",
            "Epoch 275/1000\n",
            "1/1 - 0s - loss: 1.6157 - accuracy: 0.9038 - 9ms/epoch - 9ms/step\n",
            "Epoch 276/1000\n",
            "1/1 - 0s - loss: 1.6084 - accuracy: 0.9038 - 7ms/epoch - 7ms/step\n",
            "Epoch 277/1000\n",
            "1/1 - 0s - loss: 1.6011 - accuracy: 0.9038 - 7ms/epoch - 7ms/step\n",
            "Epoch 278/1000\n",
            "1/1 - 0s - loss: 1.5939 - accuracy: 0.9038 - 6ms/epoch - 6ms/step\n",
            "Epoch 279/1000\n",
            "1/1 - 0s - loss: 1.5868 - accuracy: 0.9038 - 11ms/epoch - 11ms/step\n",
            "Epoch 280/1000\n",
            "1/1 - 0s - loss: 1.5796 - accuracy: 0.9038 - 6ms/epoch - 6ms/step\n",
            "Epoch 281/1000\n",
            "1/1 - 0s - loss: 1.5725 - accuracy: 0.9038 - 8ms/epoch - 8ms/step\n",
            "Epoch 282/1000\n",
            "1/1 - 0s - loss: 1.5655 - accuracy: 0.9038 - 9ms/epoch - 9ms/step\n",
            "Epoch 283/1000\n",
            "1/1 - 0s - loss: 1.5585 - accuracy: 0.9038 - 11ms/epoch - 11ms/step\n",
            "Epoch 284/1000\n",
            "1/1 - 0s - loss: 1.5515 - accuracy: 0.9038 - 8ms/epoch - 8ms/step\n",
            "Epoch 285/1000\n",
            "1/1 - 0s - loss: 1.5446 - accuracy: 0.9038 - 9ms/epoch - 9ms/step\n",
            "Epoch 286/1000\n",
            "1/1 - 0s - loss: 1.5377 - accuracy: 0.9038 - 6ms/epoch - 6ms/step\n",
            "Epoch 287/1000\n",
            "1/1 - 0s - loss: 1.5308 - accuracy: 0.9038 - 10ms/epoch - 10ms/step\n",
            "Epoch 288/1000\n",
            "1/1 - 0s - loss: 1.5240 - accuracy: 0.9038 - 14ms/epoch - 14ms/step\n",
            "Epoch 289/1000\n",
            "1/1 - 0s - loss: 1.5172 - accuracy: 0.9038 - 11ms/epoch - 11ms/step\n",
            "Epoch 290/1000\n",
            "1/1 - 0s - loss: 1.5104 - accuracy: 0.9038 - 22ms/epoch - 22ms/step\n",
            "Epoch 291/1000\n",
            "1/1 - 0s - loss: 1.5037 - accuracy: 0.9038 - 13ms/epoch - 13ms/step\n",
            "Epoch 292/1000\n",
            "1/1 - 0s - loss: 1.4971 - accuracy: 0.9038 - 18ms/epoch - 18ms/step\n",
            "Epoch 293/1000\n",
            "1/1 - 0s - loss: 1.4904 - accuracy: 0.9038 - 12ms/epoch - 12ms/step\n",
            "Epoch 294/1000\n",
            "1/1 - 0s - loss: 1.4838 - accuracy: 0.9038 - 13ms/epoch - 13ms/step\n",
            "Epoch 295/1000\n",
            "1/1 - 0s - loss: 1.4773 - accuracy: 0.9038 - 7ms/epoch - 7ms/step\n",
            "Epoch 296/1000\n",
            "1/1 - 0s - loss: 1.4708 - accuracy: 0.9038 - 14ms/epoch - 14ms/step\n",
            "Epoch 297/1000\n",
            "1/1 - 0s - loss: 1.4643 - accuracy: 0.9038 - 10ms/epoch - 10ms/step\n",
            "Epoch 298/1000\n",
            "1/1 - 0s - loss: 1.4578 - accuracy: 0.9038 - 7ms/epoch - 7ms/step\n",
            "Epoch 299/1000\n",
            "1/1 - 0s - loss: 1.4514 - accuracy: 0.9038 - 15ms/epoch - 15ms/step\n",
            "Epoch 300/1000\n",
            "1/1 - 0s - loss: 1.4450 - accuracy: 0.9038 - 9ms/epoch - 9ms/step\n",
            "Epoch 301/1000\n",
            "1/1 - 0s - loss: 1.4386 - accuracy: 0.9038 - 14ms/epoch - 14ms/step\n",
            "Epoch 302/1000\n",
            "1/1 - 0s - loss: 1.4323 - accuracy: 0.9038 - 13ms/epoch - 13ms/step\n",
            "Epoch 303/1000\n",
            "1/1 - 0s - loss: 1.4260 - accuracy: 0.9038 - 6ms/epoch - 6ms/step\n",
            "Epoch 304/1000\n",
            "1/1 - 0s - loss: 1.4197 - accuracy: 0.9038 - 8ms/epoch - 8ms/step\n",
            "Epoch 305/1000\n",
            "1/1 - 0s - loss: 1.4135 - accuracy: 0.9038 - 10ms/epoch - 10ms/step\n",
            "Epoch 306/1000\n",
            "1/1 - 0s - loss: 1.4073 - accuracy: 0.9038 - 5ms/epoch - 5ms/step\n",
            "Epoch 307/1000\n",
            "1/1 - 0s - loss: 1.4012 - accuracy: 0.9038 - 8ms/epoch - 8ms/step\n",
            "Epoch 308/1000\n",
            "1/1 - 0s - loss: 1.3950 - accuracy: 0.9423 - 13ms/epoch - 13ms/step\n",
            "Epoch 309/1000\n",
            "1/1 - 0s - loss: 1.3889 - accuracy: 0.9423 - 7ms/epoch - 7ms/step\n",
            "Epoch 310/1000\n",
            "1/1 - 0s - loss: 1.3828 - accuracy: 0.9423 - 6ms/epoch - 6ms/step\n",
            "Epoch 311/1000\n",
            "1/1 - 0s - loss: 1.3768 - accuracy: 0.9423 - 6ms/epoch - 6ms/step\n",
            "Epoch 312/1000\n",
            "1/1 - 0s - loss: 1.3708 - accuracy: 0.9423 - 5ms/epoch - 5ms/step\n",
            "Epoch 313/1000\n",
            "1/1 - 0s - loss: 1.3648 - accuracy: 0.9423 - 6ms/epoch - 6ms/step\n",
            "Epoch 314/1000\n",
            "1/1 - 0s - loss: 1.3588 - accuracy: 0.9423 - 6ms/epoch - 6ms/step\n",
            "Epoch 315/1000\n",
            "1/1 - 0s - loss: 1.3529 - accuracy: 0.9423 - 5ms/epoch - 5ms/step\n",
            "Epoch 316/1000\n",
            "1/1 - 0s - loss: 1.3470 - accuracy: 0.9423 - 7ms/epoch - 7ms/step\n",
            "Epoch 317/1000\n",
            "1/1 - 0s - loss: 1.3411 - accuracy: 0.9423 - 6ms/epoch - 6ms/step\n",
            "Epoch 318/1000\n",
            "1/1 - 0s - loss: 1.3353 - accuracy: 0.9423 - 7ms/epoch - 7ms/step\n",
            "Epoch 319/1000\n",
            "1/1 - 0s - loss: 1.3295 - accuracy: 0.9423 - 6ms/epoch - 6ms/step\n",
            "Epoch 320/1000\n",
            "1/1 - 0s - loss: 1.3237 - accuracy: 0.9423 - 6ms/epoch - 6ms/step\n",
            "Epoch 321/1000\n",
            "1/1 - 0s - loss: 1.3179 - accuracy: 0.9423 - 6ms/epoch - 6ms/step\n",
            "Epoch 322/1000\n",
            "1/1 - 0s - loss: 1.3122 - accuracy: 0.9423 - 7ms/epoch - 7ms/step\n",
            "Epoch 323/1000\n",
            "1/1 - 0s - loss: 1.3065 - accuracy: 0.9423 - 4ms/epoch - 4ms/step\n",
            "Epoch 324/1000\n",
            "1/1 - 0s - loss: 1.3008 - accuracy: 0.9423 - 4ms/epoch - 4ms/step\n",
            "Epoch 325/1000\n",
            "1/1 - 0s - loss: 1.2951 - accuracy: 0.9423 - 19ms/epoch - 19ms/step\n",
            "Epoch 326/1000\n",
            "1/1 - 0s - loss: 1.2895 - accuracy: 0.9423 - 8ms/epoch - 8ms/step\n",
            "Epoch 327/1000\n",
            "1/1 - 0s - loss: 1.2839 - accuracy: 0.9423 - 8ms/epoch - 8ms/step\n",
            "Epoch 328/1000\n",
            "1/1 - 0s - loss: 1.2783 - accuracy: 0.9423 - 7ms/epoch - 7ms/step\n",
            "Epoch 329/1000\n",
            "1/1 - 0s - loss: 1.2727 - accuracy: 0.9423 - 8ms/epoch - 8ms/step\n",
            "Epoch 330/1000\n",
            "1/1 - 0s - loss: 1.2672 - accuracy: 0.9423 - 6ms/epoch - 6ms/step\n",
            "Epoch 331/1000\n",
            "1/1 - 0s - loss: 1.2617 - accuracy: 0.9423 - 6ms/epoch - 6ms/step\n",
            "Epoch 332/1000\n",
            "1/1 - 0s - loss: 1.2562 - accuracy: 0.9423 - 6ms/epoch - 6ms/step\n",
            "Epoch 333/1000\n",
            "1/1 - 0s - loss: 1.2508 - accuracy: 0.9423 - 7ms/epoch - 7ms/step\n",
            "Epoch 334/1000\n",
            "1/1 - 0s - loss: 1.2454 - accuracy: 0.9423 - 10ms/epoch - 10ms/step\n",
            "Epoch 335/1000\n",
            "1/1 - 0s - loss: 1.2400 - accuracy: 0.9423 - 12ms/epoch - 12ms/step\n",
            "Epoch 336/1000\n",
            "1/1 - 0s - loss: 1.2346 - accuracy: 0.9423 - 7ms/epoch - 7ms/step\n",
            "Epoch 337/1000\n",
            "1/1 - 0s - loss: 1.2293 - accuracy: 0.9423 - 8ms/epoch - 8ms/step\n",
            "Epoch 338/1000\n",
            "1/1 - 0s - loss: 1.2239 - accuracy: 0.9423 - 7ms/epoch - 7ms/step\n",
            "Epoch 339/1000\n",
            "1/1 - 0s - loss: 1.2186 - accuracy: 0.9423 - 8ms/epoch - 8ms/step\n",
            "Epoch 340/1000\n",
            "1/1 - 0s - loss: 1.2133 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 341/1000\n",
            "1/1 - 0s - loss: 1.2081 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 342/1000\n",
            "1/1 - 0s - loss: 1.2028 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 343/1000\n",
            "1/1 - 0s - loss: 1.1976 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 344/1000\n",
            "1/1 - 0s - loss: 1.1924 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 345/1000\n",
            "1/1 - 0s - loss: 1.1872 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 346/1000\n",
            "1/1 - 0s - loss: 1.1820 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 347/1000\n",
            "1/1 - 0s - loss: 1.1769 - accuracy: 0.9615 - 11ms/epoch - 11ms/step\n",
            "Epoch 348/1000\n",
            "1/1 - 0s - loss: 1.1718 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 349/1000\n",
            "1/1 - 0s - loss: 1.1667 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 350/1000\n",
            "1/1 - 0s - loss: 1.1617 - accuracy: 0.9615 - 10ms/epoch - 10ms/step\n",
            "Epoch 351/1000\n",
            "1/1 - 0s - loss: 1.1566 - accuracy: 0.9615 - 14ms/epoch - 14ms/step\n",
            "Epoch 352/1000\n",
            "1/1 - 0s - loss: 1.1516 - accuracy: 0.9615 - 11ms/epoch - 11ms/step\n",
            "Epoch 353/1000\n",
            "1/1 - 0s - loss: 1.1466 - accuracy: 0.9615 - 10ms/epoch - 10ms/step\n",
            "Epoch 354/1000\n",
            "1/1 - 0s - loss: 1.1416 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 355/1000\n",
            "1/1 - 0s - loss: 1.1367 - accuracy: 0.9615 - 5ms/epoch - 5ms/step\n",
            "Epoch 356/1000\n",
            "1/1 - 0s - loss: 1.1317 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 357/1000\n",
            "1/1 - 0s - loss: 1.1267 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 358/1000\n",
            "1/1 - 0s - loss: 1.1218 - accuracy: 0.9615 - 10ms/epoch - 10ms/step\n",
            "Epoch 359/1000\n",
            "1/1 - 0s - loss: 1.1168 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 360/1000\n",
            "1/1 - 0s - loss: 1.1119 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 361/1000\n",
            "1/1 - 0s - loss: 1.1070 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 362/1000\n",
            "1/1 - 0s - loss: 1.1021 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 363/1000\n",
            "1/1 - 0s - loss: 1.0973 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 364/1000\n",
            "1/1 - 0s - loss: 1.0924 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 365/1000\n",
            "1/1 - 0s - loss: 1.0876 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 366/1000\n",
            "1/1 - 0s - loss: 1.0828 - accuracy: 0.9615 - 9ms/epoch - 9ms/step\n",
            "Epoch 367/1000\n",
            "1/1 - 0s - loss: 1.0781 - accuracy: 0.9615 - 9ms/epoch - 9ms/step\n",
            "Epoch 368/1000\n",
            "1/1 - 0s - loss: 1.0733 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 369/1000\n",
            "1/1 - 0s - loss: 1.0685 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 370/1000\n",
            "1/1 - 0s - loss: 1.0638 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 371/1000\n",
            "1/1 - 0s - loss: 1.0591 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 372/1000\n",
            "1/1 - 0s - loss: 1.0544 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 373/1000\n",
            "1/1 - 0s - loss: 1.0498 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 374/1000\n",
            "1/1 - 0s - loss: 1.0451 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 375/1000\n",
            "1/1 - 0s - loss: 1.0405 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 376/1000\n",
            "1/1 - 0s - loss: 1.0359 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 377/1000\n",
            "1/1 - 0s - loss: 1.0314 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 378/1000\n",
            "1/1 - 0s - loss: 1.0269 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 379/1000\n",
            "1/1 - 0s - loss: 1.0224 - accuracy: 0.9615 - 5ms/epoch - 5ms/step\n",
            "Epoch 380/1000\n",
            "1/1 - 0s - loss: 1.0179 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 381/1000\n",
            "1/1 - 0s - loss: 1.0135 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 382/1000\n",
            "1/1 - 0s - loss: 1.0091 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 383/1000\n",
            "1/1 - 0s - loss: 1.0048 - accuracy: 0.9615 - 9ms/epoch - 9ms/step\n",
            "Epoch 384/1000\n",
            "1/1 - 0s - loss: 1.0004 - accuracy: 0.9615 - 14ms/epoch - 14ms/step\n",
            "Epoch 385/1000\n",
            "1/1 - 0s - loss: 0.9961 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 386/1000\n",
            "1/1 - 0s - loss: 0.9918 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 387/1000\n",
            "1/1 - 0s - loss: 0.9875 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 388/1000\n",
            "1/1 - 0s - loss: 0.9832 - accuracy: 0.9615 - 9ms/epoch - 9ms/step\n",
            "Epoch 389/1000\n",
            "1/1 - 0s - loss: 0.9790 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 390/1000\n",
            "1/1 - 0s - loss: 0.9748 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 391/1000\n",
            "1/1 - 0s - loss: 0.9706 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 392/1000\n",
            "1/1 - 0s - loss: 0.9664 - accuracy: 0.9615 - 9ms/epoch - 9ms/step\n",
            "Epoch 393/1000\n",
            "1/1 - 0s - loss: 0.9622 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 394/1000\n",
            "1/1 - 0s - loss: 0.9581 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 395/1000\n",
            "1/1 - 0s - loss: 0.9540 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 396/1000\n",
            "1/1 - 0s - loss: 0.9499 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 397/1000\n",
            "1/1 - 0s - loss: 0.9459 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 398/1000\n",
            "1/1 - 0s - loss: 0.9418 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 399/1000\n",
            "1/1 - 0s - loss: 0.9378 - accuracy: 0.9615 - 10ms/epoch - 10ms/step\n",
            "Epoch 400/1000\n",
            "1/1 - 0s - loss: 0.9338 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 401/1000\n",
            "1/1 - 0s - loss: 0.9298 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 402/1000\n",
            "1/1 - 0s - loss: 0.9258 - accuracy: 0.9615 - 15ms/epoch - 15ms/step\n",
            "Epoch 403/1000\n",
            "1/1 - 0s - loss: 0.9219 - accuracy: 0.9615 - 12ms/epoch - 12ms/step\n",
            "Epoch 404/1000\n",
            "1/1 - 0s - loss: 0.9180 - accuracy: 0.9615 - 11ms/epoch - 11ms/step\n",
            "Epoch 405/1000\n",
            "1/1 - 0s - loss: 0.9140 - accuracy: 0.9615 - 11ms/epoch - 11ms/step\n",
            "Epoch 406/1000\n",
            "1/1 - 0s - loss: 0.9102 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 407/1000\n",
            "1/1 - 0s - loss: 0.9063 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 408/1000\n",
            "1/1 - 0s - loss: 0.9024 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 409/1000\n",
            "1/1 - 0s - loss: 0.8986 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 410/1000\n",
            "1/1 - 0s - loss: 0.8948 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 411/1000\n",
            "1/1 - 0s - loss: 0.8910 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 412/1000\n",
            "1/1 - 0s - loss: 0.8873 - accuracy: 0.9615 - 11ms/epoch - 11ms/step\n",
            "Epoch 413/1000\n",
            "1/1 - 0s - loss: 0.8836 - accuracy: 0.9808 - 6ms/epoch - 6ms/step\n",
            "Epoch 414/1000\n",
            "1/1 - 0s - loss: 0.8799 - accuracy: 0.9808 - 5ms/epoch - 5ms/step\n",
            "Epoch 415/1000\n",
            "1/1 - 0s - loss: 0.8762 - accuracy: 0.9808 - 7ms/epoch - 7ms/step\n",
            "Epoch 416/1000\n",
            "1/1 - 0s - loss: 0.8725 - accuracy: 0.9808 - 10ms/epoch - 10ms/step\n",
            "Epoch 417/1000\n",
            "1/1 - 0s - loss: 0.8689 - accuracy: 0.9808 - 6ms/epoch - 6ms/step\n",
            "Epoch 418/1000\n",
            "1/1 - 0s - loss: 0.8653 - accuracy: 0.9808 - 7ms/epoch - 7ms/step\n",
            "Epoch 419/1000\n",
            "1/1 - 0s - loss: 0.8617 - accuracy: 0.9808 - 10ms/epoch - 10ms/step\n",
            "Epoch 420/1000\n",
            "1/1 - 0s - loss: 0.8581 - accuracy: 0.9808 - 11ms/epoch - 11ms/step\n",
            "Epoch 421/1000\n",
            "1/1 - 0s - loss: 0.8546 - accuracy: 0.9808 - 7ms/epoch - 7ms/step\n",
            "Epoch 422/1000\n",
            "1/1 - 0s - loss: 0.8510 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 423/1000\n",
            "1/1 - 0s - loss: 0.8475 - accuracy: 0.9808 - 7ms/epoch - 7ms/step\n",
            "Epoch 424/1000\n",
            "1/1 - 0s - loss: 0.8440 - accuracy: 0.9808 - 7ms/epoch - 7ms/step\n",
            "Epoch 425/1000\n",
            "1/1 - 0s - loss: 0.8405 - accuracy: 0.9808 - 15ms/epoch - 15ms/step\n",
            "Epoch 426/1000\n",
            "1/1 - 0s - loss: 0.8370 - accuracy: 0.9808 - 6ms/epoch - 6ms/step\n",
            "Epoch 427/1000\n",
            "1/1 - 0s - loss: 0.8335 - accuracy: 0.9808 - 15ms/epoch - 15ms/step\n",
            "Epoch 428/1000\n",
            "1/1 - 0s - loss: 0.8301 - accuracy: 0.9808 - 9ms/epoch - 9ms/step\n",
            "Epoch 429/1000\n",
            "1/1 - 0s - loss: 0.8267 - accuracy: 0.9808 - 6ms/epoch - 6ms/step\n",
            "Epoch 430/1000\n",
            "1/1 - 0s - loss: 0.8232 - accuracy: 0.9808 - 6ms/epoch - 6ms/step\n",
            "Epoch 431/1000\n",
            "1/1 - 0s - loss: 0.8199 - accuracy: 0.9808 - 6ms/epoch - 6ms/step\n",
            "Epoch 432/1000\n",
            "1/1 - 0s - loss: 0.8165 - accuracy: 0.9808 - 6ms/epoch - 6ms/step\n",
            "Epoch 433/1000\n",
            "1/1 - 0s - loss: 0.8131 - accuracy: 0.9808 - 6ms/epoch - 6ms/step\n",
            "Epoch 434/1000\n",
            "1/1 - 0s - loss: 0.8098 - accuracy: 0.9808 - 6ms/epoch - 6ms/step\n",
            "Epoch 435/1000\n",
            "1/1 - 0s - loss: 0.8064 - accuracy: 0.9808 - 7ms/epoch - 7ms/step\n",
            "Epoch 436/1000\n",
            "1/1 - 0s - loss: 0.8031 - accuracy: 0.9808 - 5ms/epoch - 5ms/step\n",
            "Epoch 437/1000\n",
            "1/1 - 0s - loss: 0.7998 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 438/1000\n",
            "1/1 - 0s - loss: 0.7965 - accuracy: 0.9808 - 10ms/epoch - 10ms/step\n",
            "Epoch 439/1000\n",
            "1/1 - 0s - loss: 0.7933 - accuracy: 0.9808 - 7ms/epoch - 7ms/step\n",
            "Epoch 440/1000\n",
            "1/1 - 0s - loss: 0.7900 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 441/1000\n",
            "1/1 - 0s - loss: 0.7868 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 442/1000\n",
            "1/1 - 0s - loss: 0.7836 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 443/1000\n",
            "1/1 - 0s - loss: 0.7804 - accuracy: 0.9808 - 11ms/epoch - 11ms/step\n",
            "Epoch 444/1000\n",
            "1/1 - 0s - loss: 0.7772 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 445/1000\n",
            "1/1 - 0s - loss: 0.7741 - accuracy: 0.9808 - 7ms/epoch - 7ms/step\n",
            "Epoch 446/1000\n",
            "1/1 - 0s - loss: 0.7710 - accuracy: 0.9808 - 6ms/epoch - 6ms/step\n",
            "Epoch 447/1000\n",
            "1/1 - 0s - loss: 0.7678 - accuracy: 0.9808 - 6ms/epoch - 6ms/step\n",
            "Epoch 448/1000\n",
            "1/1 - 0s - loss: 0.7647 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 449/1000\n",
            "1/1 - 0s - loss: 0.7616 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 450/1000\n",
            "1/1 - 0s - loss: 0.7586 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 451/1000\n",
            "1/1 - 0s - loss: 0.7555 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 452/1000\n",
            "1/1 - 0s - loss: 0.7525 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 453/1000\n",
            "1/1 - 0s - loss: 0.7494 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 454/1000\n",
            "1/1 - 0s - loss: 0.7464 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 455/1000\n",
            "1/1 - 0s - loss: 0.7434 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 456/1000\n",
            "1/1 - 0s - loss: 0.7404 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 457/1000\n",
            "1/1 - 0s - loss: 0.7374 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 458/1000\n",
            "1/1 - 0s - loss: 0.7344 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 459/1000\n",
            "1/1 - 0s - loss: 0.7315 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 460/1000\n",
            "1/1 - 0s - loss: 0.7285 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 461/1000\n",
            "1/1 - 0s - loss: 0.7256 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 462/1000\n",
            "1/1 - 0s - loss: 0.7227 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 463/1000\n",
            "1/1 - 0s - loss: 0.7198 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 464/1000\n",
            "1/1 - 0s - loss: 0.7169 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 465/1000\n",
            "1/1 - 0s - loss: 0.7141 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 466/1000\n",
            "1/1 - 0s - loss: 0.7112 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 467/1000\n",
            "1/1 - 0s - loss: 0.7084 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 468/1000\n",
            "1/1 - 0s - loss: 0.7055 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 469/1000\n",
            "1/1 - 0s - loss: 0.7027 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 470/1000\n",
            "1/1 - 0s - loss: 0.6999 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 471/1000\n",
            "1/1 - 0s - loss: 0.6971 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 472/1000\n",
            "1/1 - 0s - loss: 0.6944 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 473/1000\n",
            "1/1 - 0s - loss: 0.6916 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 474/1000\n",
            "1/1 - 0s - loss: 0.6888 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 475/1000\n",
            "1/1 - 0s - loss: 0.6861 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 476/1000\n",
            "1/1 - 0s - loss: 0.6834 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 477/1000\n",
            "1/1 - 0s - loss: 0.6807 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 478/1000\n",
            "1/1 - 0s - loss: 0.6780 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 479/1000\n",
            "1/1 - 0s - loss: 0.6753 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 480/1000\n",
            "1/1 - 0s - loss: 0.6726 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 481/1000\n",
            "1/1 - 0s - loss: 0.6699 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 482/1000\n",
            "1/1 - 0s - loss: 0.6673 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 483/1000\n",
            "1/1 - 0s - loss: 0.6647 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 484/1000\n",
            "1/1 - 0s - loss: 0.6620 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 485/1000\n",
            "1/1 - 0s - loss: 0.6594 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 486/1000\n",
            "1/1 - 0s - loss: 0.6569 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 487/1000\n",
            "1/1 - 0s - loss: 0.6543 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 488/1000\n",
            "1/1 - 0s - loss: 0.6517 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 489/1000\n",
            "1/1 - 0s - loss: 0.6492 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 490/1000\n",
            "1/1 - 0s - loss: 0.6466 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 491/1000\n",
            "1/1 - 0s - loss: 0.6441 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 492/1000\n",
            "1/1 - 0s - loss: 0.6416 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 493/1000\n",
            "1/1 - 0s - loss: 0.6390 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 494/1000\n",
            "1/1 - 0s - loss: 0.6365 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 495/1000\n",
            "1/1 - 0s - loss: 0.6340 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 496/1000\n",
            "1/1 - 0s - loss: 0.6316 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 497/1000\n",
            "1/1 - 0s - loss: 0.6291 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 498/1000\n",
            "1/1 - 0s - loss: 0.6267 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 499/1000\n",
            "1/1 - 0s - loss: 0.6243 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 500/1000\n",
            "1/1 - 0s - loss: 0.6219 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 501/1000\n",
            "1/1 - 0s - loss: 0.6195 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 502/1000\n",
            "1/1 - 0s - loss: 0.6172 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 503/1000\n",
            "1/1 - 0s - loss: 0.6148 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 504/1000\n",
            "1/1 - 0s - loss: 0.6125 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 505/1000\n",
            "1/1 - 0s - loss: 0.6101 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 506/1000\n",
            "1/1 - 0s - loss: 0.6078 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 507/1000\n",
            "1/1 - 0s - loss: 0.6055 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 508/1000\n",
            "1/1 - 0s - loss: 0.6032 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 509/1000\n",
            "1/1 - 0s - loss: 0.6009 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 510/1000\n",
            "1/1 - 0s - loss: 0.5986 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 511/1000\n",
            "1/1 - 0s - loss: 0.5963 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 512/1000\n",
            "1/1 - 0s - loss: 0.5941 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 513/1000\n",
            "1/1 - 0s - loss: 0.5918 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 514/1000\n",
            "1/1 - 0s - loss: 0.5896 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 515/1000\n",
            "1/1 - 0s - loss: 0.5874 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 516/1000\n",
            "1/1 - 0s - loss: 0.5852 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 517/1000\n",
            "1/1 - 0s - loss: 0.5830 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 518/1000\n",
            "1/1 - 0s - loss: 0.5808 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 519/1000\n",
            "1/1 - 0s - loss: 0.5786 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 520/1000\n",
            "1/1 - 0s - loss: 0.5764 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 521/1000\n",
            "1/1 - 0s - loss: 0.5743 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 522/1000\n",
            "1/1 - 0s - loss: 0.5721 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 523/1000\n",
            "1/1 - 0s - loss: 0.5700 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 524/1000\n",
            "1/1 - 0s - loss: 0.5678 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 525/1000\n",
            "1/1 - 0s - loss: 0.5657 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 526/1000\n",
            "1/1 - 0s - loss: 0.5636 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 527/1000\n",
            "1/1 - 0s - loss: 0.5615 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 528/1000\n",
            "1/1 - 0s - loss: 0.5594 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 529/1000\n",
            "1/1 - 0s - loss: 0.5573 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 530/1000\n",
            "1/1 - 0s - loss: 0.5552 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 531/1000\n",
            "1/1 - 0s - loss: 0.5532 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 532/1000\n",
            "1/1 - 0s - loss: 0.5511 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 533/1000\n",
            "1/1 - 0s - loss: 0.5491 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 534/1000\n",
            "1/1 - 0s - loss: 0.5471 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 535/1000\n",
            "1/1 - 0s - loss: 0.5450 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 536/1000\n",
            "1/1 - 0s - loss: 0.5430 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 537/1000\n",
            "1/1 - 0s - loss: 0.5410 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 538/1000\n",
            "1/1 - 0s - loss: 0.5390 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 539/1000\n",
            "1/1 - 0s - loss: 0.5371 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 540/1000\n",
            "1/1 - 0s - loss: 0.5351 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 541/1000\n",
            "1/1 - 0s - loss: 0.5332 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 542/1000\n",
            "1/1 - 0s - loss: 0.5312 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 543/1000\n",
            "1/1 - 0s - loss: 0.5293 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 544/1000\n",
            "1/1 - 0s - loss: 0.5273 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 545/1000\n",
            "1/1 - 0s - loss: 0.5254 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 546/1000\n",
            "1/1 - 0s - loss: 0.5235 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 547/1000\n",
            "1/1 - 0s - loss: 0.5216 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 548/1000\n",
            "1/1 - 0s - loss: 0.5197 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 549/1000\n",
            "1/1 - 0s - loss: 0.5178 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 550/1000\n",
            "1/1 - 0s - loss: 0.5159 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 551/1000\n",
            "1/1 - 0s - loss: 0.5140 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 552/1000\n",
            "1/1 - 0s - loss: 0.5122 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 553/1000\n",
            "1/1 - 0s - loss: 0.5103 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 554/1000\n",
            "1/1 - 0s - loss: 0.5085 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 555/1000\n",
            "1/1 - 0s - loss: 0.5066 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 556/1000\n",
            "1/1 - 0s - loss: 0.5048 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 557/1000\n",
            "1/1 - 0s - loss: 0.5030 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 558/1000\n",
            "1/1 - 0s - loss: 0.5012 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 559/1000\n",
            "1/1 - 0s - loss: 0.4994 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 560/1000\n",
            "1/1 - 0s - loss: 0.4976 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 561/1000\n",
            "1/1 - 0s - loss: 0.4958 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 562/1000\n",
            "1/1 - 0s - loss: 0.4940 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 563/1000\n",
            "1/1 - 0s - loss: 0.4923 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 564/1000\n",
            "1/1 - 0s - loss: 0.4905 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 565/1000\n",
            "1/1 - 0s - loss: 0.4887 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 566/1000\n",
            "1/1 - 0s - loss: 0.4870 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 567/1000\n",
            "1/1 - 0s - loss: 0.4853 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 568/1000\n",
            "1/1 - 0s - loss: 0.4835 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 569/1000\n",
            "1/1 - 0s - loss: 0.4818 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 570/1000\n",
            "1/1 - 0s - loss: 0.4801 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 571/1000\n",
            "1/1 - 0s - loss: 0.4784 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 572/1000\n",
            "1/1 - 0s - loss: 0.4767 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 573/1000\n",
            "1/1 - 0s - loss: 0.4750 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 574/1000\n",
            "1/1 - 0s - loss: 0.4733 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 575/1000\n",
            "1/1 - 0s - loss: 0.4717 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 576/1000\n",
            "1/1 - 0s - loss: 0.4700 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 577/1000\n",
            "1/1 - 0s - loss: 0.4684 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 578/1000\n",
            "1/1 - 0s - loss: 0.4667 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 579/1000\n",
            "1/1 - 0s - loss: 0.4651 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 580/1000\n",
            "1/1 - 0s - loss: 0.4634 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 581/1000\n",
            "1/1 - 0s - loss: 0.4618 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 582/1000\n",
            "1/1 - 0s - loss: 0.4602 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 583/1000\n",
            "1/1 - 0s - loss: 0.4586 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 584/1000\n",
            "1/1 - 0s - loss: 0.4570 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 585/1000\n",
            "1/1 - 0s - loss: 0.4554 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 586/1000\n",
            "1/1 - 0s - loss: 0.4538 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 587/1000\n",
            "1/1 - 0s - loss: 0.4522 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 588/1000\n",
            "1/1 - 0s - loss: 0.4507 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 589/1000\n",
            "1/1 - 0s - loss: 0.4491 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 590/1000\n",
            "1/1 - 0s - loss: 0.4475 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 591/1000\n",
            "1/1 - 0s - loss: 0.4460 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 592/1000\n",
            "1/1 - 0s - loss: 0.4445 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 593/1000\n",
            "1/1 - 0s - loss: 0.4429 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 594/1000\n",
            "1/1 - 0s - loss: 0.4414 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 595/1000\n",
            "1/1 - 0s - loss: 0.4399 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 596/1000\n",
            "1/1 - 0s - loss: 0.4384 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 597/1000\n",
            "1/1 - 0s - loss: 0.4368 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 598/1000\n",
            "1/1 - 0s - loss: 0.4354 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 599/1000\n",
            "1/1 - 0s - loss: 0.4339 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 600/1000\n",
            "1/1 - 0s - loss: 0.4324 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 601/1000\n",
            "1/1 - 0s - loss: 0.4309 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 602/1000\n",
            "1/1 - 0s - loss: 0.4294 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 603/1000\n",
            "1/1 - 0s - loss: 0.4280 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 604/1000\n",
            "1/1 - 0s - loss: 0.4265 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 605/1000\n",
            "1/1 - 0s - loss: 0.4250 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 606/1000\n",
            "1/1 - 0s - loss: 0.4236 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 607/1000\n",
            "1/1 - 0s - loss: 0.4221 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 608/1000\n",
            "1/1 - 0s - loss: 0.4207 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 609/1000\n",
            "1/1 - 0s - loss: 0.4193 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 610/1000\n",
            "1/1 - 0s - loss: 0.4179 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 611/1000\n",
            "1/1 - 0s - loss: 0.4164 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 612/1000\n",
            "1/1 - 0s - loss: 0.4150 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 613/1000\n",
            "1/1 - 0s - loss: 0.4136 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 614/1000\n",
            "1/1 - 0s - loss: 0.4122 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 615/1000\n",
            "1/1 - 0s - loss: 0.4109 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 616/1000\n",
            "1/1 - 0s - loss: 0.4095 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 617/1000\n",
            "1/1 - 0s - loss: 0.4081 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 618/1000\n",
            "1/1 - 0s - loss: 0.4067 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 619/1000\n",
            "1/1 - 0s - loss: 0.4054 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 620/1000\n",
            "1/1 - 0s - loss: 0.4040 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 621/1000\n",
            "1/1 - 0s - loss: 0.4027 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 622/1000\n",
            "1/1 - 0s - loss: 0.4013 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 623/1000\n",
            "1/1 - 0s - loss: 0.4000 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 624/1000\n",
            "1/1 - 0s - loss: 0.3986 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 625/1000\n",
            "1/1 - 0s - loss: 0.3973 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 626/1000\n",
            "1/1 - 0s - loss: 0.3960 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 627/1000\n",
            "1/1 - 0s - loss: 0.3947 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 628/1000\n",
            "1/1 - 0s - loss: 0.3934 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 629/1000\n",
            "1/1 - 0s - loss: 0.3921 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 630/1000\n",
            "1/1 - 0s - loss: 0.3908 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 631/1000\n",
            "1/1 - 0s - loss: 0.3895 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 632/1000\n",
            "1/1 - 0s - loss: 0.3882 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 633/1000\n",
            "1/1 - 0s - loss: 0.3869 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 634/1000\n",
            "1/1 - 0s - loss: 0.3857 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 635/1000\n",
            "1/1 - 0s - loss: 0.3844 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 636/1000\n",
            "1/1 - 0s - loss: 0.3831 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 637/1000\n",
            "1/1 - 0s - loss: 0.3819 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 638/1000\n",
            "1/1 - 0s - loss: 0.3807 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 639/1000\n",
            "1/1 - 0s - loss: 0.3794 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 640/1000\n",
            "1/1 - 0s - loss: 0.3782 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 641/1000\n",
            "1/1 - 0s - loss: 0.3770 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 642/1000\n",
            "1/1 - 0s - loss: 0.3757 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 643/1000\n",
            "1/1 - 0s - loss: 0.3745 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 644/1000\n",
            "1/1 - 0s - loss: 0.3733 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 645/1000\n",
            "1/1 - 0s - loss: 0.3721 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 646/1000\n",
            "1/1 - 0s - loss: 0.3709 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 647/1000\n",
            "1/1 - 0s - loss: 0.3697 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 648/1000\n",
            "1/1 - 0s - loss: 0.3685 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 649/1000\n",
            "1/1 - 0s - loss: 0.3673 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 650/1000\n",
            "1/1 - 0s - loss: 0.3662 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 651/1000\n",
            "1/1 - 0s - loss: 0.3650 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 652/1000\n",
            "1/1 - 0s - loss: 0.3638 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 653/1000\n",
            "1/1 - 0s - loss: 0.3627 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 654/1000\n",
            "1/1 - 0s - loss: 0.3615 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 655/1000\n",
            "1/1 - 0s - loss: 0.3603 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 656/1000\n",
            "1/1 - 0s - loss: 0.3592 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 657/1000\n",
            "1/1 - 0s - loss: 0.3580 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 658/1000\n",
            "1/1 - 0s - loss: 0.3569 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 659/1000\n",
            "1/1 - 0s - loss: 0.3558 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 660/1000\n",
            "1/1 - 0s - loss: 0.3546 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 661/1000\n",
            "1/1 - 0s - loss: 0.3535 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 662/1000\n",
            "1/1 - 0s - loss: 0.3524 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 663/1000\n",
            "1/1 - 0s - loss: 0.3513 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 664/1000\n",
            "1/1 - 0s - loss: 0.3501 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 665/1000\n",
            "1/1 - 0s - loss: 0.3490 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 666/1000\n",
            "1/1 - 0s - loss: 0.3479 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 667/1000\n",
            "1/1 - 0s - loss: 0.3468 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 668/1000\n",
            "1/1 - 0s - loss: 0.3457 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 669/1000\n",
            "1/1 - 0s - loss: 0.3446 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 670/1000\n",
            "1/1 - 0s - loss: 0.3436 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 671/1000\n",
            "1/1 - 0s - loss: 0.3425 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 672/1000\n",
            "1/1 - 0s - loss: 0.3414 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 673/1000\n",
            "1/1 - 0s - loss: 0.3403 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 674/1000\n",
            "1/1 - 0s - loss: 0.3393 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 675/1000\n",
            "1/1 - 0s - loss: 0.3382 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 676/1000\n",
            "1/1 - 0s - loss: 0.3372 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 677/1000\n",
            "1/1 - 0s - loss: 0.3361 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 678/1000\n",
            "1/1 - 0s - loss: 0.3350 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 679/1000\n",
            "1/1 - 0s - loss: 0.3340 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 680/1000\n",
            "1/1 - 0s - loss: 0.3330 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 681/1000\n",
            "1/1 - 0s - loss: 0.3319 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 682/1000\n",
            "1/1 - 0s - loss: 0.3309 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 683/1000\n",
            "1/1 - 0s - loss: 0.3299 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 684/1000\n",
            "1/1 - 0s - loss: 0.3288 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 685/1000\n",
            "1/1 - 0s - loss: 0.3278 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 686/1000\n",
            "1/1 - 0s - loss: 0.3268 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 687/1000\n",
            "1/1 - 0s - loss: 0.3258 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 688/1000\n",
            "1/1 - 0s - loss: 0.3248 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 689/1000\n",
            "1/1 - 0s - loss: 0.3238 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 690/1000\n",
            "1/1 - 0s - loss: 0.3228 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 691/1000\n",
            "1/1 - 0s - loss: 0.3218 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 692/1000\n",
            "1/1 - 0s - loss: 0.3208 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 693/1000\n",
            "1/1 - 0s - loss: 0.3198 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 694/1000\n",
            "1/1 - 0s - loss: 0.3188 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 695/1000\n",
            "1/1 - 0s - loss: 0.3179 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 696/1000\n",
            "1/1 - 0s - loss: 0.3169 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 697/1000\n",
            "1/1 - 0s - loss: 0.3159 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 698/1000\n",
            "1/1 - 0s - loss: 0.3149 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 699/1000\n",
            "1/1 - 0s - loss: 0.3140 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 700/1000\n",
            "1/1 - 0s - loss: 0.3130 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 701/1000\n",
            "1/1 - 0s - loss: 0.3121 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 702/1000\n",
            "1/1 - 0s - loss: 0.3111 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 703/1000\n",
            "1/1 - 0s - loss: 0.3102 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 704/1000\n",
            "1/1 - 0s - loss: 0.3093 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 705/1000\n",
            "1/1 - 0s - loss: 0.3083 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 706/1000\n",
            "1/1 - 0s - loss: 0.3074 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 707/1000\n",
            "1/1 - 0s - loss: 0.3065 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 708/1000\n",
            "1/1 - 0s - loss: 0.3055 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 709/1000\n",
            "1/1 - 0s - loss: 0.3046 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 710/1000\n",
            "1/1 - 0s - loss: 0.3037 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 711/1000\n",
            "1/1 - 0s - loss: 0.3028 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 712/1000\n",
            "1/1 - 0s - loss: 0.3019 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 713/1000\n",
            "1/1 - 0s - loss: 0.3010 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 714/1000\n",
            "1/1 - 0s - loss: 0.3001 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 715/1000\n",
            "1/1 - 0s - loss: 0.2992 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 716/1000\n",
            "1/1 - 0s - loss: 0.2983 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 717/1000\n",
            "1/1 - 0s - loss: 0.2974 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 718/1000\n",
            "1/1 - 0s - loss: 0.2965 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 719/1000\n",
            "1/1 - 0s - loss: 0.2956 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 720/1000\n",
            "1/1 - 0s - loss: 0.2948 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 721/1000\n",
            "1/1 - 0s - loss: 0.2939 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 722/1000\n",
            "1/1 - 0s - loss: 0.2930 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 723/1000\n",
            "1/1 - 0s - loss: 0.2921 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 724/1000\n",
            "1/1 - 0s - loss: 0.2913 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 725/1000\n",
            "1/1 - 0s - loss: 0.2904 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 726/1000\n",
            "1/1 - 0s - loss: 0.2896 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 727/1000\n",
            "1/1 - 0s - loss: 0.2887 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 728/1000\n",
            "1/1 - 0s - loss: 0.2879 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 729/1000\n",
            "1/1 - 0s - loss: 0.2870 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 730/1000\n",
            "1/1 - 0s - loss: 0.2862 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 731/1000\n",
            "1/1 - 0s - loss: 0.2853 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 732/1000\n",
            "1/1 - 0s - loss: 0.2845 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 733/1000\n",
            "1/1 - 0s - loss: 0.2837 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 734/1000\n",
            "1/1 - 0s - loss: 0.2828 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 735/1000\n",
            "1/1 - 0s - loss: 0.2820 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 736/1000\n",
            "1/1 - 0s - loss: 0.2812 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 737/1000\n",
            "1/1 - 0s - loss: 0.2804 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 738/1000\n",
            "1/1 - 0s - loss: 0.2795 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 739/1000\n",
            "1/1 - 0s - loss: 0.2787 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 740/1000\n",
            "1/1 - 0s - loss: 0.2779 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 741/1000\n",
            "1/1 - 0s - loss: 0.2771 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 742/1000\n",
            "1/1 - 0s - loss: 0.2763 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 743/1000\n",
            "1/1 - 0s - loss: 0.2755 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 744/1000\n",
            "1/1 - 0s - loss: 0.2747 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 745/1000\n",
            "1/1 - 0s - loss: 0.2739 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 746/1000\n",
            "1/1 - 0s - loss: 0.2731 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 747/1000\n",
            "1/1 - 0s - loss: 0.2723 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 748/1000\n",
            "1/1 - 0s - loss: 0.2715 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 749/1000\n",
            "1/1 - 0s - loss: 0.2708 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 750/1000\n",
            "1/1 - 0s - loss: 0.2700 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 751/1000\n",
            "1/1 - 0s - loss: 0.2692 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 752/1000\n",
            "1/1 - 0s - loss: 0.2684 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 753/1000\n",
            "1/1 - 0s - loss: 0.2676 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 754/1000\n",
            "1/1 - 0s - loss: 0.2669 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 755/1000\n",
            "1/1 - 0s - loss: 0.2661 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 756/1000\n",
            "1/1 - 0s - loss: 0.2654 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 757/1000\n",
            "1/1 - 0s - loss: 0.2646 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 758/1000\n",
            "1/1 - 0s - loss: 0.2638 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 759/1000\n",
            "1/1 - 0s - loss: 0.2631 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 760/1000\n",
            "1/1 - 0s - loss: 0.2623 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 761/1000\n",
            "1/1 - 0s - loss: 0.2616 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 762/1000\n",
            "1/1 - 0s - loss: 0.2608 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 763/1000\n",
            "1/1 - 0s - loss: 0.2601 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 764/1000\n",
            "1/1 - 0s - loss: 0.2594 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 765/1000\n",
            "1/1 - 0s - loss: 0.2586 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 766/1000\n",
            "1/1 - 0s - loss: 0.2579 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 767/1000\n",
            "1/1 - 0s - loss: 0.2572 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 768/1000\n",
            "1/1 - 0s - loss: 0.2564 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 769/1000\n",
            "1/1 - 0s - loss: 0.2557 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 770/1000\n",
            "1/1 - 0s - loss: 0.2550 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 771/1000\n",
            "1/1 - 0s - loss: 0.2543 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 772/1000\n",
            "1/1 - 0s - loss: 0.2535 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 773/1000\n",
            "1/1 - 0s - loss: 0.2528 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 774/1000\n",
            "1/1 - 0s - loss: 0.2521 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 775/1000\n",
            "1/1 - 0s - loss: 0.2514 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 776/1000\n",
            "1/1 - 0s - loss: 0.2507 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 777/1000\n",
            "1/1 - 0s - loss: 0.2500 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 778/1000\n",
            "1/1 - 0s - loss: 0.2493 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 779/1000\n",
            "1/1 - 0s - loss: 0.2486 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 780/1000\n",
            "1/1 - 0s - loss: 0.2479 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 781/1000\n",
            "1/1 - 0s - loss: 0.2472 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 782/1000\n",
            "1/1 - 0s - loss: 0.2465 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 783/1000\n",
            "1/1 - 0s - loss: 0.2458 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 784/1000\n",
            "1/1 - 0s - loss: 0.2451 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 785/1000\n",
            "1/1 - 0s - loss: 0.2445 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 786/1000\n",
            "1/1 - 0s - loss: 0.2438 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 787/1000\n",
            "1/1 - 0s - loss: 0.2431 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 788/1000\n",
            "1/1 - 0s - loss: 0.2424 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 789/1000\n",
            "1/1 - 0s - loss: 0.2417 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 790/1000\n",
            "1/1 - 0s - loss: 0.2411 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 791/1000\n",
            "1/1 - 0s - loss: 0.2404 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 792/1000\n",
            "1/1 - 0s - loss: 0.2397 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 793/1000\n",
            "1/1 - 0s - loss: 0.2391 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 794/1000\n",
            "1/1 - 0s - loss: 0.2384 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 795/1000\n",
            "1/1 - 0s - loss: 0.2378 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 796/1000\n",
            "1/1 - 0s - loss: 0.2371 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 797/1000\n",
            "1/1 - 0s - loss: 0.2365 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 798/1000\n",
            "1/1 - 0s - loss: 0.2358 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 799/1000\n",
            "1/1 - 0s - loss: 0.2352 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 800/1000\n",
            "1/1 - 0s - loss: 0.2345 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 801/1000\n",
            "1/1 - 0s - loss: 0.2339 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 802/1000\n",
            "1/1 - 0s - loss: 0.2332 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 803/1000\n",
            "1/1 - 0s - loss: 0.2326 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 804/1000\n",
            "1/1 - 0s - loss: 0.2320 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 805/1000\n",
            "1/1 - 0s - loss: 0.2313 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 806/1000\n",
            "1/1 - 0s - loss: 0.2307 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 807/1000\n",
            "1/1 - 0s - loss: 0.2301 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 808/1000\n",
            "1/1 - 0s - loss: 0.2294 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 809/1000\n",
            "1/1 - 0s - loss: 0.2288 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 810/1000\n",
            "1/1 - 0s - loss: 0.2282 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 811/1000\n",
            "1/1 - 0s - loss: 0.2276 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 812/1000\n",
            "1/1 - 0s - loss: 0.2269 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 813/1000\n",
            "1/1 - 0s - loss: 0.2263 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 814/1000\n",
            "1/1 - 0s - loss: 0.2257 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 815/1000\n",
            "1/1 - 0s - loss: 0.2251 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 816/1000\n",
            "1/1 - 0s - loss: 0.2245 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 817/1000\n",
            "1/1 - 0s - loss: 0.2239 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 818/1000\n",
            "1/1 - 0s - loss: 0.2233 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 819/1000\n",
            "1/1 - 0s - loss: 0.2227 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 820/1000\n",
            "1/1 - 0s - loss: 0.2221 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 821/1000\n",
            "1/1 - 0s - loss: 0.2215 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 822/1000\n",
            "1/1 - 0s - loss: 0.2209 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 823/1000\n",
            "1/1 - 0s - loss: 0.2203 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 824/1000\n",
            "1/1 - 0s - loss: 0.2197 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 825/1000\n",
            "1/1 - 0s - loss: 0.2191 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 826/1000\n",
            "1/1 - 0s - loss: 0.2185 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 827/1000\n",
            "1/1 - 0s - loss: 0.2180 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 828/1000\n",
            "1/1 - 0s - loss: 0.2174 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 829/1000\n",
            "1/1 - 0s - loss: 0.2168 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 830/1000\n",
            "1/1 - 0s - loss: 0.2162 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 831/1000\n",
            "1/1 - 0s - loss: 0.2156 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 832/1000\n",
            "1/1 - 0s - loss: 0.2151 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 833/1000\n",
            "1/1 - 0s - loss: 0.2145 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 834/1000\n",
            "1/1 - 0s - loss: 0.2139 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 835/1000\n",
            "1/1 - 0s - loss: 0.2133 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 836/1000\n",
            "1/1 - 0s - loss: 0.2128 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 837/1000\n",
            "1/1 - 0s - loss: 0.2122 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 838/1000\n",
            "1/1 - 0s - loss: 0.2117 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 839/1000\n",
            "1/1 - 0s - loss: 0.2111 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 840/1000\n",
            "1/1 - 0s - loss: 0.2105 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 841/1000\n",
            "1/1 - 0s - loss: 0.2100 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 842/1000\n",
            "1/1 - 0s - loss: 0.2094 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 843/1000\n",
            "1/1 - 0s - loss: 0.2089 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 844/1000\n",
            "1/1 - 0s - loss: 0.2083 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 845/1000\n",
            "1/1 - 0s - loss: 0.2078 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 846/1000\n",
            "1/1 - 0s - loss: 0.2072 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 847/1000\n",
            "1/1 - 0s - loss: 0.2067 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 848/1000\n",
            "1/1 - 0s - loss: 0.2061 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 849/1000\n",
            "1/1 - 0s - loss: 0.2056 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 850/1000\n",
            "1/1 - 0s - loss: 0.2051 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 851/1000\n",
            "1/1 - 0s - loss: 0.2045 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 852/1000\n",
            "1/1 - 0s - loss: 0.2040 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 853/1000\n",
            "1/1 - 0s - loss: 0.2035 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 854/1000\n",
            "1/1 - 0s - loss: 0.2029 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 855/1000\n",
            "1/1 - 0s - loss: 0.2024 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 856/1000\n",
            "1/1 - 0s - loss: 0.2019 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 857/1000\n",
            "1/1 - 0s - loss: 0.2013 - accuracy: 1.0000 - 41ms/epoch - 41ms/step\n",
            "Epoch 858/1000\n",
            "1/1 - 0s - loss: 0.2008 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 859/1000\n",
            "1/1 - 0s - loss: 0.2003 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 860/1000\n",
            "1/1 - 0s - loss: 0.1998 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 861/1000\n",
            "1/1 - 0s - loss: 0.1993 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 862/1000\n",
            "1/1 - 0s - loss: 0.1987 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 863/1000\n",
            "1/1 - 0s - loss: 0.1982 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 864/1000\n",
            "1/1 - 0s - loss: 0.1977 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 865/1000\n",
            "1/1 - 0s - loss: 0.1972 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 866/1000\n",
            "1/1 - 0s - loss: 0.1967 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 867/1000\n",
            "1/1 - 0s - loss: 0.1962 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 868/1000\n",
            "1/1 - 0s - loss: 0.1957 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 869/1000\n",
            "1/1 - 0s - loss: 0.1952 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 870/1000\n",
            "1/1 - 0s - loss: 0.1947 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 871/1000\n",
            "1/1 - 0s - loss: 0.1942 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 872/1000\n",
            "1/1 - 0s - loss: 0.1937 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 873/1000\n",
            "1/1 - 0s - loss: 0.1932 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 874/1000\n",
            "1/1 - 0s - loss: 0.1927 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 875/1000\n",
            "1/1 - 0s - loss: 0.1922 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 876/1000\n",
            "1/1 - 0s - loss: 0.1917 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 877/1000\n",
            "1/1 - 0s - loss: 0.1912 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 878/1000\n",
            "1/1 - 0s - loss: 0.1907 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 879/1000\n",
            "1/1 - 0s - loss: 0.1902 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 880/1000\n",
            "1/1 - 0s - loss: 0.1897 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 881/1000\n",
            "1/1 - 0s - loss: 0.1893 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 882/1000\n",
            "1/1 - 0s - loss: 0.1888 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 883/1000\n",
            "1/1 - 0s - loss: 0.1883 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 884/1000\n",
            "1/1 - 0s - loss: 0.1878 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 885/1000\n",
            "1/1 - 0s - loss: 0.1873 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 886/1000\n",
            "1/1 - 0s - loss: 0.1869 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 887/1000\n",
            "1/1 - 0s - loss: 0.1864 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 888/1000\n",
            "1/1 - 0s - loss: 0.1859 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 889/1000\n",
            "1/1 - 0s - loss: 0.1854 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 890/1000\n",
            "1/1 - 0s - loss: 0.1850 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 891/1000\n",
            "1/1 - 0s - loss: 0.1845 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 892/1000\n",
            "1/1 - 0s - loss: 0.1840 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 893/1000\n",
            "1/1 - 0s - loss: 0.1836 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 894/1000\n",
            "1/1 - 0s - loss: 0.1831 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 895/1000\n",
            "1/1 - 0s - loss: 0.1827 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 896/1000\n",
            "1/1 - 0s - loss: 0.1822 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 897/1000\n",
            "1/1 - 0s - loss: 0.1817 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 898/1000\n",
            "1/1 - 0s - loss: 0.1813 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 899/1000\n",
            "1/1 - 0s - loss: 0.1808 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 900/1000\n",
            "1/1 - 0s - loss: 0.1804 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 901/1000\n",
            "1/1 - 0s - loss: 0.1799 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 902/1000\n",
            "1/1 - 0s - loss: 0.1795 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 903/1000\n",
            "1/1 - 0s - loss: 0.1790 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 904/1000\n",
            "1/1 - 0s - loss: 0.1786 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 905/1000\n",
            "1/1 - 0s - loss: 0.1781 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 906/1000\n",
            "1/1 - 0s - loss: 0.1777 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 907/1000\n",
            "1/1 - 0s - loss: 0.1773 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 908/1000\n",
            "1/1 - 0s - loss: 0.1768 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 909/1000\n",
            "1/1 - 0s - loss: 0.1764 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 910/1000\n",
            "1/1 - 0s - loss: 0.1759 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 911/1000\n",
            "1/1 - 0s - loss: 0.1755 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 912/1000\n",
            "1/1 - 0s - loss: 0.1751 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 913/1000\n",
            "1/1 - 0s - loss: 0.1746 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 914/1000\n",
            "1/1 - 0s - loss: 0.1742 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 915/1000\n",
            "1/1 - 0s - loss: 0.1738 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 916/1000\n",
            "1/1 - 0s - loss: 0.1733 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 917/1000\n",
            "1/1 - 0s - loss: 0.1729 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 918/1000\n",
            "1/1 - 0s - loss: 0.1725 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 919/1000\n",
            "1/1 - 0s - loss: 0.1721 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 920/1000\n",
            "1/1 - 0s - loss: 0.1716 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 921/1000\n",
            "1/1 - 0s - loss: 0.1712 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 922/1000\n",
            "1/1 - 0s - loss: 0.1708 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 923/1000\n",
            "1/1 - 0s - loss: 0.1704 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 924/1000\n",
            "1/1 - 0s - loss: 0.1700 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 925/1000\n",
            "1/1 - 0s - loss: 0.1695 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 926/1000\n",
            "1/1 - 0s - loss: 0.1691 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 927/1000\n",
            "1/1 - 0s - loss: 0.1687 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 928/1000\n",
            "1/1 - 0s - loss: 0.1683 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 929/1000\n",
            "1/1 - 0s - loss: 0.1679 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 930/1000\n",
            "1/1 - 0s - loss: 0.1675 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 931/1000\n",
            "1/1 - 0s - loss: 0.1671 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 932/1000\n",
            "1/1 - 0s - loss: 0.1667 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 933/1000\n",
            "1/1 - 0s - loss: 0.1663 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 934/1000\n",
            "1/1 - 0s - loss: 0.1658 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 935/1000\n",
            "1/1 - 0s - loss: 0.1654 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 936/1000\n",
            "1/1 - 0s - loss: 0.1650 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 937/1000\n",
            "1/1 - 0s - loss: 0.1646 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 938/1000\n",
            "1/1 - 0s - loss: 0.1642 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 939/1000\n",
            "1/1 - 0s - loss: 0.1638 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 940/1000\n",
            "1/1 - 0s - loss: 0.1634 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 941/1000\n",
            "1/1 - 0s - loss: 0.1630 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 942/1000\n",
            "1/1 - 0s - loss: 0.1626 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 943/1000\n",
            "1/1 - 0s - loss: 0.1622 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 944/1000\n",
            "1/1 - 0s - loss: 0.1619 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 945/1000\n",
            "1/1 - 0s - loss: 0.1615 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 946/1000\n",
            "1/1 - 0s - loss: 0.1611 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 947/1000\n",
            "1/1 - 0s - loss: 0.1607 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 948/1000\n",
            "1/1 - 0s - loss: 0.1603 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 949/1000\n",
            "1/1 - 0s - loss: 0.1599 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 950/1000\n",
            "1/1 - 0s - loss: 0.1595 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 951/1000\n",
            "1/1 - 0s - loss: 0.1591 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 952/1000\n",
            "1/1 - 0s - loss: 0.1587 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 953/1000\n",
            "1/1 - 0s - loss: 0.1584 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 954/1000\n",
            "1/1 - 0s - loss: 0.1580 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 955/1000\n",
            "1/1 - 0s - loss: 0.1576 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 956/1000\n",
            "1/1 - 0s - loss: 0.1572 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 957/1000\n",
            "1/1 - 0s - loss: 0.1569 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 958/1000\n",
            "1/1 - 0s - loss: 0.1565 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 959/1000\n",
            "1/1 - 0s - loss: 0.1561 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 960/1000\n",
            "1/1 - 0s - loss: 0.1557 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 961/1000\n",
            "1/1 - 0s - loss: 0.1554 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 962/1000\n",
            "1/1 - 0s - loss: 0.1550 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 963/1000\n",
            "1/1 - 0s - loss: 0.1546 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 964/1000\n",
            "1/1 - 0s - loss: 0.1542 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 965/1000\n",
            "1/1 - 0s - loss: 0.1539 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 966/1000\n",
            "1/1 - 0s - loss: 0.1535 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 967/1000\n",
            "1/1 - 0s - loss: 0.1531 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 968/1000\n",
            "1/1 - 0s - loss: 0.1528 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 969/1000\n",
            "1/1 - 0s - loss: 0.1524 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 970/1000\n",
            "1/1 - 0s - loss: 0.1521 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 971/1000\n",
            "1/1 - 0s - loss: 0.1517 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 972/1000\n",
            "1/1 - 0s - loss: 0.1513 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 973/1000\n",
            "1/1 - 0s - loss: 0.1510 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 974/1000\n",
            "1/1 - 0s - loss: 0.1506 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 975/1000\n",
            "1/1 - 0s - loss: 0.1503 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 976/1000\n",
            "1/1 - 0s - loss: 0.1499 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 977/1000\n",
            "1/1 - 0s - loss: 0.1495 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 978/1000\n",
            "1/1 - 0s - loss: 0.1492 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 979/1000\n",
            "1/1 - 0s - loss: 0.1488 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 980/1000\n",
            "1/1 - 0s - loss: 0.1485 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 981/1000\n",
            "1/1 - 0s - loss: 0.1481 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 982/1000\n",
            "1/1 - 0s - loss: 0.1478 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 983/1000\n",
            "1/1 - 0s - loss: 0.1474 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 984/1000\n",
            "1/1 - 0s - loss: 0.1471 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 985/1000\n",
            "1/1 - 0s - loss: 0.1467 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 986/1000\n",
            "1/1 - 0s - loss: 0.1464 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 987/1000\n",
            "1/1 - 0s - loss: 0.1461 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 988/1000\n",
            "1/1 - 0s - loss: 0.1457 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 989/1000\n",
            "1/1 - 0s - loss: 0.1454 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 990/1000\n",
            "1/1 - 0s - loss: 0.1450 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 991/1000\n",
            "1/1 - 0s - loss: 0.1447 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 992/1000\n",
            "1/1 - 0s - loss: 0.1444 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 993/1000\n",
            "1/1 - 0s - loss: 0.1440 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 994/1000\n",
            "1/1 - 0s - loss: 0.1437 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 995/1000\n",
            "1/1 - 0s - loss: 0.1433 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 996/1000\n",
            "1/1 - 0s - loss: 0.1430 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 997/1000\n",
            "1/1 - 0s - loss: 0.1427 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 998/1000\n",
            "1/1 - 0s - loss: 0.1423 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 999/1000\n",
            "1/1 - 0s - loss: 0.1420 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 1000/1000\n",
            "1/1 - 0s - loss: 0.1417 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff646bc72d0>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "data = train_set\n",
        "labels = one_hot\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    data,\n",
        "    labels,\n",
        "    epochs = 1000,\n",
        "    verbose = 2,\n",
        "    batch_size = 52,\n",
        "    callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3),\n",
        "    shuffle = True,\n",
        "    initial_epoch = 0\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsQs5lZsB3vP"
      },
      "source": [
        "\n",
        "\n",
        "**5. Evaluate the model on TEST_SET. What accuracy do you obtain? If the accuracy is less than 100%, which test images are misclassified? (You may wish to use the show(image) function you defined in the previous project.)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP6PgX4HVGak",
        "outputId": "6fbd4584-5f8b-472e-ae68-3aefb27151ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - loss: 1.9227 - accuracy: 0.5385 - 150ms/epoch - 150ms/step\n",
            "\n",
            "Misclassified test images\n",
            "Target char: A and Predicted char: G\n",
            "Target char: H and Predicted char: R\n",
            "Target char: M and Predicted char: K\n",
            "Target char: N and Predicted char: R\n",
            "Target char: O and Predicted char: D\n",
            "Target char: Q and Predicted char: G\n",
            "Target char: S and Predicted char: B\n",
            "Target char: U and Predicted char: L\n",
            "Target char: V and Predicted char: L\n",
            "Target char: W and Predicted char: V\n",
            "Target char: X and Predicted char: Y\n",
            "Target char: Z and Predicted char: T\n"
          ]
        }
      ],
      "source": [
        "ord_charset = []\n",
        "for num in range(0, 26):\n",
        "  ord_charset.append(ord(TEST_SET[num][0]))\n",
        "one_hot = tf.keras.utils.to_categorical(ord_charset, max(ord_charset) + 1)\n",
        "\n",
        "data = test_set\n",
        "labels = one_hot\n",
        "\n",
        "predictions = model.predict(x = data, batch_size = 26, verbose = 0)\n",
        "\n",
        "prediction_array = []\n",
        "rounded_predictions = np.argmax(predictions, axis = -1)\n",
        "for i in rounded_predictions:\n",
        "  prediction_array.append(i)\n",
        "\n",
        "answers_array = []\n",
        "rounded_answers = np.argmax(labels, axis = -1)\n",
        "for i in rounded_answers:\n",
        "  answers_array.append(i)\n",
        "\n",
        "model.evaluate(\n",
        "    data,\n",
        "    labels,\n",
        "    batch_size = 52,\n",
        "    verbose = 2,\n",
        "    sample_weight = None\n",
        ")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Misclassified test images\")\n",
        "for i in range(0, 26):\n",
        "  if answers_array[i] != prediction_array[i]:\n",
        "    print(\"Target char:\", chr(int(answers_array[i])), \"and Predicted char:\", chr(int(prediction_array[i])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLnq3ihEB_Py"
      },
      "source": [
        "**6. How does this model compare with the performance of your perceptron models in Project 1?**\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        ">  *   Our accuracy for MESSAGE from Project 1 ranged from 30-50%, so our accuracy with the model from Project 2 at around 53.85% has higher accuracy.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qFJhbztCSeN"
      },
      "source": [
        "**7. All of the letters in MESSAGE were likely not decoded correctly, so letâ€™s try to improve the performance of the model by adding additional hidden layers. Add two additional hidden layers of the same size as your original hidden layer, then repeat experiments (4) and (5). Does the performance improve?**\n",
        "\n",
        ">  *   The performance drops from around 90.32% to 30.77% accuracy with the addition of two hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh93uNxlWLyU",
        "outputId": "ed64c805-c336-497d-e7e5-112a8073b635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation\n",
            "1/1 - 1s - loss: 0.5820 - accuracy: 0.9032 - 659ms/epoch - 659ms/step\n",
            "\n",
            "Misclassified test images\n",
            "Target char: H and Predicted char: R\n",
            "Target char: X and Predicted char: Y\n",
            "Target char: Z and Predicted char: T\n"
          ]
        }
      ],
      "source": [
        "ord_charset = []\n",
        "msg = list('THEFIVEBOXINGWIZARDSJUMPQUICKLY')\n",
        "for num in range(0, len(msg_set)):\n",
        "  ord_charset.append(ord(msg[num]))\n",
        "one_hot = tf.keras.utils.to_categorical(ord_charset, max(ord_charset) + 1)\n",
        "\n",
        "data = msg_set\n",
        "labels = one_hot\n",
        "\n",
        "predictions = model.predict(x = data, batch_size = 31, verbose = 0)\n",
        "\n",
        "prediction_array = []\n",
        "rounded_predictions = np.argmax(predictions, axis = -1)\n",
        "for i in rounded_predictions:\n",
        "  prediction_array.append(i)\n",
        "\n",
        "answers_array = []\n",
        "rounded_answers = np.argmax(labels, axis = -1)\n",
        "for i in rounded_answers:\n",
        "  answers_array.append(i)\n",
        "\n",
        "print(\"Model Evaluation\")\n",
        "model.evaluate(\n",
        "    data,\n",
        "    labels,\n",
        "    batch_size = 31,\n",
        "    verbose = 2,\n",
        "    sample_weight = None\n",
        ")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Misclassified test images\")\n",
        "for i in range(0, 26):\n",
        "  if answers_array[i] != prediction_array[i]:\n",
        "    print(\"Target char:\", chr(int(answers_array[i])), \"and Predicted char:\", chr(int(prediction_array[i])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Byvw1jmCwle",
        "outputId": "fcc11524-3636-4cd9-8dd8-3ee71ea67f10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 - 1s - loss: 4.5989 - accuracy: 0.0000e+00 - 503ms/epoch - 503ms/step\n",
            "Epoch 2/1000\n",
            "1/1 - 0s - loss: 4.5889 - accuracy: 0.0000e+00 - 6ms/epoch - 6ms/step\n",
            "Epoch 3/1000\n",
            "1/1 - 0s - loss: 4.5790 - accuracy: 0.0000e+00 - 6ms/epoch - 6ms/step\n",
            "Epoch 4/1000\n",
            "1/1 - 0s - loss: 4.5692 - accuracy: 0.0000e+00 - 6ms/epoch - 6ms/step\n",
            "Epoch 5/1000\n",
            "1/1 - 0s - loss: 4.5596 - accuracy: 0.0000e+00 - 7ms/epoch - 7ms/step\n",
            "Epoch 6/1000\n",
            "1/1 - 0s - loss: 4.5501 - accuracy: 0.0000e+00 - 7ms/epoch - 7ms/step\n",
            "Epoch 7/1000\n",
            "1/1 - 0s - loss: 4.5408 - accuracy: 0.0000e+00 - 9ms/epoch - 9ms/step\n",
            "Epoch 8/1000\n",
            "1/1 - 0s - loss: 4.5317 - accuracy: 0.0192 - 13ms/epoch - 13ms/step\n",
            "Epoch 9/1000\n",
            "1/1 - 0s - loss: 4.5228 - accuracy: 0.0192 - 9ms/epoch - 9ms/step\n",
            "Epoch 10/1000\n",
            "1/1 - 0s - loss: 4.5141 - accuracy: 0.0192 - 8ms/epoch - 8ms/step\n",
            "Epoch 11/1000\n",
            "1/1 - 0s - loss: 4.5055 - accuracy: 0.0192 - 7ms/epoch - 7ms/step\n",
            "Epoch 12/1000\n",
            "1/1 - 0s - loss: 4.4971 - accuracy: 0.0192 - 14ms/epoch - 14ms/step\n",
            "Epoch 13/1000\n",
            "1/1 - 0s - loss: 4.4888 - accuracy: 0.0192 - 16ms/epoch - 16ms/step\n",
            "Epoch 14/1000\n",
            "1/1 - 0s - loss: 4.4808 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 15/1000\n",
            "1/1 - 0s - loss: 4.4729 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 16/1000\n",
            "1/1 - 0s - loss: 4.4650 - accuracy: 0.0385 - 7ms/epoch - 7ms/step\n",
            "Epoch 17/1000\n",
            "1/1 - 0s - loss: 4.4574 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 18/1000\n",
            "1/1 - 0s - loss: 4.4498 - accuracy: 0.0385 - 11ms/epoch - 11ms/step\n",
            "Epoch 19/1000\n",
            "1/1 - 0s - loss: 4.4424 - accuracy: 0.0385 - 9ms/epoch - 9ms/step\n",
            "Epoch 20/1000\n",
            "1/1 - 0s - loss: 4.4351 - accuracy: 0.0385 - 9ms/epoch - 9ms/step\n",
            "Epoch 21/1000\n",
            "1/1 - 0s - loss: 4.4279 - accuracy: 0.0385 - 10ms/epoch - 10ms/step\n",
            "Epoch 22/1000\n",
            "1/1 - 0s - loss: 4.4208 - accuracy: 0.0385 - 11ms/epoch - 11ms/step\n",
            "Epoch 23/1000\n",
            "1/1 - 0s - loss: 4.4136 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 24/1000\n",
            "1/1 - 0s - loss: 4.4065 - accuracy: 0.0385 - 17ms/epoch - 17ms/step\n",
            "Epoch 25/1000\n",
            "1/1 - 0s - loss: 4.3994 - accuracy: 0.0385 - 9ms/epoch - 9ms/step\n",
            "Epoch 26/1000\n",
            "1/1 - 0s - loss: 4.3924 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 27/1000\n",
            "1/1 - 0s - loss: 4.3856 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 28/1000\n",
            "1/1 - 0s - loss: 4.3787 - accuracy: 0.0385 - 5ms/epoch - 5ms/step\n",
            "Epoch 29/1000\n",
            "1/1 - 0s - loss: 4.3720 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 30/1000\n",
            "1/1 - 0s - loss: 4.3652 - accuracy: 0.0385 - 7ms/epoch - 7ms/step\n",
            "Epoch 31/1000\n",
            "1/1 - 0s - loss: 4.3584 - accuracy: 0.0385 - 6ms/epoch - 6ms/step\n",
            "Epoch 32/1000\n",
            "1/1 - 0s - loss: 4.3516 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 33/1000\n",
            "1/1 - 0s - loss: 4.3448 - accuracy: 0.0385 - 7ms/epoch - 7ms/step\n",
            "Epoch 34/1000\n",
            "1/1 - 0s - loss: 4.3380 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 35/1000\n",
            "1/1 - 0s - loss: 4.3311 - accuracy: 0.0385 - 8ms/epoch - 8ms/step\n",
            "Epoch 36/1000\n",
            "1/1 - 0s - loss: 4.3242 - accuracy: 0.0577 - 7ms/epoch - 7ms/step\n",
            "Epoch 37/1000\n",
            "1/1 - 0s - loss: 4.3173 - accuracy: 0.0577 - 5ms/epoch - 5ms/step\n",
            "Epoch 38/1000\n",
            "1/1 - 0s - loss: 4.3103 - accuracy: 0.0577 - 5ms/epoch - 5ms/step\n",
            "Epoch 39/1000\n",
            "1/1 - 0s - loss: 4.3032 - accuracy: 0.0577 - 6ms/epoch - 6ms/step\n",
            "Epoch 40/1000\n",
            "1/1 - 0s - loss: 4.2961 - accuracy: 0.0577 - 8ms/epoch - 8ms/step\n",
            "Epoch 41/1000\n",
            "1/1 - 0s - loss: 4.2890 - accuracy: 0.0577 - 6ms/epoch - 6ms/step\n",
            "Epoch 42/1000\n",
            "1/1 - 0s - loss: 4.2817 - accuracy: 0.0769 - 11ms/epoch - 11ms/step\n",
            "Epoch 43/1000\n",
            "1/1 - 0s - loss: 4.2744 - accuracy: 0.0769 - 8ms/epoch - 8ms/step\n",
            "Epoch 44/1000\n",
            "1/1 - 0s - loss: 4.2669 - accuracy: 0.0769 - 7ms/epoch - 7ms/step\n",
            "Epoch 45/1000\n",
            "1/1 - 0s - loss: 4.2592 - accuracy: 0.0769 - 7ms/epoch - 7ms/step\n",
            "Epoch 46/1000\n",
            "1/1 - 0s - loss: 4.2515 - accuracy: 0.0769 - 6ms/epoch - 6ms/step\n",
            "Epoch 47/1000\n",
            "1/1 - 0s - loss: 4.2438 - accuracy: 0.0769 - 11ms/epoch - 11ms/step\n",
            "Epoch 48/1000\n",
            "1/1 - 0s - loss: 4.2360 - accuracy: 0.0769 - 8ms/epoch - 8ms/step\n",
            "Epoch 49/1000\n",
            "1/1 - 0s - loss: 4.2281 - accuracy: 0.0962 - 10ms/epoch - 10ms/step\n",
            "Epoch 50/1000\n",
            "1/1 - 0s - loss: 4.2201 - accuracy: 0.1154 - 7ms/epoch - 7ms/step\n",
            "Epoch 51/1000\n",
            "1/1 - 0s - loss: 4.2119 - accuracy: 0.1154 - 10ms/epoch - 10ms/step\n",
            "Epoch 52/1000\n",
            "1/1 - 0s - loss: 4.2037 - accuracy: 0.1154 - 7ms/epoch - 7ms/step\n",
            "Epoch 53/1000\n",
            "1/1 - 0s - loss: 4.1954 - accuracy: 0.1154 - 9ms/epoch - 9ms/step\n",
            "Epoch 54/1000\n",
            "1/1 - 0s - loss: 4.1870 - accuracy: 0.1346 - 14ms/epoch - 14ms/step\n",
            "Epoch 55/1000\n",
            "1/1 - 0s - loss: 4.1785 - accuracy: 0.1346 - 9ms/epoch - 9ms/step\n",
            "Epoch 56/1000\n",
            "1/1 - 0s - loss: 4.1699 - accuracy: 0.1346 - 15ms/epoch - 15ms/step\n",
            "Epoch 57/1000\n",
            "1/1 - 0s - loss: 4.1612 - accuracy: 0.1346 - 8ms/epoch - 8ms/step\n",
            "Epoch 58/1000\n",
            "1/1 - 0s - loss: 4.1523 - accuracy: 0.1346 - 14ms/epoch - 14ms/step\n",
            "Epoch 59/1000\n",
            "1/1 - 0s - loss: 4.1433 - accuracy: 0.1346 - 10ms/epoch - 10ms/step\n",
            "Epoch 60/1000\n",
            "1/1 - 0s - loss: 4.1342 - accuracy: 0.1346 - 13ms/epoch - 13ms/step\n",
            "Epoch 61/1000\n",
            "1/1 - 0s - loss: 4.1248 - accuracy: 0.1346 - 8ms/epoch - 8ms/step\n",
            "Epoch 62/1000\n",
            "1/1 - 0s - loss: 4.1154 - accuracy: 0.1346 - 12ms/epoch - 12ms/step\n",
            "Epoch 63/1000\n",
            "1/1 - 0s - loss: 4.1059 - accuracy: 0.1346 - 8ms/epoch - 8ms/step\n",
            "Epoch 64/1000\n",
            "1/1 - 0s - loss: 4.0962 - accuracy: 0.1346 - 12ms/epoch - 12ms/step\n",
            "Epoch 65/1000\n",
            "1/1 - 0s - loss: 4.0863 - accuracy: 0.1346 - 8ms/epoch - 8ms/step\n",
            "Epoch 66/1000\n",
            "1/1 - 0s - loss: 4.0763 - accuracy: 0.1346 - 7ms/epoch - 7ms/step\n",
            "Epoch 67/1000\n",
            "1/1 - 0s - loss: 4.0661 - accuracy: 0.1346 - 13ms/epoch - 13ms/step\n",
            "Epoch 68/1000\n",
            "1/1 - 0s - loss: 4.0556 - accuracy: 0.1346 - 8ms/epoch - 8ms/step\n",
            "Epoch 69/1000\n",
            "1/1 - 0s - loss: 4.0449 - accuracy: 0.1538 - 8ms/epoch - 8ms/step\n",
            "Epoch 70/1000\n",
            "1/1 - 0s - loss: 4.0341 - accuracy: 0.1538 - 12ms/epoch - 12ms/step\n",
            "Epoch 71/1000\n",
            "1/1 - 0s - loss: 4.0229 - accuracy: 0.1538 - 9ms/epoch - 9ms/step\n",
            "Epoch 72/1000\n",
            "1/1 - 0s - loss: 4.0115 - accuracy: 0.1538 - 14ms/epoch - 14ms/step\n",
            "Epoch 73/1000\n",
            "1/1 - 0s - loss: 4.0000 - accuracy: 0.1538 - 10ms/epoch - 10ms/step\n",
            "Epoch 74/1000\n",
            "1/1 - 0s - loss: 3.9882 - accuracy: 0.1538 - 18ms/epoch - 18ms/step\n",
            "Epoch 75/1000\n",
            "1/1 - 0s - loss: 3.9763 - accuracy: 0.1538 - 10ms/epoch - 10ms/step\n",
            "Epoch 76/1000\n",
            "1/1 - 0s - loss: 3.9641 - accuracy: 0.1538 - 14ms/epoch - 14ms/step\n",
            "Epoch 77/1000\n",
            "1/1 - 0s - loss: 3.9516 - accuracy: 0.1538 - 11ms/epoch - 11ms/step\n",
            "Epoch 78/1000\n",
            "1/1 - 0s - loss: 3.9390 - accuracy: 0.1538 - 9ms/epoch - 9ms/step\n",
            "Epoch 79/1000\n",
            "1/1 - 0s - loss: 3.9263 - accuracy: 0.1538 - 10ms/epoch - 10ms/step\n",
            "Epoch 80/1000\n",
            "1/1 - 0s - loss: 3.9133 - accuracy: 0.1538 - 13ms/epoch - 13ms/step\n",
            "Epoch 81/1000\n",
            "1/1 - 0s - loss: 3.9001 - accuracy: 0.1538 - 8ms/epoch - 8ms/step\n",
            "Epoch 82/1000\n",
            "1/1 - 0s - loss: 3.8866 - accuracy: 0.1538 - 8ms/epoch - 8ms/step\n",
            "Epoch 83/1000\n",
            "1/1 - 0s - loss: 3.8730 - accuracy: 0.1538 - 13ms/epoch - 13ms/step\n",
            "Epoch 84/1000\n",
            "1/1 - 0s - loss: 3.8592 - accuracy: 0.1538 - 8ms/epoch - 8ms/step\n",
            "Epoch 85/1000\n",
            "1/1 - 0s - loss: 3.8451 - accuracy: 0.1538 - 19ms/epoch - 19ms/step\n",
            "Epoch 86/1000\n",
            "1/1 - 0s - loss: 3.8308 - accuracy: 0.1538 - 14ms/epoch - 14ms/step\n",
            "Epoch 87/1000\n",
            "1/1 - 0s - loss: 3.8163 - accuracy: 0.1538 - 13ms/epoch - 13ms/step\n",
            "Epoch 88/1000\n",
            "1/1 - 0s - loss: 3.8016 - accuracy: 0.1923 - 13ms/epoch - 13ms/step\n",
            "Epoch 89/1000\n",
            "1/1 - 0s - loss: 3.7868 - accuracy: 0.1923 - 10ms/epoch - 10ms/step\n",
            "Epoch 90/1000\n",
            "1/1 - 0s - loss: 3.7717 - accuracy: 0.1923 - 12ms/epoch - 12ms/step\n",
            "Epoch 91/1000\n",
            "1/1 - 0s - loss: 3.7563 - accuracy: 0.2115 - 12ms/epoch - 12ms/step\n",
            "Epoch 92/1000\n",
            "1/1 - 0s - loss: 3.7407 - accuracy: 0.2115 - 9ms/epoch - 9ms/step\n",
            "Epoch 93/1000\n",
            "1/1 - 0s - loss: 3.7249 - accuracy: 0.2115 - 13ms/epoch - 13ms/step\n",
            "Epoch 94/1000\n",
            "1/1 - 0s - loss: 3.7089 - accuracy: 0.2115 - 9ms/epoch - 9ms/step\n",
            "Epoch 95/1000\n",
            "1/1 - 0s - loss: 3.6927 - accuracy: 0.2115 - 18ms/epoch - 18ms/step\n",
            "Epoch 96/1000\n",
            "1/1 - 0s - loss: 3.6762 - accuracy: 0.2115 - 9ms/epoch - 9ms/step\n",
            "Epoch 97/1000\n",
            "1/1 - 0s - loss: 3.6595 - accuracy: 0.2115 - 10ms/epoch - 10ms/step\n",
            "Epoch 98/1000\n",
            "1/1 - 0s - loss: 3.6427 - accuracy: 0.2115 - 8ms/epoch - 8ms/step\n",
            "Epoch 99/1000\n",
            "1/1 - 0s - loss: 3.6258 - accuracy: 0.2115 - 11ms/epoch - 11ms/step\n",
            "Epoch 100/1000\n",
            "1/1 - 0s - loss: 3.6088 - accuracy: 0.2115 - 13ms/epoch - 13ms/step\n",
            "Epoch 101/1000\n",
            "1/1 - 0s - loss: 3.5916 - accuracy: 0.2115 - 10ms/epoch - 10ms/step\n",
            "Epoch 102/1000\n",
            "1/1 - 0s - loss: 3.5742 - accuracy: 0.2115 - 11ms/epoch - 11ms/step\n",
            "Epoch 103/1000\n",
            "1/1 - 0s - loss: 3.5569 - accuracy: 0.2115 - 11ms/epoch - 11ms/step\n",
            "Epoch 104/1000\n",
            "1/1 - 0s - loss: 3.5393 - accuracy: 0.2115 - 10ms/epoch - 10ms/step\n",
            "Epoch 105/1000\n",
            "1/1 - 0s - loss: 3.5216 - accuracy: 0.2308 - 11ms/epoch - 11ms/step\n",
            "Epoch 106/1000\n",
            "1/1 - 0s - loss: 3.5038 - accuracy: 0.2308 - 10ms/epoch - 10ms/step\n",
            "Epoch 107/1000\n",
            "1/1 - 0s - loss: 3.4858 - accuracy: 0.2308 - 12ms/epoch - 12ms/step\n",
            "Epoch 108/1000\n",
            "1/1 - 0s - loss: 3.4676 - accuracy: 0.2308 - 12ms/epoch - 12ms/step\n",
            "Epoch 109/1000\n",
            "1/1 - 0s - loss: 3.4493 - accuracy: 0.2308 - 11ms/epoch - 11ms/step\n",
            "Epoch 110/1000\n",
            "1/1 - 0s - loss: 3.4308 - accuracy: 0.2308 - 13ms/epoch - 13ms/step\n",
            "Epoch 111/1000\n",
            "1/1 - 0s - loss: 3.4122 - accuracy: 0.2308 - 10ms/epoch - 10ms/step\n",
            "Epoch 112/1000\n",
            "1/1 - 0s - loss: 3.3934 - accuracy: 0.2308 - 8ms/epoch - 8ms/step\n",
            "Epoch 113/1000\n",
            "1/1 - 0s - loss: 3.3745 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 114/1000\n",
            "1/1 - 0s - loss: 3.3554 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 115/1000\n",
            "1/1 - 0s - loss: 3.3363 - accuracy: 0.2500 - 18ms/epoch - 18ms/step\n",
            "Epoch 116/1000\n",
            "1/1 - 0s - loss: 3.3170 - accuracy: 0.2500 - 8ms/epoch - 8ms/step\n",
            "Epoch 117/1000\n",
            "1/1 - 0s - loss: 3.2976 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 118/1000\n",
            "1/1 - 0s - loss: 3.2783 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 119/1000\n",
            "1/1 - 0s - loss: 3.2588 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 120/1000\n",
            "1/1 - 0s - loss: 3.2392 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 121/1000\n",
            "1/1 - 0s - loss: 3.2195 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 122/1000\n",
            "1/1 - 0s - loss: 3.1997 - accuracy: 0.2500 - 9ms/epoch - 9ms/step\n",
            "Epoch 123/1000\n",
            "1/1 - 0s - loss: 3.1799 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 124/1000\n",
            "1/1 - 0s - loss: 3.1600 - accuracy: 0.2500 - 8ms/epoch - 8ms/step\n",
            "Epoch 125/1000\n",
            "1/1 - 0s - loss: 3.1402 - accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
            "Epoch 126/1000\n",
            "1/1 - 0s - loss: 3.1203 - accuracy: 0.2500 - 8ms/epoch - 8ms/step\n",
            "Epoch 127/1000\n",
            "1/1 - 0s - loss: 3.1002 - accuracy: 0.2500 - 7ms/epoch - 7ms/step\n",
            "Epoch 128/1000\n",
            "1/1 - 0s - loss: 3.0800 - accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 129/1000\n",
            "1/1 - 0s - loss: 3.0598 - accuracy: 0.2500 - 10ms/epoch - 10ms/step\n",
            "Epoch 130/1000\n",
            "1/1 - 0s - loss: 3.0395 - accuracy: 0.2692 - 12ms/epoch - 12ms/step\n",
            "Epoch 131/1000\n",
            "1/1 - 0s - loss: 3.0191 - accuracy: 0.2692 - 9ms/epoch - 9ms/step\n",
            "Epoch 132/1000\n",
            "1/1 - 0s - loss: 2.9986 - accuracy: 0.2692 - 10ms/epoch - 10ms/step\n",
            "Epoch 133/1000\n",
            "1/1 - 0s - loss: 2.9781 - accuracy: 0.2692 - 9ms/epoch - 9ms/step\n",
            "Epoch 134/1000\n",
            "1/1 - 0s - loss: 2.9575 - accuracy: 0.2692 - 10ms/epoch - 10ms/step\n",
            "Epoch 135/1000\n",
            "1/1 - 0s - loss: 2.9369 - accuracy: 0.2692 - 7ms/epoch - 7ms/step\n",
            "Epoch 136/1000\n",
            "1/1 - 0s - loss: 2.9162 - accuracy: 0.2692 - 7ms/epoch - 7ms/step\n",
            "Epoch 137/1000\n",
            "1/1 - 0s - loss: 2.8954 - accuracy: 0.2885 - 6ms/epoch - 6ms/step\n",
            "Epoch 138/1000\n",
            "1/1 - 0s - loss: 2.8745 - accuracy: 0.3077 - 8ms/epoch - 8ms/step\n",
            "Epoch 139/1000\n",
            "1/1 - 0s - loss: 2.8536 - accuracy: 0.3462 - 8ms/epoch - 8ms/step\n",
            "Epoch 140/1000\n",
            "1/1 - 0s - loss: 2.8327 - accuracy: 0.3462 - 9ms/epoch - 9ms/step\n",
            "Epoch 141/1000\n",
            "1/1 - 0s - loss: 2.8118 - accuracy: 0.3462 - 7ms/epoch - 7ms/step\n",
            "Epoch 142/1000\n",
            "1/1 - 0s - loss: 2.7908 - accuracy: 0.3654 - 9ms/epoch - 9ms/step\n",
            "Epoch 143/1000\n",
            "1/1 - 0s - loss: 2.7697 - accuracy: 0.3654 - 8ms/epoch - 8ms/step\n",
            "Epoch 144/1000\n",
            "1/1 - 0s - loss: 2.7487 - accuracy: 0.3654 - 8ms/epoch - 8ms/step\n",
            "Epoch 145/1000\n",
            "1/1 - 0s - loss: 2.7277 - accuracy: 0.3654 - 8ms/epoch - 8ms/step\n",
            "Epoch 146/1000\n",
            "1/1 - 0s - loss: 2.7066 - accuracy: 0.3654 - 8ms/epoch - 8ms/step\n",
            "Epoch 147/1000\n",
            "1/1 - 0s - loss: 2.6855 - accuracy: 0.3654 - 7ms/epoch - 7ms/step\n",
            "Epoch 148/1000\n",
            "1/1 - 0s - loss: 2.6645 - accuracy: 0.3846 - 8ms/epoch - 8ms/step\n",
            "Epoch 149/1000\n",
            "1/1 - 0s - loss: 2.6434 - accuracy: 0.4038 - 8ms/epoch - 8ms/step\n",
            "Epoch 150/1000\n",
            "1/1 - 0s - loss: 2.6224 - accuracy: 0.4423 - 7ms/epoch - 7ms/step\n",
            "Epoch 151/1000\n",
            "1/1 - 0s - loss: 2.6016 - accuracy: 0.4423 - 8ms/epoch - 8ms/step\n",
            "Epoch 152/1000\n",
            "1/1 - 0s - loss: 2.5808 - accuracy: 0.4808 - 12ms/epoch - 12ms/step\n",
            "Epoch 153/1000\n",
            "1/1 - 0s - loss: 2.5603 - accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 154/1000\n",
            "1/1 - 0s - loss: 2.5398 - accuracy: 0.5385 - 8ms/epoch - 8ms/step\n",
            "Epoch 155/1000\n",
            "1/1 - 0s - loss: 2.5192 - accuracy: 0.5385 - 8ms/epoch - 8ms/step\n",
            "Epoch 156/1000\n",
            "1/1 - 0s - loss: 2.4985 - accuracy: 0.5385 - 10ms/epoch - 10ms/step\n",
            "Epoch 157/1000\n",
            "1/1 - 0s - loss: 2.4779 - accuracy: 0.5577 - 8ms/epoch - 8ms/step\n",
            "Epoch 158/1000\n",
            "1/1 - 0s - loss: 2.4573 - accuracy: 0.5577 - 8ms/epoch - 8ms/step\n",
            "Epoch 159/1000\n",
            "1/1 - 0s - loss: 2.4368 - accuracy: 0.5577 - 8ms/epoch - 8ms/step\n",
            "Epoch 160/1000\n",
            "1/1 - 0s - loss: 2.4163 - accuracy: 0.5577 - 8ms/epoch - 8ms/step\n",
            "Epoch 161/1000\n",
            "1/1 - 0s - loss: 2.3959 - accuracy: 0.5577 - 15ms/epoch - 15ms/step\n",
            "Epoch 162/1000\n",
            "1/1 - 0s - loss: 2.3757 - accuracy: 0.5577 - 11ms/epoch - 11ms/step\n",
            "Epoch 163/1000\n",
            "1/1 - 0s - loss: 2.3554 - accuracy: 0.5577 - 7ms/epoch - 7ms/step\n",
            "Epoch 164/1000\n",
            "1/1 - 0s - loss: 2.3353 - accuracy: 0.5577 - 19ms/epoch - 19ms/step\n",
            "Epoch 165/1000\n",
            "1/1 - 0s - loss: 2.3152 - accuracy: 0.5769 - 8ms/epoch - 8ms/step\n",
            "Epoch 166/1000\n",
            "1/1 - 0s - loss: 2.2953 - accuracy: 0.5962 - 11ms/epoch - 11ms/step\n",
            "Epoch 167/1000\n",
            "1/1 - 0s - loss: 2.2755 - accuracy: 0.5962 - 12ms/epoch - 12ms/step\n",
            "Epoch 168/1000\n",
            "1/1 - 0s - loss: 2.2557 - accuracy: 0.6346 - 8ms/epoch - 8ms/step\n",
            "Epoch 169/1000\n",
            "1/1 - 0s - loss: 2.2358 - accuracy: 0.6538 - 9ms/epoch - 9ms/step\n",
            "Epoch 170/1000\n",
            "1/1 - 0s - loss: 2.2162 - accuracy: 0.6731 - 10ms/epoch - 10ms/step\n",
            "Epoch 171/1000\n",
            "1/1 - 0s - loss: 2.1967 - accuracy: 0.6731 - 10ms/epoch - 10ms/step\n",
            "Epoch 172/1000\n",
            "1/1 - 0s - loss: 2.1776 - accuracy: 0.6731 - 10ms/epoch - 10ms/step\n",
            "Epoch 173/1000\n",
            "1/1 - 0s - loss: 2.1585 - accuracy: 0.6731 - 11ms/epoch - 11ms/step\n",
            "Epoch 174/1000\n",
            "1/1 - 0s - loss: 2.1396 - accuracy: 0.6538 - 9ms/epoch - 9ms/step\n",
            "Epoch 175/1000\n",
            "1/1 - 0s - loss: 2.1208 - accuracy: 0.6731 - 10ms/epoch - 10ms/step\n",
            "Epoch 176/1000\n",
            "1/1 - 0s - loss: 2.1021 - accuracy: 0.6731 - 10ms/epoch - 10ms/step\n",
            "Epoch 177/1000\n",
            "1/1 - 0s - loss: 2.0835 - accuracy: 0.6731 - 11ms/epoch - 11ms/step\n",
            "Epoch 178/1000\n",
            "1/1 - 0s - loss: 2.0651 - accuracy: 0.6923 - 10ms/epoch - 10ms/step\n",
            "Epoch 179/1000\n",
            "1/1 - 0s - loss: 2.0467 - accuracy: 0.6923 - 10ms/epoch - 10ms/step\n",
            "Epoch 180/1000\n",
            "1/1 - 0s - loss: 2.0285 - accuracy: 0.6923 - 10ms/epoch - 10ms/step\n",
            "Epoch 181/1000\n",
            "1/1 - 0s - loss: 2.0104 - accuracy: 0.6923 - 10ms/epoch - 10ms/step\n",
            "Epoch 182/1000\n",
            "1/1 - 0s - loss: 1.9926 - accuracy: 0.6923 - 9ms/epoch - 9ms/step\n",
            "Epoch 183/1000\n",
            "1/1 - 0s - loss: 1.9749 - accuracy: 0.6923 - 12ms/epoch - 12ms/step\n",
            "Epoch 184/1000\n",
            "1/1 - 0s - loss: 1.9574 - accuracy: 0.7115 - 11ms/epoch - 11ms/step\n",
            "Epoch 185/1000\n",
            "1/1 - 0s - loss: 1.9400 - accuracy: 0.7115 - 8ms/epoch - 8ms/step\n",
            "Epoch 186/1000\n",
            "1/1 - 0s - loss: 1.9226 - accuracy: 0.7308 - 10ms/epoch - 10ms/step\n",
            "Epoch 187/1000\n",
            "1/1 - 0s - loss: 1.9053 - accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
            "Epoch 188/1000\n",
            "1/1 - 0s - loss: 1.8881 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
            "Epoch 189/1000\n",
            "1/1 - 0s - loss: 1.8710 - accuracy: 0.7692 - 12ms/epoch - 12ms/step\n",
            "Epoch 190/1000\n",
            "1/1 - 0s - loss: 1.8540 - accuracy: 0.7692 - 11ms/epoch - 11ms/step\n",
            "Epoch 191/1000\n",
            "1/1 - 0s - loss: 1.8372 - accuracy: 0.7692 - 10ms/epoch - 10ms/step\n",
            "Epoch 192/1000\n",
            "1/1 - 0s - loss: 1.8205 - accuracy: 0.7692 - 11ms/epoch - 11ms/step\n",
            "Epoch 193/1000\n",
            "1/1 - 0s - loss: 1.8038 - accuracy: 0.7692 - 8ms/epoch - 8ms/step\n",
            "Epoch 194/1000\n",
            "1/1 - 0s - loss: 1.7874 - accuracy: 0.7692 - 8ms/epoch - 8ms/step\n",
            "Epoch 195/1000\n",
            "1/1 - 0s - loss: 1.7711 - accuracy: 0.7885 - 12ms/epoch - 12ms/step\n",
            "Epoch 196/1000\n",
            "1/1 - 0s - loss: 1.7549 - accuracy: 0.7885 - 8ms/epoch - 8ms/step\n",
            "Epoch 197/1000\n",
            "1/1 - 0s - loss: 1.7389 - accuracy: 0.7885 - 8ms/epoch - 8ms/step\n",
            "Epoch 198/1000\n",
            "1/1 - 0s - loss: 1.7229 - accuracy: 0.7885 - 11ms/epoch - 11ms/step\n",
            "Epoch 199/1000\n",
            "1/1 - 0s - loss: 1.7070 - accuracy: 0.7885 - 10ms/epoch - 10ms/step\n",
            "Epoch 200/1000\n",
            "1/1 - 0s - loss: 1.6911 - accuracy: 0.8077 - 8ms/epoch - 8ms/step\n",
            "Epoch 201/1000\n",
            "1/1 - 0s - loss: 1.6753 - accuracy: 0.8077 - 12ms/epoch - 12ms/step\n",
            "Epoch 202/1000\n",
            "1/1 - 0s - loss: 1.6597 - accuracy: 0.8077 - 14ms/epoch - 14ms/step\n",
            "Epoch 203/1000\n",
            "1/1 - 0s - loss: 1.6443 - accuracy: 0.8077 - 9ms/epoch - 9ms/step\n",
            "Epoch 204/1000\n",
            "1/1 - 0s - loss: 1.6290 - accuracy: 0.8269 - 9ms/epoch - 9ms/step\n",
            "Epoch 205/1000\n",
            "1/1 - 0s - loss: 1.6136 - accuracy: 0.8269 - 8ms/epoch - 8ms/step\n",
            "Epoch 206/1000\n",
            "1/1 - 0s - loss: 1.5985 - accuracy: 0.8269 - 8ms/epoch - 8ms/step\n",
            "Epoch 207/1000\n",
            "1/1 - 0s - loss: 1.5834 - accuracy: 0.8462 - 16ms/epoch - 16ms/step\n",
            "Epoch 208/1000\n",
            "1/1 - 0s - loss: 1.5685 - accuracy: 0.8462 - 12ms/epoch - 12ms/step\n",
            "Epoch 209/1000\n",
            "1/1 - 0s - loss: 1.5536 - accuracy: 0.8462 - 11ms/epoch - 11ms/step\n",
            "Epoch 210/1000\n",
            "1/1 - 0s - loss: 1.5387 - accuracy: 0.8462 - 8ms/epoch - 8ms/step\n",
            "Epoch 211/1000\n",
            "1/1 - 0s - loss: 1.5239 - accuracy: 0.8462 - 10ms/epoch - 10ms/step\n",
            "Epoch 212/1000\n",
            "1/1 - 0s - loss: 1.5092 - accuracy: 0.8462 - 8ms/epoch - 8ms/step\n",
            "Epoch 213/1000\n",
            "1/1 - 0s - loss: 1.4946 - accuracy: 0.8462 - 7ms/epoch - 7ms/step\n",
            "Epoch 214/1000\n",
            "1/1 - 0s - loss: 1.4801 - accuracy: 0.8654 - 8ms/epoch - 8ms/step\n",
            "Epoch 215/1000\n",
            "1/1 - 0s - loss: 1.4657 - accuracy: 0.8654 - 10ms/epoch - 10ms/step\n",
            "Epoch 216/1000\n",
            "1/1 - 0s - loss: 1.4514 - accuracy: 0.8654 - 6ms/epoch - 6ms/step\n",
            "Epoch 217/1000\n",
            "1/1 - 0s - loss: 1.4371 - accuracy: 0.8654 - 8ms/epoch - 8ms/step\n",
            "Epoch 218/1000\n",
            "1/1 - 0s - loss: 1.4231 - accuracy: 0.8654 - 13ms/epoch - 13ms/step\n",
            "Epoch 219/1000\n",
            "1/1 - 0s - loss: 1.4091 - accuracy: 0.8654 - 8ms/epoch - 8ms/step\n",
            "Epoch 220/1000\n",
            "1/1 - 0s - loss: 1.3953 - accuracy: 0.8846 - 11ms/epoch - 11ms/step\n",
            "Epoch 221/1000\n",
            "1/1 - 0s - loss: 1.3816 - accuracy: 0.9038 - 8ms/epoch - 8ms/step\n",
            "Epoch 222/1000\n",
            "1/1 - 0s - loss: 1.3679 - accuracy: 0.9038 - 11ms/epoch - 11ms/step\n",
            "Epoch 223/1000\n",
            "1/1 - 0s - loss: 1.3544 - accuracy: 0.9038 - 9ms/epoch - 9ms/step\n",
            "Epoch 224/1000\n",
            "1/1 - 0s - loss: 1.3411 - accuracy: 0.9038 - 7ms/epoch - 7ms/step\n",
            "Epoch 225/1000\n",
            "1/1 - 0s - loss: 1.3278 - accuracy: 0.9038 - 7ms/epoch - 7ms/step\n",
            "Epoch 226/1000\n",
            "1/1 - 0s - loss: 1.3146 - accuracy: 0.9038 - 8ms/epoch - 8ms/step\n",
            "Epoch 227/1000\n",
            "1/1 - 0s - loss: 1.3016 - accuracy: 0.9038 - 11ms/epoch - 11ms/step\n",
            "Epoch 228/1000\n",
            "1/1 - 0s - loss: 1.2887 - accuracy: 0.9038 - 11ms/epoch - 11ms/step\n",
            "Epoch 229/1000\n",
            "1/1 - 0s - loss: 1.2759 - accuracy: 0.9038 - 8ms/epoch - 8ms/step\n",
            "Epoch 230/1000\n",
            "1/1 - 0s - loss: 1.2632 - accuracy: 0.9038 - 18ms/epoch - 18ms/step\n",
            "Epoch 231/1000\n",
            "1/1 - 0s - loss: 1.2506 - accuracy: 0.9038 - 11ms/epoch - 11ms/step\n",
            "Epoch 232/1000\n",
            "1/1 - 0s - loss: 1.2381 - accuracy: 0.9038 - 12ms/epoch - 12ms/step\n",
            "Epoch 233/1000\n",
            "1/1 - 0s - loss: 1.2257 - accuracy: 0.9038 - 9ms/epoch - 9ms/step\n",
            "Epoch 234/1000\n",
            "1/1 - 0s - loss: 1.2134 - accuracy: 0.9231 - 21ms/epoch - 21ms/step\n",
            "Epoch 235/1000\n",
            "1/1 - 0s - loss: 1.2012 - accuracy: 0.9231 - 12ms/epoch - 12ms/step\n",
            "Epoch 236/1000\n",
            "1/1 - 0s - loss: 1.1891 - accuracy: 0.9231 - 8ms/epoch - 8ms/step\n",
            "Epoch 237/1000\n",
            "1/1 - 0s - loss: 1.1771 - accuracy: 0.9423 - 11ms/epoch - 11ms/step\n",
            "Epoch 238/1000\n",
            "1/1 - 0s - loss: 1.1653 - accuracy: 0.9423 - 10ms/epoch - 10ms/step\n",
            "Epoch 239/1000\n",
            "1/1 - 0s - loss: 1.1536 - accuracy: 0.9423 - 11ms/epoch - 11ms/step\n",
            "Epoch 240/1000\n",
            "1/1 - 0s - loss: 1.1420 - accuracy: 0.9423 - 13ms/epoch - 13ms/step\n",
            "Epoch 241/1000\n",
            "1/1 - 0s - loss: 1.1304 - accuracy: 0.9423 - 11ms/epoch - 11ms/step\n",
            "Epoch 242/1000\n",
            "1/1 - 0s - loss: 1.1189 - accuracy: 0.9423 - 7ms/epoch - 7ms/step\n",
            "Epoch 243/1000\n",
            "1/1 - 0s - loss: 1.1076 - accuracy: 0.9423 - 9ms/epoch - 9ms/step\n",
            "Epoch 244/1000\n",
            "1/1 - 0s - loss: 1.0964 - accuracy: 0.9423 - 9ms/epoch - 9ms/step\n",
            "Epoch 245/1000\n",
            "1/1 - 0s - loss: 1.0853 - accuracy: 0.9423 - 9ms/epoch - 9ms/step\n",
            "Epoch 246/1000\n",
            "1/1 - 0s - loss: 1.0743 - accuracy: 0.9423 - 13ms/epoch - 13ms/step\n",
            "Epoch 247/1000\n",
            "1/1 - 0s - loss: 1.0634 - accuracy: 0.9423 - 8ms/epoch - 8ms/step\n",
            "Epoch 248/1000\n",
            "1/1 - 0s - loss: 1.0526 - accuracy: 0.9423 - 10ms/epoch - 10ms/step\n",
            "Epoch 249/1000\n",
            "1/1 - 0s - loss: 1.0419 - accuracy: 0.9423 - 10ms/epoch - 10ms/step\n",
            "Epoch 250/1000\n",
            "1/1 - 0s - loss: 1.0314 - accuracy: 0.9423 - 10ms/epoch - 10ms/step\n",
            "Epoch 251/1000\n",
            "1/1 - 0s - loss: 1.0210 - accuracy: 0.9423 - 17ms/epoch - 17ms/step\n",
            "Epoch 252/1000\n",
            "1/1 - 0s - loss: 1.0108 - accuracy: 0.9423 - 13ms/epoch - 13ms/step\n",
            "Epoch 253/1000\n",
            "1/1 - 0s - loss: 1.0006 - accuracy: 0.9423 - 11ms/epoch - 11ms/step\n",
            "Epoch 254/1000\n",
            "1/1 - 0s - loss: 0.9906 - accuracy: 0.9423 - 10ms/epoch - 10ms/step\n",
            "Epoch 255/1000\n",
            "1/1 - 0s - loss: 0.9807 - accuracy: 0.9423 - 8ms/epoch - 8ms/step\n",
            "Epoch 256/1000\n",
            "1/1 - 0s - loss: 0.9709 - accuracy: 0.9423 - 10ms/epoch - 10ms/step\n",
            "Epoch 257/1000\n",
            "1/1 - 0s - loss: 0.9612 - accuracy: 0.9423 - 8ms/epoch - 8ms/step\n",
            "Epoch 258/1000\n",
            "1/1 - 0s - loss: 0.9516 - accuracy: 0.9423 - 10ms/epoch - 10ms/step\n",
            "Epoch 259/1000\n",
            "1/1 - 0s - loss: 0.9421 - accuracy: 0.9423 - 9ms/epoch - 9ms/step\n",
            "Epoch 260/1000\n",
            "1/1 - 0s - loss: 0.9327 - accuracy: 0.9423 - 11ms/epoch - 11ms/step\n",
            "Epoch 261/1000\n",
            "1/1 - 0s - loss: 0.9234 - accuracy: 0.9423 - 9ms/epoch - 9ms/step\n",
            "Epoch 262/1000\n",
            "1/1 - 0s - loss: 0.9141 - accuracy: 0.9615 - 14ms/epoch - 14ms/step\n",
            "Epoch 263/1000\n",
            "1/1 - 0s - loss: 0.9050 - accuracy: 0.9615 - 12ms/epoch - 12ms/step\n",
            "Epoch 264/1000\n",
            "1/1 - 0s - loss: 0.8959 - accuracy: 0.9615 - 10ms/epoch - 10ms/step\n",
            "Epoch 265/1000\n",
            "1/1 - 0s - loss: 0.8869 - accuracy: 0.9615 - 10ms/epoch - 10ms/step\n",
            "Epoch 266/1000\n",
            "1/1 - 0s - loss: 0.8779 - accuracy: 0.9615 - 10ms/epoch - 10ms/step\n",
            "Epoch 267/1000\n",
            "1/1 - 0s - loss: 0.8690 - accuracy: 0.9615 - 9ms/epoch - 9ms/step\n",
            "Epoch 268/1000\n",
            "1/1 - 0s - loss: 0.8601 - accuracy: 0.9615 - 13ms/epoch - 13ms/step\n",
            "Epoch 269/1000\n",
            "1/1 - 0s - loss: 0.8514 - accuracy: 0.9615 - 9ms/epoch - 9ms/step\n",
            "Epoch 270/1000\n",
            "1/1 - 0s - loss: 0.8427 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 271/1000\n",
            "1/1 - 0s - loss: 0.8340 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 272/1000\n",
            "1/1 - 0s - loss: 0.8255 - accuracy: 0.9615 - 9ms/epoch - 9ms/step\n",
            "Epoch 273/1000\n",
            "1/1 - 0s - loss: 0.8171 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 274/1000\n",
            "1/1 - 0s - loss: 0.8087 - accuracy: 0.9615 - 12ms/epoch - 12ms/step\n",
            "Epoch 275/1000\n",
            "1/1 - 0s - loss: 0.8004 - accuracy: 0.9615 - 20ms/epoch - 20ms/step\n",
            "Epoch 276/1000\n",
            "1/1 - 0s - loss: 0.7922 - accuracy: 0.9615 - 14ms/epoch - 14ms/step\n",
            "Epoch 277/1000\n",
            "1/1 - 0s - loss: 0.7841 - accuracy: 0.9615 - 9ms/epoch - 9ms/step\n",
            "Epoch 278/1000\n",
            "1/1 - 0s - loss: 0.7761 - accuracy: 0.9615 - 16ms/epoch - 16ms/step\n",
            "Epoch 279/1000\n",
            "1/1 - 0s - loss: 0.7681 - accuracy: 0.9615 - 7ms/epoch - 7ms/step\n",
            "Epoch 280/1000\n",
            "1/1 - 0s - loss: 0.7602 - accuracy: 0.9615 - 17ms/epoch - 17ms/step\n",
            "Epoch 281/1000\n",
            "1/1 - 0s - loss: 0.7524 - accuracy: 0.9615 - 6ms/epoch - 6ms/step\n",
            "Epoch 282/1000\n",
            "1/1 - 0s - loss: 0.7448 - accuracy: 0.9615 - 8ms/epoch - 8ms/step\n",
            "Epoch 283/1000\n",
            "1/1 - 0s - loss: 0.7372 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 284/1000\n",
            "1/1 - 0s - loss: 0.7298 - accuracy: 0.9808 - 13ms/epoch - 13ms/step\n",
            "Epoch 285/1000\n",
            "1/1 - 0s - loss: 0.7225 - accuracy: 0.9808 - 13ms/epoch - 13ms/step\n",
            "Epoch 286/1000\n",
            "1/1 - 0s - loss: 0.7152 - accuracy: 0.9808 - 14ms/epoch - 14ms/step\n",
            "Epoch 287/1000\n",
            "1/1 - 0s - loss: 0.7081 - accuracy: 0.9808 - 7ms/epoch - 7ms/step\n",
            "Epoch 288/1000\n",
            "1/1 - 0s - loss: 0.7010 - accuracy: 0.9808 - 9ms/epoch - 9ms/step\n",
            "Epoch 289/1000\n",
            "1/1 - 0s - loss: 0.6940 - accuracy: 0.9808 - 12ms/epoch - 12ms/step\n",
            "Epoch 290/1000\n",
            "1/1 - 0s - loss: 0.6872 - accuracy: 0.9808 - 10ms/epoch - 10ms/step\n",
            "Epoch 291/1000\n",
            "1/1 - 0s - loss: 0.6804 - accuracy: 0.9808 - 9ms/epoch - 9ms/step\n",
            "Epoch 292/1000\n",
            "1/1 - 0s - loss: 0.6737 - accuracy: 0.9808 - 12ms/epoch - 12ms/step\n",
            "Epoch 293/1000\n",
            "1/1 - 0s - loss: 0.6671 - accuracy: 0.9808 - 12ms/epoch - 12ms/step\n",
            "Epoch 294/1000\n",
            "1/1 - 0s - loss: 0.6606 - accuracy: 0.9808 - 13ms/epoch - 13ms/step\n",
            "Epoch 295/1000\n",
            "1/1 - 0s - loss: 0.6541 - accuracy: 0.9808 - 13ms/epoch - 13ms/step\n",
            "Epoch 296/1000\n",
            "1/1 - 0s - loss: 0.6476 - accuracy: 0.9808 - 12ms/epoch - 12ms/step\n",
            "Epoch 297/1000\n",
            "1/1 - 0s - loss: 0.6413 - accuracy: 0.9808 - 9ms/epoch - 9ms/step\n",
            "Epoch 298/1000\n",
            "1/1 - 0s - loss: 0.6351 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 299/1000\n",
            "1/1 - 0s - loss: 0.6289 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 300/1000\n",
            "1/1 - 0s - loss: 0.6228 - accuracy: 0.9808 - 12ms/epoch - 12ms/step\n",
            "Epoch 301/1000\n",
            "1/1 - 0s - loss: 0.6167 - accuracy: 0.9808 - 9ms/epoch - 9ms/step\n",
            "Epoch 302/1000\n",
            "1/1 - 0s - loss: 0.6107 - accuracy: 0.9808 - 14ms/epoch - 14ms/step\n",
            "Epoch 303/1000\n",
            "1/1 - 0s - loss: 0.6048 - accuracy: 0.9808 - 11ms/epoch - 11ms/step\n",
            "Epoch 304/1000\n",
            "1/1 - 0s - loss: 0.5989 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 305/1000\n",
            "1/1 - 0s - loss: 0.5931 - accuracy: 0.9808 - 12ms/epoch - 12ms/step\n",
            "Epoch 306/1000\n",
            "1/1 - 0s - loss: 0.5873 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 307/1000\n",
            "1/1 - 0s - loss: 0.5816 - accuracy: 0.9808 - 22ms/epoch - 22ms/step\n",
            "Epoch 308/1000\n",
            "1/1 - 0s - loss: 0.5760 - accuracy: 0.9808 - 9ms/epoch - 9ms/step\n",
            "Epoch 309/1000\n",
            "1/1 - 0s - loss: 0.5704 - accuracy: 0.9808 - 13ms/epoch - 13ms/step\n",
            "Epoch 310/1000\n",
            "1/1 - 0s - loss: 0.5649 - accuracy: 0.9808 - 12ms/epoch - 12ms/step\n",
            "Epoch 311/1000\n",
            "1/1 - 0s - loss: 0.5595 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 312/1000\n",
            "1/1 - 0s - loss: 0.5541 - accuracy: 0.9808 - 12ms/epoch - 12ms/step\n",
            "Epoch 313/1000\n",
            "1/1 - 0s - loss: 0.5488 - accuracy: 0.9808 - 9ms/epoch - 9ms/step\n",
            "Epoch 314/1000\n",
            "1/1 - 0s - loss: 0.5436 - accuracy: 0.9808 - 14ms/epoch - 14ms/step\n",
            "Epoch 315/1000\n",
            "1/1 - 0s - loss: 0.5384 - accuracy: 0.9808 - 10ms/epoch - 10ms/step\n",
            "Epoch 316/1000\n",
            "1/1 - 0s - loss: 0.5333 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 317/1000\n",
            "1/1 - 0s - loss: 0.5283 - accuracy: 0.9808 - 11ms/epoch - 11ms/step\n",
            "Epoch 318/1000\n",
            "1/1 - 0s - loss: 0.5232 - accuracy: 0.9808 - 12ms/epoch - 12ms/step\n",
            "Epoch 319/1000\n",
            "1/1 - 0s - loss: 0.5183 - accuracy: 0.9808 - 11ms/epoch - 11ms/step\n",
            "Epoch 320/1000\n",
            "1/1 - 0s - loss: 0.5133 - accuracy: 0.9808 - 9ms/epoch - 9ms/step\n",
            "Epoch 321/1000\n",
            "1/1 - 0s - loss: 0.5085 - accuracy: 0.9808 - 16ms/epoch - 16ms/step\n",
            "Epoch 322/1000\n",
            "1/1 - 0s - loss: 0.5037 - accuracy: 0.9808 - 9ms/epoch - 9ms/step\n",
            "Epoch 323/1000\n",
            "1/1 - 0s - loss: 0.4989 - accuracy: 0.9808 - 9ms/epoch - 9ms/step\n",
            "Epoch 324/1000\n",
            "1/1 - 0s - loss: 0.4942 - accuracy: 0.9808 - 11ms/epoch - 11ms/step\n",
            "Epoch 325/1000\n",
            "1/1 - 0s - loss: 0.4896 - accuracy: 0.9808 - 9ms/epoch - 9ms/step\n",
            "Epoch 326/1000\n",
            "1/1 - 0s - loss: 0.4850 - accuracy: 0.9808 - 11ms/epoch - 11ms/step\n",
            "Epoch 327/1000\n",
            "1/1 - 0s - loss: 0.4805 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 328/1000\n",
            "1/1 - 0s - loss: 0.4760 - accuracy: 0.9808 - 9ms/epoch - 9ms/step\n",
            "Epoch 329/1000\n",
            "1/1 - 0s - loss: 0.4716 - accuracy: 0.9808 - 8ms/epoch - 8ms/step\n",
            "Epoch 330/1000\n",
            "1/1 - 0s - loss: 0.4672 - accuracy: 0.9808 - 13ms/epoch - 13ms/step\n",
            "Epoch 331/1000\n",
            "1/1 - 0s - loss: 0.4629 - accuracy: 0.9808 - 14ms/epoch - 14ms/step\n",
            "Epoch 332/1000\n",
            "1/1 - 0s - loss: 0.4586 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 333/1000\n",
            "1/1 - 0s - loss: 0.4544 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 334/1000\n",
            "1/1 - 0s - loss: 0.4502 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 335/1000\n",
            "1/1 - 0s - loss: 0.4461 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 336/1000\n",
            "1/1 - 0s - loss: 0.4420 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 337/1000\n",
            "1/1 - 0s - loss: 0.4379 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 338/1000\n",
            "1/1 - 0s - loss: 0.4339 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 339/1000\n",
            "1/1 - 0s - loss: 0.4299 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 340/1000\n",
            "1/1 - 0s - loss: 0.4260 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 341/1000\n",
            "1/1 - 0s - loss: 0.4221 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 342/1000\n",
            "1/1 - 0s - loss: 0.4183 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 343/1000\n",
            "1/1 - 0s - loss: 0.4145 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 344/1000\n",
            "1/1 - 0s - loss: 0.4107 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 345/1000\n",
            "1/1 - 0s - loss: 0.4070 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 346/1000\n",
            "1/1 - 0s - loss: 0.4034 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 347/1000\n",
            "1/1 - 0s - loss: 0.3997 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 348/1000\n",
            "1/1 - 0s - loss: 0.3962 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 349/1000\n",
            "1/1 - 0s - loss: 0.3926 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 350/1000\n",
            "1/1 - 0s - loss: 0.3891 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 351/1000\n",
            "1/1 - 0s - loss: 0.3857 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 352/1000\n",
            "1/1 - 0s - loss: 0.3823 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 353/1000\n",
            "1/1 - 0s - loss: 0.3789 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 354/1000\n",
            "1/1 - 0s - loss: 0.3755 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 355/1000\n",
            "1/1 - 0s - loss: 0.3722 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 356/1000\n",
            "1/1 - 0s - loss: 0.3689 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 357/1000\n",
            "1/1 - 0s - loss: 0.3657 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 358/1000\n",
            "1/1 - 0s - loss: 0.3625 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 359/1000\n",
            "1/1 - 0s - loss: 0.3594 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 360/1000\n",
            "1/1 - 0s - loss: 0.3562 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 361/1000\n",
            "1/1 - 0s - loss: 0.3531 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 362/1000\n",
            "1/1 - 0s - loss: 0.3501 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 363/1000\n",
            "1/1 - 0s - loss: 0.3470 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 364/1000\n",
            "1/1 - 0s - loss: 0.3441 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 365/1000\n",
            "1/1 - 0s - loss: 0.3411 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 366/1000\n",
            "1/1 - 0s - loss: 0.3382 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 367/1000\n",
            "1/1 - 0s - loss: 0.3352 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 368/1000\n",
            "1/1 - 0s - loss: 0.3323 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 369/1000\n",
            "1/1 - 0s - loss: 0.3295 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 370/1000\n",
            "1/1 - 0s - loss: 0.3267 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 371/1000\n",
            "1/1 - 0s - loss: 0.3239 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 372/1000\n",
            "1/1 - 0s - loss: 0.3211 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 373/1000\n",
            "1/1 - 0s - loss: 0.3184 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 374/1000\n",
            "1/1 - 0s - loss: 0.3157 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 375/1000\n",
            "1/1 - 0s - loss: 0.3130 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 376/1000\n",
            "1/1 - 0s - loss: 0.3103 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 377/1000\n",
            "1/1 - 0s - loss: 0.3077 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 378/1000\n",
            "1/1 - 0s - loss: 0.3051 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 379/1000\n",
            "1/1 - 0s - loss: 0.3026 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 380/1000\n",
            "1/1 - 0s - loss: 0.3000 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 381/1000\n",
            "1/1 - 0s - loss: 0.2975 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 382/1000\n",
            "1/1 - 0s - loss: 0.2951 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 383/1000\n",
            "1/1 - 0s - loss: 0.2926 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 384/1000\n",
            "1/1 - 0s - loss: 0.2902 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 385/1000\n",
            "1/1 - 0s - loss: 0.2878 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 386/1000\n",
            "1/1 - 0s - loss: 0.2854 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 387/1000\n",
            "1/1 - 0s - loss: 0.2831 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 388/1000\n",
            "1/1 - 0s - loss: 0.2808 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 389/1000\n",
            "1/1 - 0s - loss: 0.2785 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 390/1000\n",
            "1/1 - 0s - loss: 0.2762 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 391/1000\n",
            "1/1 - 0s - loss: 0.2740 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 392/1000\n",
            "1/1 - 0s - loss: 0.2717 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 393/1000\n",
            "1/1 - 0s - loss: 0.2695 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 394/1000\n",
            "1/1 - 0s - loss: 0.2674 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 395/1000\n",
            "1/1 - 0s - loss: 0.2652 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 396/1000\n",
            "1/1 - 0s - loss: 0.2631 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 397/1000\n",
            "1/1 - 0s - loss: 0.2609 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 398/1000\n",
            "1/1 - 0s - loss: 0.2589 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 399/1000\n",
            "1/1 - 0s - loss: 0.2568 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 400/1000\n",
            "1/1 - 0s - loss: 0.2547 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 401/1000\n",
            "1/1 - 0s - loss: 0.2527 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 402/1000\n",
            "1/1 - 0s - loss: 0.2507 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 403/1000\n",
            "1/1 - 0s - loss: 0.2487 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 404/1000\n",
            "1/1 - 0s - loss: 0.2467 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 405/1000\n",
            "1/1 - 0s - loss: 0.2448 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 406/1000\n",
            "1/1 - 0s - loss: 0.2428 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 407/1000\n",
            "1/1 - 0s - loss: 0.2409 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 408/1000\n",
            "1/1 - 0s - loss: 0.2390 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 409/1000\n",
            "1/1 - 0s - loss: 0.2371 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 410/1000\n",
            "1/1 - 0s - loss: 0.2353 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 411/1000\n",
            "1/1 - 0s - loss: 0.2334 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 412/1000\n",
            "1/1 - 0s - loss: 0.2316 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 413/1000\n",
            "1/1 - 0s - loss: 0.2298 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 414/1000\n",
            "1/1 - 0s - loss: 0.2280 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 415/1000\n",
            "1/1 - 0s - loss: 0.2263 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 416/1000\n",
            "1/1 - 0s - loss: 0.2245 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 417/1000\n",
            "1/1 - 0s - loss: 0.2228 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 418/1000\n",
            "1/1 - 0s - loss: 0.2210 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 419/1000\n",
            "1/1 - 0s - loss: 0.2193 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 420/1000\n",
            "1/1 - 0s - loss: 0.2176 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 421/1000\n",
            "1/1 - 0s - loss: 0.2160 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 422/1000\n",
            "1/1 - 0s - loss: 0.2143 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 423/1000\n",
            "1/1 - 0s - loss: 0.2127 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 424/1000\n",
            "1/1 - 0s - loss: 0.2110 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 425/1000\n",
            "1/1 - 0s - loss: 0.2094 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 426/1000\n",
            "1/1 - 0s - loss: 0.2078 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 427/1000\n",
            "1/1 - 0s - loss: 0.2062 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 428/1000\n",
            "1/1 - 0s - loss: 0.2047 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 429/1000\n",
            "1/1 - 0s - loss: 0.2031 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 430/1000\n",
            "1/1 - 0s - loss: 0.2016 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 431/1000\n",
            "1/1 - 0s - loss: 0.2001 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 432/1000\n",
            "1/1 - 0s - loss: 0.1986 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 433/1000\n",
            "1/1 - 0s - loss: 0.1971 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 434/1000\n",
            "1/1 - 0s - loss: 0.1956 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 435/1000\n",
            "1/1 - 0s - loss: 0.1942 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 436/1000\n",
            "1/1 - 0s - loss: 0.1928 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 437/1000\n",
            "1/1 - 0s - loss: 0.1913 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 438/1000\n",
            "1/1 - 0s - loss: 0.1899 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 439/1000\n",
            "1/1 - 0s - loss: 0.1885 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 440/1000\n",
            "1/1 - 0s - loss: 0.1872 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 441/1000\n",
            "1/1 - 0s - loss: 0.1858 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 442/1000\n",
            "1/1 - 0s - loss: 0.1845 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 443/1000\n",
            "1/1 - 0s - loss: 0.1831 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 444/1000\n",
            "1/1 - 0s - loss: 0.1818 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 445/1000\n",
            "1/1 - 0s - loss: 0.1805 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 446/1000\n",
            "1/1 - 0s - loss: 0.1792 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 447/1000\n",
            "1/1 - 0s - loss: 0.1779 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 448/1000\n",
            "1/1 - 0s - loss: 0.1766 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 449/1000\n",
            "1/1 - 0s - loss: 0.1753 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 450/1000\n",
            "1/1 - 0s - loss: 0.1741 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 451/1000\n",
            "1/1 - 0s - loss: 0.1728 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 452/1000\n",
            "1/1 - 0s - loss: 0.1716 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 453/1000\n",
            "1/1 - 0s - loss: 0.1703 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 454/1000\n",
            "1/1 - 0s - loss: 0.1691 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 455/1000\n",
            "1/1 - 0s - loss: 0.1679 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 456/1000\n",
            "1/1 - 0s - loss: 0.1667 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 457/1000\n",
            "1/1 - 0s - loss: 0.1655 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 458/1000\n",
            "1/1 - 0s - loss: 0.1643 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 459/1000\n",
            "1/1 - 0s - loss: 0.1632 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 460/1000\n",
            "1/1 - 0s - loss: 0.1620 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 461/1000\n",
            "1/1 - 0s - loss: 0.1609 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 462/1000\n",
            "1/1 - 0s - loss: 0.1598 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 463/1000\n",
            "1/1 - 0s - loss: 0.1587 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 464/1000\n",
            "1/1 - 0s - loss: 0.1576 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 465/1000\n",
            "1/1 - 0s - loss: 0.1565 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 466/1000\n",
            "1/1 - 0s - loss: 0.1554 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 467/1000\n",
            "1/1 - 0s - loss: 0.1543 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 468/1000\n",
            "1/1 - 0s - loss: 0.1532 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 469/1000\n",
            "1/1 - 0s - loss: 0.1522 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 470/1000\n",
            "1/1 - 0s - loss: 0.1511 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 471/1000\n",
            "1/1 - 0s - loss: 0.1501 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 472/1000\n",
            "1/1 - 0s - loss: 0.1491 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 473/1000\n",
            "1/1 - 0s - loss: 0.1481 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 474/1000\n",
            "1/1 - 0s - loss: 0.1471 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 475/1000\n",
            "1/1 - 0s - loss: 0.1461 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 476/1000\n",
            "1/1 - 0s - loss: 0.1451 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 477/1000\n",
            "1/1 - 0s - loss: 0.1441 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 478/1000\n",
            "1/1 - 0s - loss: 0.1431 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 479/1000\n",
            "1/1 - 0s - loss: 0.1421 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 480/1000\n",
            "1/1 - 0s - loss: 0.1412 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 481/1000\n",
            "1/1 - 0s - loss: 0.1402 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 482/1000\n",
            "1/1 - 0s - loss: 0.1393 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 483/1000\n",
            "1/1 - 0s - loss: 0.1384 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 484/1000\n",
            "1/1 - 0s - loss: 0.1375 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 485/1000\n",
            "1/1 - 0s - loss: 0.1365 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 486/1000\n",
            "1/1 - 0s - loss: 0.1356 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 487/1000\n",
            "1/1 - 0s - loss: 0.1347 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 488/1000\n",
            "1/1 - 0s - loss: 0.1338 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 489/1000\n",
            "1/1 - 0s - loss: 0.1329 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 490/1000\n",
            "1/1 - 0s - loss: 0.1321 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 491/1000\n",
            "1/1 - 0s - loss: 0.1312 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 492/1000\n",
            "1/1 - 0s - loss: 0.1303 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 493/1000\n",
            "1/1 - 0s - loss: 0.1295 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 494/1000\n",
            "1/1 - 0s - loss: 0.1286 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 495/1000\n",
            "1/1 - 0s - loss: 0.1278 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 496/1000\n",
            "1/1 - 0s - loss: 0.1270 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 497/1000\n",
            "1/1 - 0s - loss: 0.1261 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 498/1000\n",
            "1/1 - 0s - loss: 0.1253 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 499/1000\n",
            "1/1 - 0s - loss: 0.1245 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 500/1000\n",
            "1/1 - 0s - loss: 0.1237 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 501/1000\n",
            "1/1 - 0s - loss: 0.1229 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 502/1000\n",
            "1/1 - 0s - loss: 0.1221 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 503/1000\n",
            "1/1 - 0s - loss: 0.1213 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 504/1000\n",
            "1/1 - 0s - loss: 0.1205 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 505/1000\n",
            "1/1 - 0s - loss: 0.1198 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 506/1000\n",
            "1/1 - 0s - loss: 0.1190 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 507/1000\n",
            "1/1 - 0s - loss: 0.1182 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 508/1000\n",
            "1/1 - 0s - loss: 0.1175 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 509/1000\n",
            "1/1 - 0s - loss: 0.1167 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 510/1000\n",
            "1/1 - 0s - loss: 0.1160 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 511/1000\n",
            "1/1 - 0s - loss: 0.1153 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 512/1000\n",
            "1/1 - 0s - loss: 0.1145 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 513/1000\n",
            "1/1 - 0s - loss: 0.1138 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 514/1000\n",
            "1/1 - 0s - loss: 0.1131 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 515/1000\n",
            "1/1 - 0s - loss: 0.1124 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 516/1000\n",
            "1/1 - 0s - loss: 0.1117 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 517/1000\n",
            "1/1 - 0s - loss: 0.1110 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 518/1000\n",
            "1/1 - 0s - loss: 0.1103 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 519/1000\n",
            "1/1 - 0s - loss: 0.1096 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 520/1000\n",
            "1/1 - 0s - loss: 0.1089 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 521/1000\n",
            "1/1 - 0s - loss: 0.1083 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 522/1000\n",
            "1/1 - 0s - loss: 0.1076 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 523/1000\n",
            "1/1 - 0s - loss: 0.1069 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 524/1000\n",
            "1/1 - 0s - loss: 0.1062 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 525/1000\n",
            "1/1 - 0s - loss: 0.1056 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 526/1000\n",
            "1/1 - 0s - loss: 0.1049 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 527/1000\n",
            "1/1 - 0s - loss: 0.1043 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 528/1000\n",
            "1/1 - 0s - loss: 0.1037 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 529/1000\n",
            "1/1 - 0s - loss: 0.1030 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 530/1000\n",
            "1/1 - 0s - loss: 0.1024 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 531/1000\n",
            "1/1 - 0s - loss: 0.1018 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 532/1000\n",
            "1/1 - 0s - loss: 0.1011 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 533/1000\n",
            "1/1 - 0s - loss: 0.1005 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 534/1000\n",
            "1/1 - 0s - loss: 0.0999 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 535/1000\n",
            "1/1 - 0s - loss: 0.0993 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 536/1000\n",
            "1/1 - 0s - loss: 0.0987 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 537/1000\n",
            "1/1 - 0s - loss: 0.0981 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 538/1000\n",
            "1/1 - 0s - loss: 0.0975 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 539/1000\n",
            "1/1 - 0s - loss: 0.0969 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 540/1000\n",
            "1/1 - 0s - loss: 0.0963 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 541/1000\n",
            "1/1 - 0s - loss: 0.0958 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 542/1000\n",
            "1/1 - 0s - loss: 0.0952 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 543/1000\n",
            "1/1 - 0s - loss: 0.0946 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 544/1000\n",
            "1/1 - 0s - loss: 0.0940 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 545/1000\n",
            "1/1 - 0s - loss: 0.0935 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 546/1000\n",
            "1/1 - 0s - loss: 0.0929 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 547/1000\n",
            "1/1 - 0s - loss: 0.0924 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 548/1000\n",
            "1/1 - 0s - loss: 0.0918 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 549/1000\n",
            "1/1 - 0s - loss: 0.0913 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 550/1000\n",
            "1/1 - 0s - loss: 0.0907 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 551/1000\n",
            "1/1 - 0s - loss: 0.0902 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 552/1000\n",
            "1/1 - 0s - loss: 0.0896 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 553/1000\n",
            "1/1 - 0s - loss: 0.0891 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 554/1000\n",
            "1/1 - 0s - loss: 0.0886 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 555/1000\n",
            "1/1 - 0s - loss: 0.0881 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 556/1000\n",
            "1/1 - 0s - loss: 0.0876 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 557/1000\n",
            "1/1 - 0s - loss: 0.0870 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 558/1000\n",
            "1/1 - 0s - loss: 0.0865 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 559/1000\n",
            "1/1 - 0s - loss: 0.0860 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 560/1000\n",
            "1/1 - 0s - loss: 0.0855 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 561/1000\n",
            "1/1 - 0s - loss: 0.0850 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 562/1000\n",
            "1/1 - 0s - loss: 0.0845 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 563/1000\n",
            "1/1 - 0s - loss: 0.0840 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 564/1000\n",
            "1/1 - 0s - loss: 0.0836 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 565/1000\n",
            "1/1 - 0s - loss: 0.0831 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 566/1000\n",
            "1/1 - 0s - loss: 0.0826 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 567/1000\n",
            "1/1 - 0s - loss: 0.0821 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 568/1000\n",
            "1/1 - 0s - loss: 0.0816 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 569/1000\n",
            "1/1 - 0s - loss: 0.0812 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 570/1000\n",
            "1/1 - 0s - loss: 0.0807 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 571/1000\n",
            "1/1 - 0s - loss: 0.0803 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 572/1000\n",
            "1/1 - 0s - loss: 0.0798 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 573/1000\n",
            "1/1 - 0s - loss: 0.0793 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 574/1000\n",
            "1/1 - 0s - loss: 0.0789 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 575/1000\n",
            "1/1 - 0s - loss: 0.0784 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 576/1000\n",
            "1/1 - 0s - loss: 0.0780 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 577/1000\n",
            "1/1 - 0s - loss: 0.0776 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 578/1000\n",
            "1/1 - 0s - loss: 0.0771 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 579/1000\n",
            "1/1 - 0s - loss: 0.0767 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 580/1000\n",
            "1/1 - 0s - loss: 0.0763 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 581/1000\n",
            "1/1 - 0s - loss: 0.0758 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 582/1000\n",
            "1/1 - 0s - loss: 0.0754 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 583/1000\n",
            "1/1 - 0s - loss: 0.0750 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 584/1000\n",
            "1/1 - 0s - loss: 0.0746 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 585/1000\n",
            "1/1 - 0s - loss: 0.0742 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 586/1000\n",
            "1/1 - 0s - loss: 0.0737 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 587/1000\n",
            "1/1 - 0s - loss: 0.0733 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 588/1000\n",
            "1/1 - 0s - loss: 0.0729 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 589/1000\n",
            "1/1 - 0s - loss: 0.0725 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 590/1000\n",
            "1/1 - 0s - loss: 0.0721 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 591/1000\n",
            "1/1 - 0s - loss: 0.0717 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 592/1000\n",
            "1/1 - 0s - loss: 0.0713 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 593/1000\n",
            "1/1 - 0s - loss: 0.0709 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 594/1000\n",
            "1/1 - 0s - loss: 0.0706 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 595/1000\n",
            "1/1 - 0s - loss: 0.0702 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 596/1000\n",
            "1/1 - 0s - loss: 0.0698 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 597/1000\n",
            "1/1 - 0s - loss: 0.0694 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 598/1000\n",
            "1/1 - 0s - loss: 0.0690 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 599/1000\n",
            "1/1 - 0s - loss: 0.0687 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 600/1000\n",
            "1/1 - 0s - loss: 0.0683 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 601/1000\n",
            "1/1 - 0s - loss: 0.0679 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 602/1000\n",
            "1/1 - 0s - loss: 0.0676 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 603/1000\n",
            "1/1 - 0s - loss: 0.0672 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 604/1000\n",
            "1/1 - 0s - loss: 0.0668 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 605/1000\n",
            "1/1 - 0s - loss: 0.0665 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 606/1000\n",
            "1/1 - 0s - loss: 0.0661 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 607/1000\n",
            "1/1 - 0s - loss: 0.0658 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 608/1000\n",
            "1/1 - 0s - loss: 0.0654 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 609/1000\n",
            "1/1 - 0s - loss: 0.0651 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 610/1000\n",
            "1/1 - 0s - loss: 0.0647 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 611/1000\n",
            "1/1 - 0s - loss: 0.0644 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 612/1000\n",
            "1/1 - 0s - loss: 0.0640 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 613/1000\n",
            "1/1 - 0s - loss: 0.0637 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 614/1000\n",
            "1/1 - 0s - loss: 0.0634 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 615/1000\n",
            "1/1 - 0s - loss: 0.0630 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 616/1000\n",
            "1/1 - 0s - loss: 0.0627 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 617/1000\n",
            "1/1 - 0s - loss: 0.0624 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 618/1000\n",
            "1/1 - 0s - loss: 0.0620 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 619/1000\n",
            "1/1 - 0s - loss: 0.0617 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 620/1000\n",
            "1/1 - 0s - loss: 0.0614 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 621/1000\n",
            "1/1 - 0s - loss: 0.0611 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 622/1000\n",
            "1/1 - 0s - loss: 0.0607 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 623/1000\n",
            "1/1 - 0s - loss: 0.0604 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 624/1000\n",
            "1/1 - 0s - loss: 0.0601 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 625/1000\n",
            "1/1 - 0s - loss: 0.0598 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 626/1000\n",
            "1/1 - 0s - loss: 0.0595 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 627/1000\n",
            "1/1 - 0s - loss: 0.0592 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 628/1000\n",
            "1/1 - 0s - loss: 0.0589 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 629/1000\n",
            "1/1 - 0s - loss: 0.0586 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 630/1000\n",
            "1/1 - 0s - loss: 0.0583 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 631/1000\n",
            "1/1 - 0s - loss: 0.0580 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 632/1000\n",
            "1/1 - 0s - loss: 0.0577 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 633/1000\n",
            "1/1 - 0s - loss: 0.0574 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 634/1000\n",
            "1/1 - 0s - loss: 0.0571 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 635/1000\n",
            "1/1 - 0s - loss: 0.0568 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 636/1000\n",
            "1/1 - 0s - loss: 0.0565 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 637/1000\n",
            "1/1 - 0s - loss: 0.0563 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 638/1000\n",
            "1/1 - 0s - loss: 0.0560 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 639/1000\n",
            "1/1 - 0s - loss: 0.0557 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 640/1000\n",
            "1/1 - 0s - loss: 0.0554 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 641/1000\n",
            "1/1 - 0s - loss: 0.0551 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 642/1000\n",
            "1/1 - 0s - loss: 0.0549 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 643/1000\n",
            "1/1 - 0s - loss: 0.0546 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 644/1000\n",
            "1/1 - 0s - loss: 0.0543 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 645/1000\n",
            "1/1 - 0s - loss: 0.0540 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 646/1000\n",
            "1/1 - 0s - loss: 0.0538 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 647/1000\n",
            "1/1 - 0s - loss: 0.0535 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 648/1000\n",
            "1/1 - 0s - loss: 0.0533 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 649/1000\n",
            "1/1 - 0s - loss: 0.0530 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 650/1000\n",
            "1/1 - 0s - loss: 0.0527 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 651/1000\n",
            "1/1 - 0s - loss: 0.0525 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 652/1000\n",
            "1/1 - 0s - loss: 0.0522 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 653/1000\n",
            "1/1 - 0s - loss: 0.0520 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 654/1000\n",
            "1/1 - 0s - loss: 0.0517 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 655/1000\n",
            "1/1 - 0s - loss: 0.0515 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 656/1000\n",
            "1/1 - 0s - loss: 0.0512 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 657/1000\n",
            "1/1 - 0s - loss: 0.0510 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 658/1000\n",
            "1/1 - 0s - loss: 0.0507 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 659/1000\n",
            "1/1 - 0s - loss: 0.0505 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 660/1000\n",
            "1/1 - 0s - loss: 0.0502 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 661/1000\n",
            "1/1 - 0s - loss: 0.0500 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 662/1000\n",
            "1/1 - 0s - loss: 0.0497 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 663/1000\n",
            "1/1 - 0s - loss: 0.0495 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 664/1000\n",
            "1/1 - 0s - loss: 0.0493 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 665/1000\n",
            "1/1 - 0s - loss: 0.0490 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 666/1000\n",
            "1/1 - 0s - loss: 0.0488 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 667/1000\n",
            "1/1 - 0s - loss: 0.0486 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 668/1000\n",
            "1/1 - 0s - loss: 0.0483 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 669/1000\n",
            "1/1 - 0s - loss: 0.0481 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 670/1000\n",
            "1/1 - 0s - loss: 0.0479 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 671/1000\n",
            "1/1 - 0s - loss: 0.0477 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 672/1000\n",
            "1/1 - 0s - loss: 0.0474 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 673/1000\n",
            "1/1 - 0s - loss: 0.0472 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 674/1000\n",
            "1/1 - 0s - loss: 0.0470 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 675/1000\n",
            "1/1 - 0s - loss: 0.0468 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 676/1000\n",
            "1/1 - 0s - loss: 0.0465 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 677/1000\n",
            "1/1 - 0s - loss: 0.0463 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 678/1000\n",
            "1/1 - 0s - loss: 0.0461 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 679/1000\n",
            "1/1 - 0s - loss: 0.0459 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 680/1000\n",
            "1/1 - 0s - loss: 0.0457 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 681/1000\n",
            "1/1 - 0s - loss: 0.0455 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 682/1000\n",
            "1/1 - 0s - loss: 0.0452 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 683/1000\n",
            "1/1 - 0s - loss: 0.0450 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 684/1000\n",
            "1/1 - 0s - loss: 0.0448 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 685/1000\n",
            "1/1 - 0s - loss: 0.0446 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 686/1000\n",
            "1/1 - 0s - loss: 0.0444 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 687/1000\n",
            "1/1 - 0s - loss: 0.0442 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 688/1000\n",
            "1/1 - 0s - loss: 0.0440 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 689/1000\n",
            "1/1 - 0s - loss: 0.0438 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 690/1000\n",
            "1/1 - 0s - loss: 0.0436 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 691/1000\n",
            "1/1 - 0s - loss: 0.0434 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 692/1000\n",
            "1/1 - 0s - loss: 0.0432 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 693/1000\n",
            "1/1 - 0s - loss: 0.0430 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 694/1000\n",
            "1/1 - 0s - loss: 0.0428 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 695/1000\n",
            "1/1 - 0s - loss: 0.0426 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 696/1000\n",
            "1/1 - 0s - loss: 0.0424 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 697/1000\n",
            "1/1 - 0s - loss: 0.0422 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 698/1000\n",
            "1/1 - 0s - loss: 0.0420 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 699/1000\n",
            "1/1 - 0s - loss: 0.0418 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 700/1000\n",
            "1/1 - 0s - loss: 0.0416 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 701/1000\n",
            "1/1 - 0s - loss: 0.0414 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 702/1000\n",
            "1/1 - 0s - loss: 0.0413 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 703/1000\n",
            "1/1 - 0s - loss: 0.0411 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 704/1000\n",
            "1/1 - 0s - loss: 0.0409 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 705/1000\n",
            "1/1 - 0s - loss: 0.0407 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 706/1000\n",
            "1/1 - 0s - loss: 0.0405 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 707/1000\n",
            "1/1 - 0s - loss: 0.0403 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 708/1000\n",
            "1/1 - 0s - loss: 0.0402 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 709/1000\n",
            "1/1 - 0s - loss: 0.0400 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 710/1000\n",
            "1/1 - 0s - loss: 0.0398 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 711/1000\n",
            "1/1 - 0s - loss: 0.0396 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 712/1000\n",
            "1/1 - 0s - loss: 0.0395 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 713/1000\n",
            "1/1 - 0s - loss: 0.0393 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 714/1000\n",
            "1/1 - 0s - loss: 0.0391 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 715/1000\n",
            "1/1 - 0s - loss: 0.0389 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 716/1000\n",
            "1/1 - 0s - loss: 0.0388 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 717/1000\n",
            "1/1 - 0s - loss: 0.0386 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 718/1000\n",
            "1/1 - 0s - loss: 0.0384 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 719/1000\n",
            "1/1 - 0s - loss: 0.0383 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 720/1000\n",
            "1/1 - 0s - loss: 0.0381 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 721/1000\n",
            "1/1 - 0s - loss: 0.0379 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 722/1000\n",
            "1/1 - 0s - loss: 0.0378 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 723/1000\n",
            "1/1 - 0s - loss: 0.0376 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 724/1000\n",
            "1/1 - 0s - loss: 0.0374 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 725/1000\n",
            "1/1 - 0s - loss: 0.0373 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 726/1000\n",
            "1/1 - 0s - loss: 0.0371 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 727/1000\n",
            "1/1 - 0s - loss: 0.0370 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 728/1000\n",
            "1/1 - 0s - loss: 0.0368 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 729/1000\n",
            "1/1 - 0s - loss: 0.0366 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 730/1000\n",
            "1/1 - 0s - loss: 0.0365 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 731/1000\n",
            "1/1 - 0s - loss: 0.0363 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 732/1000\n",
            "1/1 - 0s - loss: 0.0362 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 733/1000\n",
            "1/1 - 0s - loss: 0.0360 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 734/1000\n",
            "1/1 - 0s - loss: 0.0359 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 735/1000\n",
            "1/1 - 0s - loss: 0.0357 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 736/1000\n",
            "1/1 - 0s - loss: 0.0355 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 737/1000\n",
            "1/1 - 0s - loss: 0.0354 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 738/1000\n",
            "1/1 - 0s - loss: 0.0352 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 739/1000\n",
            "1/1 - 0s - loss: 0.0351 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 740/1000\n",
            "1/1 - 0s - loss: 0.0350 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 741/1000\n",
            "1/1 - 0s - loss: 0.0348 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 742/1000\n",
            "1/1 - 0s - loss: 0.0347 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 743/1000\n",
            "1/1 - 0s - loss: 0.0345 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 744/1000\n",
            "1/1 - 0s - loss: 0.0344 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 745/1000\n",
            "1/1 - 0s - loss: 0.0342 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 746/1000\n",
            "1/1 - 0s - loss: 0.0341 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 747/1000\n",
            "1/1 - 0s - loss: 0.0339 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 748/1000\n",
            "1/1 - 0s - loss: 0.0338 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 749/1000\n",
            "1/1 - 0s - loss: 0.0337 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 750/1000\n",
            "1/1 - 0s - loss: 0.0335 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 751/1000\n",
            "1/1 - 0s - loss: 0.0334 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 752/1000\n",
            "1/1 - 0s - loss: 0.0332 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 753/1000\n",
            "1/1 - 0s - loss: 0.0331 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 754/1000\n",
            "1/1 - 0s - loss: 0.0330 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 755/1000\n",
            "1/1 - 0s - loss: 0.0328 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 756/1000\n",
            "1/1 - 0s - loss: 0.0327 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 757/1000\n",
            "1/1 - 0s - loss: 0.0326 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 758/1000\n",
            "1/1 - 0s - loss: 0.0324 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 759/1000\n",
            "1/1 - 0s - loss: 0.0323 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 760/1000\n",
            "1/1 - 0s - loss: 0.0322 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 761/1000\n",
            "1/1 - 0s - loss: 0.0320 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 762/1000\n",
            "1/1 - 0s - loss: 0.0319 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 763/1000\n",
            "1/1 - 0s - loss: 0.0318 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 764/1000\n",
            "1/1 - 0s - loss: 0.0316 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 765/1000\n",
            "1/1 - 0s - loss: 0.0315 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 766/1000\n",
            "1/1 - 0s - loss: 0.0314 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 767/1000\n",
            "1/1 - 0s - loss: 0.0313 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 768/1000\n",
            "1/1 - 0s - loss: 0.0311 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 769/1000\n",
            "1/1 - 0s - loss: 0.0310 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 770/1000\n",
            "1/1 - 0s - loss: 0.0309 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 771/1000\n",
            "1/1 - 0s - loss: 0.0308 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 772/1000\n",
            "1/1 - 0s - loss: 0.0306 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 773/1000\n",
            "1/1 - 0s - loss: 0.0305 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 774/1000\n",
            "1/1 - 0s - loss: 0.0304 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 775/1000\n",
            "1/1 - 0s - loss: 0.0303 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 776/1000\n",
            "1/1 - 0s - loss: 0.0302 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 777/1000\n",
            "1/1 - 0s - loss: 0.0300 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 778/1000\n",
            "1/1 - 0s - loss: 0.0299 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 779/1000\n",
            "1/1 - 0s - loss: 0.0298 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 780/1000\n",
            "1/1 - 0s - loss: 0.0297 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 781/1000\n",
            "1/1 - 0s - loss: 0.0296 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 782/1000\n",
            "1/1 - 0s - loss: 0.0294 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 783/1000\n",
            "1/1 - 0s - loss: 0.0293 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 784/1000\n",
            "1/1 - 0s - loss: 0.0292 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 785/1000\n",
            "1/1 - 0s - loss: 0.0291 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 786/1000\n",
            "1/1 - 0s - loss: 0.0290 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 787/1000\n",
            "1/1 - 0s - loss: 0.0289 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 788/1000\n",
            "1/1 - 0s - loss: 0.0288 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 789/1000\n",
            "1/1 - 0s - loss: 0.0286 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 790/1000\n",
            "1/1 - 0s - loss: 0.0285 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 791/1000\n",
            "1/1 - 0s - loss: 0.0284 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 792/1000\n",
            "1/1 - 0s - loss: 0.0283 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 793/1000\n",
            "1/1 - 0s - loss: 0.0282 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 794/1000\n",
            "1/1 - 0s - loss: 0.0281 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 795/1000\n",
            "1/1 - 0s - loss: 0.0280 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 796/1000\n",
            "1/1 - 0s - loss: 0.0279 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 797/1000\n",
            "1/1 - 0s - loss: 0.0278 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 798/1000\n",
            "1/1 - 0s - loss: 0.0276 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 799/1000\n",
            "1/1 - 0s - loss: 0.0275 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 800/1000\n",
            "1/1 - 0s - loss: 0.0274 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 801/1000\n",
            "1/1 - 0s - loss: 0.0273 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 802/1000\n",
            "1/1 - 0s - loss: 0.0272 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 803/1000\n",
            "1/1 - 0s - loss: 0.0271 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 804/1000\n",
            "1/1 - 0s - loss: 0.0270 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 805/1000\n",
            "1/1 - 0s - loss: 0.0269 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 806/1000\n",
            "1/1 - 0s - loss: 0.0268 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 807/1000\n",
            "1/1 - 0s - loss: 0.0267 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 808/1000\n",
            "1/1 - 0s - loss: 0.0266 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 809/1000\n",
            "1/1 - 0s - loss: 0.0265 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 810/1000\n",
            "1/1 - 0s - loss: 0.0264 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 811/1000\n",
            "1/1 - 0s - loss: 0.0263 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 812/1000\n",
            "1/1 - 0s - loss: 0.0262 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 813/1000\n",
            "1/1 - 0s - loss: 0.0261 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 814/1000\n",
            "1/1 - 0s - loss: 0.0260 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 815/1000\n",
            "1/1 - 0s - loss: 0.0259 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 816/1000\n",
            "1/1 - 0s - loss: 0.0258 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 817/1000\n",
            "1/1 - 0s - loss: 0.0257 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 818/1000\n",
            "1/1 - 0s - loss: 0.0256 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 819/1000\n",
            "1/1 - 0s - loss: 0.0255 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 820/1000\n",
            "1/1 - 0s - loss: 0.0254 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 821/1000\n",
            "1/1 - 0s - loss: 0.0253 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 822/1000\n",
            "1/1 - 0s - loss: 0.0252 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 823/1000\n",
            "1/1 - 0s - loss: 0.0251 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 824/1000\n",
            "1/1 - 0s - loss: 0.0250 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 825/1000\n",
            "1/1 - 0s - loss: 0.0250 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 826/1000\n",
            "1/1 - 0s - loss: 0.0249 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 827/1000\n",
            "1/1 - 0s - loss: 0.0248 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 828/1000\n",
            "1/1 - 0s - loss: 0.0247 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 829/1000\n",
            "1/1 - 0s - loss: 0.0246 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 830/1000\n",
            "1/1 - 0s - loss: 0.0245 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 831/1000\n",
            "1/1 - 0s - loss: 0.0244 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 832/1000\n",
            "1/1 - 0s - loss: 0.0243 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 833/1000\n",
            "1/1 - 0s - loss: 0.0242 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 834/1000\n",
            "1/1 - 0s - loss: 0.0241 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 835/1000\n",
            "1/1 - 0s - loss: 0.0240 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 836/1000\n",
            "1/1 - 0s - loss: 0.0240 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 837/1000\n",
            "1/1 - 0s - loss: 0.0239 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 838/1000\n",
            "1/1 - 0s - loss: 0.0238 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 839/1000\n",
            "1/1 - 0s - loss: 0.0237 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 840/1000\n",
            "1/1 - 0s - loss: 0.0236 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 841/1000\n",
            "1/1 - 0s - loss: 0.0235 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 842/1000\n",
            "1/1 - 0s - loss: 0.0234 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 843/1000\n",
            "1/1 - 0s - loss: 0.0233 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 844/1000\n",
            "1/1 - 0s - loss: 0.0233 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 845/1000\n",
            "1/1 - 0s - loss: 0.0232 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 846/1000\n",
            "1/1 - 0s - loss: 0.0231 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 847/1000\n",
            "1/1 - 0s - loss: 0.0230 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 848/1000\n",
            "1/1 - 0s - loss: 0.0229 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 849/1000\n",
            "1/1 - 0s - loss: 0.0228 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 850/1000\n",
            "1/1 - 0s - loss: 0.0228 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 851/1000\n",
            "1/1 - 0s - loss: 0.0227 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 852/1000\n",
            "1/1 - 0s - loss: 0.0226 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 853/1000\n",
            "1/1 - 0s - loss: 0.0225 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 854/1000\n",
            "1/1 - 0s - loss: 0.0224 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 855/1000\n",
            "1/1 - 0s - loss: 0.0223 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 856/1000\n",
            "1/1 - 0s - loss: 0.0223 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 857/1000\n",
            "1/1 - 0s - loss: 0.0222 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 858/1000\n",
            "1/1 - 0s - loss: 0.0221 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 859/1000\n",
            "1/1 - 0s - loss: 0.0220 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 860/1000\n",
            "1/1 - 0s - loss: 0.0220 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 861/1000\n",
            "1/1 - 0s - loss: 0.0219 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 862/1000\n",
            "1/1 - 0s - loss: 0.0218 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 863/1000\n",
            "1/1 - 0s - loss: 0.0217 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 864/1000\n",
            "1/1 - 0s - loss: 0.0216 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 865/1000\n",
            "1/1 - 0s - loss: 0.0216 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 866/1000\n",
            "1/1 - 0s - loss: 0.0215 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 867/1000\n",
            "1/1 - 0s - loss: 0.0214 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 868/1000\n",
            "1/1 - 0s - loss: 0.0213 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 869/1000\n",
            "1/1 - 0s - loss: 0.0213 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 870/1000\n",
            "1/1 - 0s - loss: 0.0212 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 871/1000\n",
            "1/1 - 0s - loss: 0.0211 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 872/1000\n",
            "1/1 - 0s - loss: 0.0210 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 873/1000\n",
            "1/1 - 0s - loss: 0.0210 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 874/1000\n",
            "1/1 - 0s - loss: 0.0209 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 875/1000\n",
            "1/1 - 0s - loss: 0.0208 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 876/1000\n",
            "1/1 - 0s - loss: 0.0207 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 877/1000\n",
            "1/1 - 0s - loss: 0.0207 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 878/1000\n",
            "1/1 - 0s - loss: 0.0206 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 879/1000\n",
            "1/1 - 0s - loss: 0.0205 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 880/1000\n",
            "1/1 - 0s - loss: 0.0205 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 881/1000\n",
            "1/1 - 0s - loss: 0.0204 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 882/1000\n",
            "1/1 - 0s - loss: 0.0203 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 883/1000\n",
            "1/1 - 0s - loss: 0.0203 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 884/1000\n",
            "1/1 - 0s - loss: 0.0202 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 885/1000\n",
            "1/1 - 0s - loss: 0.0201 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 886/1000\n",
            "1/1 - 0s - loss: 0.0200 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 887/1000\n",
            "1/1 - 0s - loss: 0.0200 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 888/1000\n",
            "1/1 - 0s - loss: 0.0199 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 889/1000\n",
            "1/1 - 0s - loss: 0.0198 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 890/1000\n",
            "1/1 - 0s - loss: 0.0198 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 891/1000\n",
            "1/1 - 0s - loss: 0.0197 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 892/1000\n",
            "1/1 - 0s - loss: 0.0196 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 893/1000\n",
            "1/1 - 0s - loss: 0.0196 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 894/1000\n",
            "1/1 - 0s - loss: 0.0195 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 895/1000\n",
            "1/1 - 0s - loss: 0.0194 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 896/1000\n",
            "1/1 - 0s - loss: 0.0194 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 897/1000\n",
            "1/1 - 0s - loss: 0.0193 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 898/1000\n",
            "1/1 - 0s - loss: 0.0192 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 899/1000\n",
            "1/1 - 0s - loss: 0.0192 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 900/1000\n",
            "1/1 - 0s - loss: 0.0191 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 901/1000\n",
            "1/1 - 0s - loss: 0.0191 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 902/1000\n",
            "1/1 - 0s - loss: 0.0190 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 903/1000\n",
            "1/1 - 0s - loss: 0.0189 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 904/1000\n",
            "1/1 - 0s - loss: 0.0189 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 905/1000\n",
            "1/1 - 0s - loss: 0.0188 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 906/1000\n",
            "1/1 - 0s - loss: 0.0187 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 907/1000\n",
            "1/1 - 0s - loss: 0.0187 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 908/1000\n",
            "1/1 - 0s - loss: 0.0186 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 909/1000\n",
            "1/1 - 0s - loss: 0.0186 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 910/1000\n",
            "1/1 - 0s - loss: 0.0185 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 911/1000\n",
            "1/1 - 0s - loss: 0.0184 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 912/1000\n",
            "1/1 - 0s - loss: 0.0184 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 913/1000\n",
            "1/1 - 0s - loss: 0.0183 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 914/1000\n",
            "1/1 - 0s - loss: 0.0183 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 915/1000\n",
            "1/1 - 0s - loss: 0.0182 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 916/1000\n",
            "1/1 - 0s - loss: 0.0181 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 917/1000\n",
            "1/1 - 0s - loss: 0.0181 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 918/1000\n",
            "1/1 - 0s - loss: 0.0180 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 919/1000\n",
            "1/1 - 0s - loss: 0.0180 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 920/1000\n",
            "1/1 - 0s - loss: 0.0179 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 921/1000\n",
            "1/1 - 0s - loss: 0.0178 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 922/1000\n",
            "1/1 - 0s - loss: 0.0178 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 923/1000\n",
            "1/1 - 0s - loss: 0.0177 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 924/1000\n",
            "1/1 - 0s - loss: 0.0177 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 925/1000\n",
            "1/1 - 0s - loss: 0.0176 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 926/1000\n",
            "1/1 - 0s - loss: 0.0176 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 927/1000\n",
            "1/1 - 0s - loss: 0.0175 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 928/1000\n",
            "1/1 - 0s - loss: 0.0174 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 929/1000\n",
            "1/1 - 0s - loss: 0.0174 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 930/1000\n",
            "1/1 - 0s - loss: 0.0173 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 931/1000\n",
            "1/1 - 0s - loss: 0.0173 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 932/1000\n",
            "1/1 - 0s - loss: 0.0172 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 933/1000\n",
            "1/1 - 0s - loss: 0.0172 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 934/1000\n",
            "1/1 - 0s - loss: 0.0171 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 935/1000\n",
            "1/1 - 0s - loss: 0.0171 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 936/1000\n",
            "1/1 - 0s - loss: 0.0170 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 937/1000\n",
            "1/1 - 0s - loss: 0.0170 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 938/1000\n",
            "1/1 - 0s - loss: 0.0169 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 939/1000\n",
            "1/1 - 0s - loss: 0.0168 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 940/1000\n",
            "1/1 - 0s - loss: 0.0168 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 941/1000\n",
            "1/1 - 0s - loss: 0.0167 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 942/1000\n",
            "1/1 - 0s - loss: 0.0167 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 943/1000\n",
            "1/1 - 0s - loss: 0.0166 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 944/1000\n",
            "1/1 - 0s - loss: 0.0166 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 945/1000\n",
            "1/1 - 0s - loss: 0.0165 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 946/1000\n",
            "1/1 - 0s - loss: 0.0165 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 947/1000\n",
            "1/1 - 0s - loss: 0.0164 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 948/1000\n",
            "1/1 - 0s - loss: 0.0164 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 949/1000\n",
            "1/1 - 0s - loss: 0.0163 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 950/1000\n",
            "1/1 - 0s - loss: 0.0163 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 951/1000\n",
            "1/1 - 0s - loss: 0.0162 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
            "Epoch 952/1000\n",
            "1/1 - 0s - loss: 0.0162 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 953/1000\n",
            "1/1 - 0s - loss: 0.0161 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 954/1000\n",
            "1/1 - 0s - loss: 0.0161 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 955/1000\n",
            "1/1 - 0s - loss: 0.0160 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 956/1000\n",
            "1/1 - 0s - loss: 0.0160 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 957/1000\n",
            "1/1 - 0s - loss: 0.0159 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 958/1000\n",
            "1/1 - 0s - loss: 0.0159 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 959/1000\n",
            "1/1 - 0s - loss: 0.0158 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 960/1000\n",
            "1/1 - 0s - loss: 0.0158 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 961/1000\n",
            "1/1 - 0s - loss: 0.0157 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 962/1000\n",
            "1/1 - 0s - loss: 0.0157 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 963/1000\n",
            "1/1 - 0s - loss: 0.0156 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 964/1000\n",
            "1/1 - 0s - loss: 0.0156 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 965/1000\n",
            "1/1 - 0s - loss: 0.0155 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 966/1000\n",
            "1/1 - 0s - loss: 0.0155 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 967/1000\n",
            "1/1 - 0s - loss: 0.0154 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 968/1000\n",
            "1/1 - 0s - loss: 0.0154 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 969/1000\n",
            "1/1 - 0s - loss: 0.0153 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 970/1000\n",
            "1/1 - 0s - loss: 0.0153 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 971/1000\n",
            "1/1 - 0s - loss: 0.0153 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 972/1000\n",
            "1/1 - 0s - loss: 0.0152 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 973/1000\n",
            "1/1 - 0s - loss: 0.0152 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 974/1000\n",
            "1/1 - 0s - loss: 0.0151 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 975/1000\n",
            "1/1 - 0s - loss: 0.0151 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 976/1000\n",
            "1/1 - 0s - loss: 0.0150 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 977/1000\n",
            "1/1 - 0s - loss: 0.0150 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 978/1000\n",
            "1/1 - 0s - loss: 0.0149 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 979/1000\n",
            "1/1 - 0s - loss: 0.0149 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 980/1000\n",
            "1/1 - 0s - loss: 0.0148 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 981/1000\n",
            "1/1 - 0s - loss: 0.0148 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 982/1000\n",
            "1/1 - 0s - loss: 0.0148 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 983/1000\n",
            "1/1 - 0s - loss: 0.0147 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 984/1000\n",
            "1/1 - 0s - loss: 0.0147 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 985/1000\n",
            "1/1 - 0s - loss: 0.0146 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 986/1000\n",
            "1/1 - 0s - loss: 0.0146 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "Epoch 987/1000\n",
            "1/1 - 0s - loss: 0.0145 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 988/1000\n",
            "1/1 - 0s - loss: 0.0145 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 989/1000\n",
            "1/1 - 0s - loss: 0.0145 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 990/1000\n",
            "1/1 - 0s - loss: 0.0144 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 991/1000\n",
            "1/1 - 0s - loss: 0.0144 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 992/1000\n",
            "1/1 - 0s - loss: 0.0143 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 993/1000\n",
            "1/1 - 0s - loss: 0.0143 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 994/1000\n",
            "1/1 - 0s - loss: 0.0142 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 995/1000\n",
            "1/1 - 0s - loss: 0.0142 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 996/1000\n",
            "1/1 - 0s - loss: 0.0142 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 997/1000\n",
            "1/1 - 0s - loss: 0.0141 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 998/1000\n",
            "1/1 - 0s - loss: 0.0141 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 999/1000\n",
            "1/1 - 0s - loss: 0.0140 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 1000/1000\n",
            "1/1 - 0s - loss: 0.0140 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
            "\n",
            "Model2 Evaluation\n",
            "1/1 - 0s - loss: 2.4718 - accuracy: 0.3077 - 273ms/epoch - 273ms/step\n",
            "\n",
            "Misclassified test images\n",
            "Target char: A and Predicted char: G\n",
            "Target char: B and Predicted char: I\n",
            "Target char: D and Predicted char: S\n",
            "Target char: F and Predicted char: T\n",
            "Target char: H and Predicted char: K\n",
            "Target char: L and Predicted char: I\n",
            "Target char: M and Predicted char: K\n",
            "Target char: N and Predicted char: D\n",
            "Target char: O and Predicted char: G\n",
            "Target char: P and Predicted char: F\n",
            "Target char: Q and Predicted char: G\n",
            "Target char: R and Predicted char: I\n",
            "Target char: S and Predicted char: B\n",
            "Target char: U and Predicted char: G\n",
            "Target char: V and Predicted char: S\n",
            "Target char: W and Predicted char: D\n",
            "Target char: X and Predicted char: I\n",
            "Target char: Z and Predicted char: T\n"
          ]
        }
      ],
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(91, input_shape = (256,), activation = 'relu'))\n",
        "model2.add(Dense(91, activation = 'relu'))\n",
        "model2.add(Dense(91, activation = 'relu'))\n",
        "model2.add(Dense(91, activation = 'softmax'))\n",
        "\n",
        "\n",
        "#################################### Repeat Problem 4 ####################################\n",
        "ord_charset = []\n",
        "for num in range(0, 52):\n",
        "  ord_charset.append(ord(TRAINING_SET[num][0]))\n",
        "one_hot = tf.keras.utils.to_categorical(ord_charset, max(ord_charset) + 1)\n",
        "\n",
        "data = train_set\n",
        "labels = one_hot\n",
        "\n",
        "model2.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model2.fit(\n",
        "    data,\n",
        "    labels,\n",
        "    epochs = 1000,\n",
        "    verbose = 2,\n",
        "    batch_size = 52,\n",
        "    callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3),\n",
        "    shuffle = True,\n",
        "    initial_epoch = 0\n",
        "    )\n",
        "\n",
        "print()\n",
        "\n",
        "\n",
        "#################################### Problem 5 ####################################\n",
        "ord_charset = []\n",
        "for num in range(0, 26):\n",
        "  ord_charset.append(ord(TEST_SET[num][0]))\n",
        "one_hot = tf.keras.utils.to_categorical(ord_charset, max(ord_charset) + 1)\n",
        "\n",
        "data = test_set\n",
        "labels = one_hot\n",
        "\n",
        "predictions = model2.predict(x = data, batch_size = 26, verbose = 0)\n",
        "\n",
        "prediction_array = []\n",
        "rounded_predictions = np.argmax(predictions, axis = -1)\n",
        "for i in rounded_predictions:\n",
        "  prediction_array.append(i)\n",
        "\n",
        "answers_array = []\n",
        "rounded_answers = np.argmax(labels, axis = -1)\n",
        "for i in rounded_answers:\n",
        "  answers_array.append(i)\n",
        "\n",
        "print(\"Model2 Evaluation\")\n",
        "model2.evaluate(\n",
        "    data,\n",
        "    labels,\n",
        "    batch_size = 52,\n",
        "    verbose = 2,\n",
        "    sample_weight = None\n",
        ")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Misclassified test images\")\n",
        "for i in range(0, 26):\n",
        "  if answers_array[i] != prediction_array[i]:\n",
        "    print(\"Target char:\", chr(int(answers_array[i])), \"and Predicted char:\", chr(int(prediction_array[i])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DGyjD8GIj1b"
      },
      "source": [
        "**8. Repeat experiment (7), adding additional layers of the same size until the message is decoded correctly. What results do you observe?**\n",
        "\n",
        ">  * As we added more additional layers, the loss increased which resulted in a lower accuracy. Our model runs into the problem of overfitting since neural networks tend to be low bias and high variance. Therefore, with a small dataset, our neural network may not be able to generalize to new unseen data even though our training set accuracy was high."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdEGY6srIl-8",
        "outputId": "d5a1c141-ec17-4b44-90cd-39afa1266c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model2 Evaluation\n",
            "1/1 - 0s - loss: 0.6574 - accuracy: 0.8387 - 277ms/epoch - 277ms/step\n",
            "\n",
            "Misclassified test images\n",
            "Target char: H and Predicted char: W\n",
            "Target char: X and Predicted char: I\n",
            "Target char: Z and Predicted char: T\n",
            "Target char: R and Predicted char: I\n",
            "Target char: D and Predicted char: S\n",
            "\n",
            "All classified test images\n",
            "Target char: T and Predicted char: T\n",
            "Target char: H and Predicted char: W\n",
            "Target char: E and Predicted char: E\n",
            "Target char: F and Predicted char: F\n",
            "Target char: I and Predicted char: I\n",
            "Target char: V and Predicted char: V\n",
            "Target char: E and Predicted char: E\n",
            "Target char: B and Predicted char: B\n",
            "Target char: O and Predicted char: O\n",
            "Target char: X and Predicted char: I\n",
            "Target char: I and Predicted char: I\n",
            "Target char: N and Predicted char: N\n",
            "Target char: G and Predicted char: G\n",
            "Target char: W and Predicted char: W\n",
            "Target char: I and Predicted char: I\n",
            "Target char: Z and Predicted char: T\n",
            "Target char: A and Predicted char: A\n",
            "Target char: R and Predicted char: I\n",
            "Target char: D and Predicted char: S\n",
            "Target char: S and Predicted char: S\n",
            "Target char: J and Predicted char: J\n",
            "Target char: U and Predicted char: U\n",
            "Target char: M and Predicted char: M\n",
            "Target char: P and Predicted char: P\n",
            "Target char: Q and Predicted char: Q\n",
            "Target char: U and Predicted char: U\n"
          ]
        }
      ],
      "source": [
        "ord_charset = []\n",
        "msg = list('THEFIVEBOXINGWIZARDSJUMPQUICKLY')\n",
        "for num in range(0, len(msg_set)):\n",
        "  ord_charset.append(ord(msg[num]))\n",
        "one_hot = tf.keras.utils.to_categorical(ord_charset, max(ord_charset) + 1)\n",
        "\n",
        "data = msg_set\n",
        "labels = one_hot\n",
        "\n",
        "predictions = model2.predict(x = data, batch_size = 31, verbose = 0)\n",
        "\n",
        "prediction_array = []\n",
        "rounded_predictions = np.argmax(predictions, axis = -1)\n",
        "for i in rounded_predictions:\n",
        "  prediction_array.append(i)\n",
        "\n",
        "answers_array = []\n",
        "rounded_answers = np.argmax(labels, axis = -1)\n",
        "for i in rounded_answers:\n",
        "  answers_array.append(i)\n",
        "\n",
        "print(\"Model2 Evaluation\")\n",
        "model2.evaluate(\n",
        "    data,\n",
        "    labels,\n",
        "    batch_size = 31,\n",
        "    verbose = 2,\n",
        "    sample_weight = None\n",
        ")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Misclassified test images\")\n",
        "for i in range(0, 26):\n",
        "  if answers_array[i] != prediction_array[i]:\n",
        "    print(\"Target char:\", chr(int(answers_array[i])), \"and Predicted char:\", chr(int(prediction_array[i])))\n",
        "\n",
        "print(\"\\nAll classified test images\")\n",
        "for i in range(0, 26):\n",
        "    print(\"Target char:\", chr(int(answers_array[i])), \"and Predicted char:\", chr(int(prediction_array[i])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xKFK0awLO9O"
      },
      "source": [
        "#**===== PART 2 =====**\n",
        "---\n",
        "As described in Section 1.8 of the textbook, the MNIST dataset of handwritten digits is a standard benchmark for computer vision. This dataset is included with Keras and is a good introduction to working with larger datasets.\n",
        "This notebook by Francois Chollet creates a simple Multilayer Perceptron as described in Section 2.1 of Deep Learning with Python, Second Edition. (Recall that this book is available from the library.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSXsvJepLlM1"
      },
      "source": [
        "**9. Load the EMNIST Letters dataset, and use plt.imshow() to verify that the image data has been loaded correctly and that the corresponding labels are correct.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHq9-V7wL0X7",
        "outputId": "a09eb258-ad8d-41e6-9daa-fa0cdf80fd62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train_images', 'train_labels', 'validate_images', 'validate_labels', 'test_images', 'test_labels']\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "emnist = np.load('emnist_letters.npz')\n",
        "print(emnist.files)\n",
        "\n",
        "train_images = emnist['train_images']\n",
        "train_labels = emnist['train_labels']\n",
        "validate_images = emnist['validate_images']\n",
        "validate_labels = emnist['validate_labels']\n",
        "test_images = emnist['test_images']\n",
        "test_labels = emnist['test_labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8xOj7dDWGopi",
        "outputId": "7a3401df-36c3-4246-bc56-0573e27d05c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff65020e790>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "trainLetter = train_images[0].reshape(28,28)\n",
        "plt.imshow(trainLetter, cmap='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "3gPpCXrxGpR5",
        "outputId": "5cd8b08e-78cf-446d-e370-32f22adc0e95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff646c31290>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "validateLetter = validate_images[0].reshape(28,28)\n",
        "plt.imshow(validateLetter, cmap='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "jXs9mUyyGrbZ",
        "outputId": "32afe897-848e-4df3-c607-c01d4457efa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff646b95b50>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "testLetter = test_images[0].reshape(28,28)\n",
        "plt.imshow(testLetter, cmap='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx7QHU0lL4K4",
        "outputId": "805bb0e7-8395-402f-8e69-114f7a2bb1d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(104000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EEvDp_kMXRg",
        "outputId": "7ca700a1-f750-4936-ea56-be13c0e23117"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104000"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vttmgp7OMYwz",
        "outputId": "fa6fa430-0dc0-42e5-b23a-b380bfdda072"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSvtrXUFMayx",
        "outputId": "a12c5b9e-7493-41f0-8820-ee6bec87f864"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20800, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h9blP64McUa",
        "outputId": "1ae0b7f8-d862-4ade-efba-ea9346f74b26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20800"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3DBvXQTMcvA",
        "outputId": "0b66dd10-63a3-42b0-9955-2a3f7d71bc7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWb9k-PDOg0B"
      },
      "source": [
        "**10a. Apply the network architecture from Cholletâ€™s MNIST notebook to the EMNIST Letters data. (You will need to modify the numbers of inputs and outputs, but should leave the dense layer intact.)**\n",
        "\n",
        "**11. Keeping the same number of layers in the network (i.e. an MLP with a single hidden layer), modify the architecture to improve the accuracy. You will need to decide on an appropriate number of neurons in the hidden layer. Keep in mind that:**\n",
        "\n",
        ">a. There are 27 classes rather than 10, so you will need a larger hidden layer than the MNIST network.\n",
        "\n",
        ">b. In addition to having more classes, EMNIST Letters mixes upper- and lowercase letters within each class, so even with enough neurons in the hidden layer, your accuracy is likely to be lower.  See the details in the EMNIST paper for the kind of performance you might reasonably expect.\n",
        "\n",
        ">c. The Keras fit() method can take a validation_data parameter in order to evaluate metrics on the validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xceTl9o7MjdL"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Applied Chollet's MNist network architecture\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(27, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csVywt9XMvb1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56MG6JoXMxV9"
      },
      "outputs": [],
      "source": [
        "# Reshape 1D images array to have 2D shape (784,)\n",
        "train_images = train_images.reshape((104000, 28 * 28))\n",
        "validate_images = validate_images.reshape((20800, 28 * 28))\n",
        "test_images = test_images.reshape((20800, 28 * 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TouMUa1yMzWm",
        "outputId": "eed2aaf1-5abd-4f64-9fa2-051b066cb694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "813/813 [==============================] - 10s 11ms/step - loss: 0.7682 - accuracy: 0.7750 - val_loss: 0.4768 - val_accuracy: 0.8570\n",
            "Epoch 2/5\n",
            "813/813 [==============================] - 9s 11ms/step - loss: 0.3941 - accuracy: 0.8783 - val_loss: 0.3814 - val_accuracy: 0.8846\n",
            "Epoch 3/5\n",
            "813/813 [==============================] - 9s 11ms/step - loss: 0.3110 - accuracy: 0.9003 - val_loss: 0.3319 - val_accuracy: 0.8976\n",
            "Epoch 4/5\n",
            "813/813 [==============================] - 9s 11ms/step - loss: 0.2632 - accuracy: 0.9151 - val_loss: 0.3162 - val_accuracy: 0.9002\n",
            "Epoch 5/5\n",
            "813/813 [==============================] - 9s 11ms/step - loss: 0.2323 - accuracy: 0.9233 - val_loss: 0.3094 - val_accuracy: 0.9038\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6503340d0>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128, validation_data=(validate_images, validate_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8-aMT1TO5Xl"
      },
      "source": [
        "**10b. What accuracy do you achieve? How does this compare with the accuracy for MNIST?**\n",
        "\n",
        ">  *   As seen below in the next 2 cells, our accuracy is around 90.13%, where the accuracy for MNIST is around 98.08%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmS2TTvuM2ow",
        "outputId": "d41edd54-68e6-4c9d-851a-8bade1e104be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "650/650 [==============================] - 3s 4ms/step - loss: 0.3178 - accuracy: 0.9013\n",
            "test_acc: 0.9012981057167053\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLrvCvZLHzQA"
      },
      "source": [
        "**MNIST accuracy from notebook by Francois Chollet:**\n",
        "\n",
        "313/313 [==============================] - 1s 3ms/step - loss: 0.0688 - accuracy: 0.9808\n",
        "\n",
        "test_acc: 0.9807999730110168"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWnMLAFNH5cY"
      },
      "source": [
        "**12a. The Keras examples include a Simple MNIST convnet. Note the accuracy obtained by that code compared to the previous example from Chollet.\n",
        "Rather than building a deeper MLP, letâ€™s apply this architecture to the EMNIST Letters data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6swDCNYeH_Bc",
        "outputId": "98181212-96ed-4433-9fb0-6bc9a74e461a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (104000, 28, 28, 1)\n",
            "104000 train samples\n",
            "20800 test samples\n"
          ]
        }
      ],
      "source": [
        "# Reshape 1D images array to have 2D shape (28, 28)\n",
        "train_images = train_images.reshape((104000, 28, 28))\n",
        "validate_images = validate_images.reshape((20800, 28, 28))\n",
        "test_images = test_images.reshape((20800, 28, 28))\n",
        "\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "train_images = np.expand_dims(train_images, -1)\n",
        "validate_images = np.expand_dims(validate_images, -1)\n",
        "test_images = np.expand_dims(test_images, -1)\n",
        "print(\"x_train shape:\", train_images.shape)\n",
        "print(train_images.shape[0], \"train samples\")\n",
        "print(test_images.shape[0], \"test samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8pHd_O7IBQ7",
        "outputId": "1b14cebd-e904-4819-ae10-0c2ea9ed1f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 27)                43227     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,043\n",
            "Trainable params: 62,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Chollet's Simple MNIST covnet architecture applied to our EMNIST Letters data\n",
        "model = keras.Sequential([\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(27, activation=\"softmax\"),\n",
        "    ])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iphRw610IDmH"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e3S8Uq5IFTN"
      },
      "source": [
        "**12b. What accuracy do you achieve? How does this compare with the accuracy for the MNIST dataset?**\n",
        "\n",
        "> * As seen below in the next 3 cells, our accuracy is around 92%, where the accuracy for MNIST is around 99.22%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmaKuUSJIHvO",
        "outputId": "14fc5579-41a8-408b-a50b-d7ba108903cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "813/813 [==============================] - 90s 110ms/step - loss: 0.8306 - accuracy: 0.7472 - val_loss: 0.4057 - val_accuracy: 0.8747\n",
            "Epoch 2/15\n",
            "813/813 [==============================] - 89s 110ms/step - loss: 0.4492 - accuracy: 0.8592 - val_loss: 0.3262 - val_accuracy: 0.8988\n",
            "Epoch 3/15\n",
            "813/813 [==============================] - 90s 110ms/step - loss: 0.3790 - accuracy: 0.8807 - val_loss: 0.2920 - val_accuracy: 0.9098\n",
            "Epoch 4/15\n",
            "813/813 [==============================] - 90s 111ms/step - loss: 0.3412 - accuracy: 0.8920 - val_loss: 0.2663 - val_accuracy: 0.9173\n",
            "Epoch 5/15\n",
            "813/813 [==============================] - 91s 111ms/step - loss: 0.3155 - accuracy: 0.8991 - val_loss: 0.2523 - val_accuracy: 0.9217\n",
            "Epoch 6/15\n",
            "813/813 [==============================] - 89s 110ms/step - loss: 0.3007 - accuracy: 0.9038 - val_loss: 0.2423 - val_accuracy: 0.9248\n",
            "Epoch 7/15\n",
            "813/813 [==============================] - 90s 110ms/step - loss: 0.2822 - accuracy: 0.9089 - val_loss: 0.2397 - val_accuracy: 0.9247\n",
            "Epoch 8/15\n",
            "813/813 [==============================] - 90s 110ms/step - loss: 0.2729 - accuracy: 0.9108 - val_loss: 0.2228 - val_accuracy: 0.9311\n",
            "Epoch 9/15\n",
            "813/813 [==============================] - 91s 112ms/step - loss: 0.2631 - accuracy: 0.9144 - val_loss: 0.2197 - val_accuracy: 0.9301\n",
            "Epoch 10/15\n",
            "813/813 [==============================] - 91s 112ms/step - loss: 0.2570 - accuracy: 0.9148 - val_loss: 0.2203 - val_accuracy: 0.9312\n",
            "Epoch 11/15\n",
            "813/813 [==============================] - 90s 111ms/step - loss: 0.2476 - accuracy: 0.9174 - val_loss: 0.2168 - val_accuracy: 0.9338\n",
            "Epoch 12/15\n",
            "813/813 [==============================] - 91s 112ms/step - loss: 0.2409 - accuracy: 0.9200 - val_loss: 0.2134 - val_accuracy: 0.9332\n",
            "Epoch 13/15\n",
            "813/813 [==============================] - 91s 112ms/step - loss: 0.2379 - accuracy: 0.9209 - val_loss: 0.2076 - val_accuracy: 0.9353\n",
            "Epoch 14/15\n",
            "813/813 [==============================] - 91s 112ms/step - loss: 0.2347 - accuracy: 0.9220 - val_loss: 0.2055 - val_accuracy: 0.9351\n",
            "Epoch 15/15\n",
            "813/813 [==============================] - 91s 112ms/step - loss: 0.2275 - accuracy: 0.9236 - val_loss: 0.2077 - val_accuracy: 0.9340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff646bea850>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "model.fit(train_images, train_labels, epochs=15, batch_size=128, validation_data=(validate_images, validate_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYf2XL_jLIys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf0aa17-f89d-4928-9598-d14e1c1cfab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.2083428055047989\n",
            "Test accuracy: 0.9342788457870483\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(test_images, batch_size = 128, verbose = 0)\n",
        "\n",
        "prediction_array = []\n",
        "rounded_predictions = np.argmax(predictions, axis = -1)\n",
        "for i in rounded_predictions:\n",
        "  prediction_array.append(i)\n",
        "\n",
        "answers_array = []\n",
        "rounded_answers = np.argmax(test_labels, axis = -1)\n",
        "for i in rounded_answers:\n",
        "  answers_array.append(i)\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3gAlIURISWo"
      },
      "source": [
        "**Simple MNIST convnet accuracy from Francois Chollet**\n",
        "\n",
        "Test loss: 0.023950600996613503\n",
        "\n",
        "Test accuracy: 0.9922000169754028"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5t-VR6RHa0f"
      },
      "source": [
        "**13a. Use plt.imshow() to view some of the misclassified images and examine their labels.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbt3dMb4HcrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f978c1d-4fff-4700-eba3-d4bad57603b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Misclassified test images\n",
            "Index # 44 Target Class: 1 and Predicted Class: 21\n",
            "Index # 68 Target Class: 1 and Predicted Class: 17\n",
            "Index # 76 Target Class: 1 and Predicted Class: 17\n",
            "Index # 90 Target Class: 1 and Predicted Class: 17\n",
            "Index # 119 Target Class: 1 and Predicted Class: 4\n",
            "Index # 191 Target Class: 1 and Predicted Class: 4\n",
            "Index # 201 Target Class: 1 and Predicted Class: 26\n",
            "Index # 207 Target Class: 1 and Predicted Class: 3\n",
            "Index # 209 Target Class: 1 and Predicted Class: 7\n",
            "Index # 214 Target Class: 1 and Predicted Class: 26\n",
            "Index # 218 Target Class: 1 and Predicted Class: 7\n",
            "Index # 240 Target Class: 1 and Predicted Class: 17\n",
            "Index # 253 Target Class: 1 and Predicted Class: 14\n",
            "Index # 254 Target Class: 1 and Predicted Class: 17\n",
            "Index # 288 Target Class: 1 and Predicted Class: 13\n",
            "Index # 289 Target Class: 1 and Predicted Class: 7\n",
            "Index # 290 Target Class: 1 and Predicted Class: 4\n",
            "Index # 299 Target Class: 1 and Predicted Class: 8\n",
            "Index # 350 Target Class: 1 and Predicted Class: 8\n",
            "Index # 354 Target Class: 1 and Predicted Class: 17\n",
            "Index # 365 Target Class: 1 and Predicted Class: 17\n",
            "Index # 394 Target Class: 1 and Predicted Class: 4\n",
            "Index # 396 Target Class: 1 and Predicted Class: 24\n",
            "Index # 423 Target Class: 1 and Predicted Class: 14\n",
            "Index # 439 Target Class: 1 and Predicted Class: 5\n",
            "Index # 440 Target Class: 1 and Predicted Class: 7\n",
            "Index # 507 Target Class: 1 and Predicted Class: 17\n",
            "Index # 546 Target Class: 1 and Predicted Class: 4\n",
            "Index # 554 Target Class: 1 and Predicted Class: 21\n",
            "Index # 563 Target Class: 1 and Predicted Class: 17\n",
            "Index # 582 Target Class: 1 and Predicted Class: 17\n",
            "Index # 587 Target Class: 1 and Predicted Class: 15\n",
            "Index # 593 Target Class: 1 and Predicted Class: 14\n",
            "Index # 617 Target Class: 1 and Predicted Class: 8\n",
            "Index # 630 Target Class: 1 and Predicted Class: 17\n",
            "Index # 639 Target Class: 1 and Predicted Class: 17\n",
            "Index # 648 Target Class: 1 and Predicted Class: 17\n",
            "Index # 651 Target Class: 1 and Predicted Class: 4\n",
            "Index # 716 Target Class: 1 and Predicted Class: 26\n",
            "Index # 722 Target Class: 1 and Predicted Class: 13\n",
            "Index # 773 Target Class: 1 and Predicted Class: 7\n",
            "Index # 789 Target Class: 1 and Predicted Class: 17\n",
            "Index # 798 Target Class: 1 and Predicted Class: 4\n",
            "Index # 829 Target Class: 2 and Predicted Class: 8\n",
            "Index # 830 Target Class: 2 and Predicted Class: 4\n",
            "Index # 837 Target Class: 2 and Predicted Class: 5\n",
            "Index # 852 Target Class: 2 and Predicted Class: 24\n",
            "Index # 858 Target Class: 2 and Predicted Class: 11\n",
            "Index # 868 Target Class: 2 and Predicted Class: 7\n",
            "Index # 881 Target Class: 2 and Predicted Class: 12\n",
            "Index # 906 Target Class: 2 and Predicted Class: 8\n",
            "Index # 909 Target Class: 2 and Predicted Class: 7\n",
            "Index # 911 Target Class: 2 and Predicted Class: 9\n",
            "Index # 990 Target Class: 2 and Predicted Class: 12\n",
            "Index # 1000 Target Class: 2 and Predicted Class: 21\n",
            "Index # 1043 Target Class: 2 and Predicted Class: 7\n",
            "Index # 1064 Target Class: 2 and Predicted Class: 14\n",
            "Index # 1070 Target Class: 2 and Predicted Class: 18\n",
            "Index # 1082 Target Class: 2 and Predicted Class: 8\n",
            "Index # 1111 Target Class: 2 and Predicted Class: 8\n",
            "Index # 1179 Target Class: 2 and Predicted Class: 18\n",
            "Index # 1219 Target Class: 2 and Predicted Class: 4\n",
            "Index # 1225 Target Class: 2 and Predicted Class: 15\n",
            "Index # 1245 Target Class: 2 and Predicted Class: 17\n",
            "Index # 1323 Target Class: 2 and Predicted Class: 8\n",
            "Index # 1360 Target Class: 2 and Predicted Class: 15\n",
            "Index # 1393 Target Class: 2 and Predicted Class: 1\n",
            "Index # 1395 Target Class: 2 and Predicted Class: 8\n",
            "Index # 1409 Target Class: 2 and Predicted Class: 26\n",
            "Index # 1419 Target Class: 2 and Predicted Class: 4\n",
            "Index # 1468 Target Class: 2 and Predicted Class: 8\n",
            "Index # 1524 Target Class: 2 and Predicted Class: 8\n",
            "Index # 1570 Target Class: 2 and Predicted Class: 26\n",
            "Index # 1592 Target Class: 2 and Predicted Class: 5\n",
            "Index # 1642 Target Class: 3 and Predicted Class: 5\n",
            "Index # 1671 Target Class: 3 and Predicted Class: 5\n",
            "Index # 1677 Target Class: 3 and Predicted Class: 4\n",
            "Index # 1702 Target Class: 3 and Predicted Class: 12\n",
            "Index # 1746 Target Class: 3 and Predicted Class: 5\n",
            "Index # 1769 Target Class: 3 and Predicted Class: 19\n",
            "Index # 1872 Target Class: 3 and Predicted Class: 5\n",
            "Index # 1899 Target Class: 3 and Predicted Class: 5\n",
            "Index # 2016 Target Class: 3 and Predicted Class: 5\n",
            "Index # 2038 Target Class: 3 and Predicted Class: 7\n",
            "Index # 2055 Target Class: 3 and Predicted Class: 12\n",
            "Index # 2069 Target Class: 3 and Predicted Class: 5\n",
            "Index # 2089 Target Class: 3 and Predicted Class: 17\n",
            "Index # 2137 Target Class: 3 and Predicted Class: 5\n",
            "Index # 2179 Target Class: 3 and Predicted Class: 15\n",
            "Index # 2180 Target Class: 3 and Predicted Class: 5\n",
            "Index # 2209 Target Class: 3 and Predicted Class: 21\n",
            "Index # 2273 Target Class: 3 and Predicted Class: 26\n",
            "Index # 2276 Target Class: 3 and Predicted Class: 21\n",
            "Index # 2281 Target Class: 3 and Predicted Class: 18\n",
            "Index # 2345 Target Class: 3 and Predicted Class: 5\n",
            "Index # 2408 Target Class: 4 and Predicted Class: 16\n",
            "Index # 2409 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2414 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2426 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2435 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2447 Target Class: 4 and Predicted Class: 10\n",
            "Index # 2468 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2481 Target Class: 4 and Predicted Class: 9\n",
            "Index # 2493 Target Class: 4 and Predicted Class: 16\n",
            "Index # 2498 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2511 Target Class: 4 and Predicted Class: 1\n",
            "Index # 2535 Target Class: 4 and Predicted Class: 17\n",
            "Index # 2558 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2583 Target Class: 4 and Predicted Class: 9\n",
            "Index # 2616 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2621 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2626 Target Class: 4 and Predicted Class: 1\n",
            "Index # 2629 Target Class: 4 and Predicted Class: 7\n",
            "Index # 2639 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2662 Target Class: 4 and Predicted Class: 16\n",
            "Index # 2667 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2668 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2699 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2702 Target Class: 4 and Predicted Class: 2\n",
            "Index # 2706 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2741 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2768 Target Class: 4 and Predicted Class: 1\n",
            "Index # 2770 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2771 Target Class: 4 and Predicted Class: 16\n",
            "Index # 2795 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2803 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2840 Target Class: 4 and Predicted Class: 10\n",
            "Index # 2853 Target Class: 4 and Predicted Class: 10\n",
            "Index # 2878 Target Class: 4 and Predicted Class: 1\n",
            "Index # 2882 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2920 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2921 Target Class: 4 and Predicted Class: 14\n",
            "Index # 2947 Target Class: 4 and Predicted Class: 1\n",
            "Index # 2948 Target Class: 4 and Predicted Class: 15\n",
            "Index # 2960 Target Class: 4 and Predicted Class: 15\n",
            "Index # 3000 Target Class: 4 and Predicted Class: 2\n",
            "Index # 3009 Target Class: 4 and Predicted Class: 15\n",
            "Index # 3013 Target Class: 4 and Predicted Class: 5\n",
            "Index # 3014 Target Class: 4 and Predicted Class: 1\n",
            "Index # 3030 Target Class: 4 and Predicted Class: 2\n",
            "Index # 3047 Target Class: 4 and Predicted Class: 17\n",
            "Index # 3048 Target Class: 4 and Predicted Class: 17\n",
            "Index # 3067 Target Class: 4 and Predicted Class: 15\n",
            "Index # 3073 Target Class: 4 and Predicted Class: 16\n",
            "Index # 3092 Target Class: 4 and Predicted Class: 1\n",
            "Index # 3097 Target Class: 4 and Predicted Class: 15\n",
            "Index # 3102 Target Class: 4 and Predicted Class: 1\n",
            "Index # 3112 Target Class: 4 and Predicted Class: 1\n",
            "Index # 3125 Target Class: 4 and Predicted Class: 14\n",
            "Index # 3136 Target Class: 4 and Predicted Class: 15\n",
            "Index # 3165 Target Class: 4 and Predicted Class: 15\n",
            "Index # 3169 Target Class: 4 and Predicted Class: 15\n",
            "Index # 3183 Target Class: 4 and Predicted Class: 17\n",
            "Index # 3204 Target Class: 5 and Predicted Class: 3\n",
            "Index # 3226 Target Class: 5 and Predicted Class: 3\n",
            "Index # 3264 Target Class: 5 and Predicted Class: 1\n",
            "Index # 3315 Target Class: 5 and Predicted Class: 1\n",
            "Index # 3319 Target Class: 5 and Predicted Class: 1\n",
            "Index # 3335 Target Class: 5 and Predicted Class: 7\n",
            "Index # 3369 Target Class: 5 and Predicted Class: 6\n",
            "Index # 3430 Target Class: 5 and Predicted Class: 3\n",
            "Index # 3479 Target Class: 5 and Predicted Class: 7\n",
            "Index # 3483 Target Class: 5 and Predicted Class: 10\n",
            "Index # 3500 Target Class: 5 and Predicted Class: 9\n",
            "Index # 3511 Target Class: 5 and Predicted Class: 12\n",
            "Index # 3573 Target Class: 5 and Predicted Class: 10\n",
            "Index # 3582 Target Class: 5 and Predicted Class: 2\n",
            "Index # 3628 Target Class: 5 and Predicted Class: 16\n",
            "Index # 3656 Target Class: 5 and Predicted Class: 18\n",
            "Index # 3677 Target Class: 5 and Predicted Class: 3\n",
            "Index # 3711 Target Class: 5 and Predicted Class: 11\n",
            "Index # 3731 Target Class: 5 and Predicted Class: 3\n",
            "Index # 3733 Target Class: 5 and Predicted Class: 3\n",
            "Index # 3740 Target Class: 5 and Predicted Class: 7\n",
            "Index # 3754 Target Class: 5 and Predicted Class: 2\n",
            "Index # 3799 Target Class: 5 and Predicted Class: 16\n",
            "Index # 3844 Target Class: 5 and Predicted Class: 11\n",
            "Index # 3927 Target Class: 5 and Predicted Class: 3\n",
            "Index # 3983 Target Class: 5 and Predicted Class: 3\n",
            "Index # 3997 Target Class: 5 and Predicted Class: 3\n",
            "Index # 4071 Target Class: 6 and Predicted Class: 5\n",
            "Index # 4072 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4078 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4100 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4166 Target Class: 6 and Predicted Class: 10\n",
            "Index # 4183 Target Class: 6 and Predicted Class: 16\n",
            "Index # 4186 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4196 Target Class: 6 and Predicted Class: 16\n",
            "Index # 4198 Target Class: 6 and Predicted Class: 16\n",
            "Index # 4206 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4208 Target Class: 6 and Predicted Class: 7\n",
            "Index # 4228 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4229 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4248 Target Class: 6 and Predicted Class: 18\n",
            "Index # 4265 Target Class: 6 and Predicted Class: 5\n",
            "Index # 4267 Target Class: 6 and Predicted Class: 16\n",
            "Index # 4332 Target Class: 6 and Predicted Class: 16\n",
            "Index # 4347 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4364 Target Class: 6 and Predicted Class: 19\n",
            "Index # 4378 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4384 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4410 Target Class: 6 and Predicted Class: 7\n",
            "Index # 4438 Target Class: 6 and Predicted Class: 16\n",
            "Index # 4472 Target Class: 6 and Predicted Class: 24\n",
            "Index # 4486 Target Class: 6 and Predicted Class: 18\n",
            "Index # 4555 Target Class: 6 and Predicted Class: 3\n",
            "Index # 4570 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4594 Target Class: 6 and Predicted Class: 5\n",
            "Index # 4600 Target Class: 6 and Predicted Class: 18\n",
            "Index # 4613 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4632 Target Class: 6 and Predicted Class: 17\n",
            "Index # 4638 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4640 Target Class: 6 and Predicted Class: 4\n",
            "Index # 4657 Target Class: 6 and Predicted Class: 3\n",
            "Index # 4658 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4699 Target Class: 6 and Predicted Class: 18\n",
            "Index # 4724 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4742 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4746 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4748 Target Class: 6 and Predicted Class: 10\n",
            "Index # 4755 Target Class: 6 and Predicted Class: 7\n",
            "Index # 4759 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4784 Target Class: 6 and Predicted Class: 20\n",
            "Index # 4806 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4810 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4811 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4818 Target Class: 7 and Predicted Class: 10\n",
            "Index # 4836 Target Class: 7 and Predicted Class: 3\n",
            "Index # 4838 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4841 Target Class: 7 and Predicted Class: 1\n",
            "Index # 4849 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4872 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4881 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4891 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4899 Target Class: 7 and Predicted Class: 11\n",
            "Index # 4904 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4913 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4914 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4922 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4923 Target Class: 7 and Predicted Class: 2\n",
            "Index # 4939 Target Class: 7 and Predicted Class: 1\n",
            "Index # 4941 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4942 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4947 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4975 Target Class: 7 and Predicted Class: 17\n",
            "Index # 4988 Target Class: 7 and Predicted Class: 3\n",
            "Index # 5005 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5007 Target Class: 7 and Predicted Class: 5\n",
            "Index # 5009 Target Class: 7 and Predicted Class: 25\n",
            "Index # 5010 Target Class: 7 and Predicted Class: 15\n",
            "Index # 5011 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5027 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5029 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5030 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5032 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5039 Target Class: 7 and Predicted Class: 3\n",
            "Index # 5052 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5057 Target Class: 7 and Predicted Class: 1\n",
            "Index # 5060 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5061 Target Class: 7 and Predicted Class: 1\n",
            "Index # 5062 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5068 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5071 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5072 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5080 Target Class: 7 and Predicted Class: 10\n",
            "Index # 5084 Target Class: 7 and Predicted Class: 19\n",
            "Index # 5092 Target Class: 7 and Predicted Class: 1\n",
            "Index # 5103 Target Class: 7 and Predicted Class: 1\n",
            "Index # 5106 Target Class: 7 and Predicted Class: 2\n",
            "Index # 5121 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5129 Target Class: 7 and Predicted Class: 19\n",
            "Index # 5132 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5133 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5134 Target Class: 7 and Predicted Class: 2\n",
            "Index # 5136 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5138 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5143 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5147 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5148 Target Class: 7 and Predicted Class: 11\n",
            "Index # 5154 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5156 Target Class: 7 and Predicted Class: 19\n",
            "Index # 5158 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5160 Target Class: 7 and Predicted Class: 3\n",
            "Index # 5169 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5170 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5171 Target Class: 7 and Predicted Class: 4\n",
            "Index # 5176 Target Class: 7 and Predicted Class: 19\n",
            "Index # 5189 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5191 Target Class: 7 and Predicted Class: 15\n",
            "Index # 5192 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5197 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5202 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5211 Target Class: 7 and Predicted Class: 1\n",
            "Index # 5212 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5221 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5233 Target Class: 7 and Predicted Class: 2\n",
            "Index # 5235 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5239 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5242 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5254 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5257 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5271 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5273 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5277 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5279 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5280 Target Class: 7 and Predicted Class: 2\n",
            "Index # 5288 Target Class: 7 and Predicted Class: 10\n",
            "Index # 5290 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5293 Target Class: 7 and Predicted Class: 1\n",
            "Index # 5300 Target Class: 7 and Predicted Class: 1\n",
            "Index # 5304 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5320 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5323 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5327 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5331 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5332 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5333 Target Class: 7 and Predicted Class: 14\n",
            "Index # 5334 Target Class: 7 and Predicted Class: 1\n",
            "Index # 5337 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5340 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5341 Target Class: 7 and Predicted Class: 1\n",
            "Index # 5354 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5362 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5371 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5372 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5373 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5378 Target Class: 7 and Predicted Class: 6\n",
            "Index # 5382 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5385 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5388 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5391 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5402 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5408 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5420 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5424 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5425 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5429 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5430 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5441 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5447 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5453 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5460 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5462 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5468 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5477 Target Class: 7 and Predicted Class: 25\n",
            "Index # 5480 Target Class: 7 and Predicted Class: 1\n",
            "Index # 5481 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5484 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5488 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5489 Target Class: 7 and Predicted Class: 2\n",
            "Index # 5505 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5508 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5523 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5527 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5537 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5544 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5549 Target Class: 7 and Predicted Class: 1\n",
            "Index # 5562 Target Class: 7 and Predicted Class: 1\n",
            "Index # 5576 Target Class: 7 and Predicted Class: 10\n",
            "Index # 5577 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5584 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5586 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5589 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5590 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5595 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5597 Target Class: 7 and Predicted Class: 17\n",
            "Index # 5602 Target Class: 8 and Predicted Class: 11\n",
            "Index # 5646 Target Class: 8 and Predicted Class: 24\n",
            "Index # 5678 Target Class: 8 and Predicted Class: 14\n",
            "Index # 5681 Target Class: 8 and Predicted Class: 11\n",
            "Index # 5693 Target Class: 8 and Predicted Class: 2\n",
            "Index # 5695 Target Class: 8 and Predicted Class: 4\n",
            "Index # 5702 Target Class: 8 and Predicted Class: 11\n",
            "Index # 5761 Target Class: 8 and Predicted Class: 14\n",
            "Index # 5771 Target Class: 8 and Predicted Class: 21\n",
            "Index # 5772 Target Class: 8 and Predicted Class: 14\n",
            "Index # 5806 Target Class: 8 and Predicted Class: 14\n",
            "Index # 5831 Target Class: 8 and Predicted Class: 24\n",
            "Index # 5842 Target Class: 8 and Predicted Class: 1\n",
            "Index # 5850 Target Class: 8 and Predicted Class: 14\n",
            "Index # 5855 Target Class: 8 and Predicted Class: 12\n",
            "Index # 5859 Target Class: 8 and Predicted Class: 11\n",
            "Index # 5892 Target Class: 8 and Predicted Class: 12\n",
            "Index # 5896 Target Class: 8 and Predicted Class: 14\n",
            "Index # 5897 Target Class: 8 and Predicted Class: 12\n",
            "Index # 5932 Target Class: 8 and Predicted Class: 4\n",
            "Index # 5935 Target Class: 8 and Predicted Class: 14\n",
            "Index # 5954 Target Class: 8 and Predicted Class: 14\n",
            "Index # 5960 Target Class: 8 and Predicted Class: 21\n",
            "Index # 5996 Target Class: 8 and Predicted Class: 12\n",
            "Index # 6024 Target Class: 8 and Predicted Class: 24\n",
            "Index # 6029 Target Class: 8 and Predicted Class: 11\n",
            "Index # 6030 Target Class: 8 and Predicted Class: 11\n",
            "Index # 6039 Target Class: 8 and Predicted Class: 14\n",
            "Index # 6040 Target Class: 8 and Predicted Class: 14\n",
            "Index # 6064 Target Class: 8 and Predicted Class: 13\n",
            "Index # 6118 Target Class: 8 and Predicted Class: 11\n",
            "Index # 6190 Target Class: 8 and Predicted Class: 14\n",
            "Index # 6225 Target Class: 8 and Predicted Class: 12\n",
            "Index # 6230 Target Class: 8 and Predicted Class: 14\n",
            "Index # 6233 Target Class: 8 and Predicted Class: 13\n",
            "Index # 6237 Target Class: 8 and Predicted Class: 13\n",
            "Index # 6249 Target Class: 8 and Predicted Class: 14\n",
            "Index # 6258 Target Class: 8 and Predicted Class: 11\n",
            "Index # 6280 Target Class: 8 and Predicted Class: 21\n",
            "Index # 6283 Target Class: 8 and Predicted Class: 1\n",
            "Index # 6327 Target Class: 8 and Predicted Class: 21\n",
            "Index # 6359 Target Class: 8 and Predicted Class: 1\n",
            "Index # 6372 Target Class: 8 and Predicted Class: 13\n",
            "Index # 6387 Target Class: 8 and Predicted Class: 14\n",
            "Index # 6394 Target Class: 8 and Predicted Class: 14\n",
            "Index # 6399 Target Class: 8 and Predicted Class: 24\n",
            "Index # 6401 Target Class: 9 and Predicted Class: 14\n",
            "Index # 6405 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6406 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6413 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6428 Target Class: 9 and Predicted Class: 7\n",
            "Index # 6432 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6436 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6450 Target Class: 9 and Predicted Class: 10\n",
            "Index # 6452 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6456 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6467 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6470 Target Class: 9 and Predicted Class: 10\n",
            "Index # 6474 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6481 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6485 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6487 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6488 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6489 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6490 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6491 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6498 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6500 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6501 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6512 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6514 Target Class: 9 and Predicted Class: 17\n",
            "Index # 6520 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6523 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6540 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6541 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6546 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6547 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6550 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6551 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6552 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6557 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6571 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6577 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6587 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6597 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6599 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6608 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6612 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6613 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6619 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6620 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6633 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6638 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6660 Target Class: 9 and Predicted Class: 2\n",
            "Index # 6661 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6665 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6690 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6706 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6713 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6716 Target Class: 9 and Predicted Class: 7\n",
            "Index # 6717 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6720 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6733 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6748 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6759 Target Class: 9 and Predicted Class: 8\n",
            "Index # 6762 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6767 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6770 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6778 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6780 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6784 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6787 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6799 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6801 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6807 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6812 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6817 Target Class: 9 and Predicted Class: 22\n",
            "Index # 6824 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6840 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6843 Target Class: 9 and Predicted Class: 26\n",
            "Index # 6870 Target Class: 9 and Predicted Class: 10\n",
            "Index # 6872 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6873 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6875 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6879 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6880 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6881 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6882 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6887 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6893 Target Class: 9 and Predicted Class: 10\n",
            "Index # 6901 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6907 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6908 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6914 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6918 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6929 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6935 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6956 Target Class: 9 and Predicted Class: 20\n",
            "Index # 6959 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6963 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6964 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6966 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6976 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6983 Target Class: 9 and Predicted Class: 12\n",
            "Index # 6989 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7003 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7005 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7011 Target Class: 9 and Predicted Class: 24\n",
            "Index # 7022 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7025 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7028 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7035 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7037 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7041 Target Class: 9 and Predicted Class: 10\n",
            "Index # 7042 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7045 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7058 Target Class: 9 and Predicted Class: 24\n",
            "Index # 7063 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7064 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7070 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7072 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7074 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7080 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7084 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7085 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7090 Target Class: 9 and Predicted Class: 5\n",
            "Index # 7092 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7094 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7109 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7113 Target Class: 9 and Predicted Class: 26\n",
            "Index # 7115 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7118 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7122 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7129 Target Class: 9 and Predicted Class: 3\n",
            "Index # 7131 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7133 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7134 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7135 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7143 Target Class: 9 and Predicted Class: 18\n",
            "Index # 7146 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7147 Target Class: 9 and Predicted Class: 10\n",
            "Index # 7155 Target Class: 9 and Predicted Class: 10\n",
            "Index # 7162 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7178 Target Class: 9 and Predicted Class: 12\n",
            "Index # 7191 Target Class: 9 and Predicted Class: 6\n",
            "Index # 7200 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7222 Target Class: 10 and Predicted Class: 7\n",
            "Index # 7247 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7251 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7272 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7300 Target Class: 10 and Predicted Class: 26\n",
            "Index # 7315 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7341 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7343 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7358 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7376 Target Class: 10 and Predicted Class: 19\n",
            "Index # 7382 Target Class: 10 and Predicted Class: 7\n",
            "Index # 7384 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7391 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7435 Target Class: 10 and Predicted Class: 7\n",
            "Index # 7458 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7467 Target Class: 10 and Predicted Class: 4\n",
            "Index # 7470 Target Class: 10 and Predicted Class: 20\n",
            "Index # 7476 Target Class: 10 and Predicted Class: 26\n",
            "Index # 7477 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7498 Target Class: 10 and Predicted Class: 22\n",
            "Index # 7560 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7570 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7573 Target Class: 10 and Predicted Class: 19\n",
            "Index # 7577 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7597 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7606 Target Class: 10 and Predicted Class: 20\n",
            "Index # 7619 Target Class: 10 and Predicted Class: 12\n",
            "Index # 7620 Target Class: 10 and Predicted Class: 21\n",
            "Index # 7622 Target Class: 10 and Predicted Class: 20\n",
            "Index # 7626 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7670 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7671 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7691 Target Class: 10 and Predicted Class: 6\n",
            "Index # 7695 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7712 Target Class: 10 and Predicted Class: 20\n",
            "Index # 7745 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7810 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7818 Target Class: 10 and Predicted Class: 22\n",
            "Index # 7829 Target Class: 10 and Predicted Class: 6\n",
            "Index # 7857 Target Class: 10 and Predicted Class: 17\n",
            "Index # 7882 Target Class: 10 and Predicted Class: 8\n",
            "Index # 7919 Target Class: 10 and Predicted Class: 20\n",
            "Index # 7950 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7957 Target Class: 10 and Predicted Class: 19\n",
            "Index # 7972 Target Class: 10 and Predicted Class: 9\n",
            "Index # 7993 Target Class: 10 and Predicted Class: 20\n",
            "Index # 8029 Target Class: 11 and Predicted Class: 18\n",
            "Index # 8074 Target Class: 11 and Predicted Class: 12\n",
            "Index # 8075 Target Class: 11 and Predicted Class: 24\n",
            "Index # 8109 Target Class: 11 and Predicted Class: 25\n",
            "Index # 8112 Target Class: 11 and Predicted Class: 8\n",
            "Index # 8152 Target Class: 11 and Predicted Class: 24\n",
            "Index # 8155 Target Class: 11 and Predicted Class: 12\n",
            "Index # 8158 Target Class: 11 and Predicted Class: 8\n",
            "Index # 8183 Target Class: 11 and Predicted Class: 5\n",
            "Index # 8184 Target Class: 11 and Predicted Class: 8\n",
            "Index # 8199 Target Class: 11 and Predicted Class: 24\n",
            "Index # 8312 Target Class: 11 and Predicted Class: 8\n",
            "Index # 8343 Target Class: 11 and Predicted Class: 24\n",
            "Index # 8349 Target Class: 11 and Predicted Class: 8\n",
            "Index # 8376 Target Class: 11 and Predicted Class: 13\n",
            "Index # 8381 Target Class: 11 and Predicted Class: 12\n",
            "Index # 8428 Target Class: 11 and Predicted Class: 8\n",
            "Index # 8446 Target Class: 11 and Predicted Class: 8\n",
            "Index # 8475 Target Class: 11 and Predicted Class: 12\n",
            "Index # 8488 Target Class: 11 and Predicted Class: 1\n",
            "Index # 8497 Target Class: 11 and Predicted Class: 2\n",
            "Index # 8517 Target Class: 11 and Predicted Class: 9\n",
            "Index # 8539 Target Class: 11 and Predicted Class: 8\n",
            "Index # 8550 Target Class: 11 and Predicted Class: 18\n",
            "Index # 8555 Target Class: 11 and Predicted Class: 24\n",
            "Index # 8576 Target Class: 11 and Predicted Class: 20\n",
            "Index # 8646 Target Class: 11 and Predicted Class: 18\n",
            "Index # 8666 Target Class: 11 and Predicted Class: 18\n",
            "Index # 8675 Target Class: 11 and Predicted Class: 8\n",
            "Index # 8684 Target Class: 11 and Predicted Class: 18\n",
            "Index # 8709 Target Class: 11 and Predicted Class: 5\n",
            "Index # 8724 Target Class: 11 and Predicted Class: 20\n",
            "Index # 8754 Target Class: 11 and Predicted Class: 24\n",
            "Index # 8791 Target Class: 11 and Predicted Class: 8\n",
            "Index # 8800 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8803 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8804 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8807 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8809 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8810 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8811 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8815 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8816 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8817 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8821 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8823 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8827 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8832 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8838 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8840 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8847 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8849 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8850 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8851 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8853 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8861 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8865 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8868 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8870 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8879 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8880 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8881 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8893 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8895 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8897 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8898 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8899 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8905 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8907 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8909 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8910 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8911 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8912 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8913 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8921 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8922 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8928 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8931 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8932 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8933 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8935 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8936 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8939 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8947 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8951 Target Class: 12 and Predicted Class: 15\n",
            "Index # 8954 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8958 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8962 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8965 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8966 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8967 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8972 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8974 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8978 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8980 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8982 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8983 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8985 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8989 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8991 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8994 Target Class: 12 and Predicted Class: 9\n",
            "Index # 8999 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9001 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9003 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9009 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9014 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9015 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9018 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9020 Target Class: 12 and Predicted Class: 3\n",
            "Index # 9025 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9027 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9032 Target Class: 12 and Predicted Class: 25\n",
            "Index # 9042 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9043 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9044 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9045 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9047 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9052 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9055 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9056 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9060 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9064 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9071 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9072 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9087 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9095 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9098 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9099 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9103 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9106 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9107 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9109 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9110 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9111 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9113 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9114 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9115 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9127 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9133 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9137 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9140 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9142 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9143 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9144 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9146 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9147 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9148 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9149 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9153 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9157 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9159 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9160 Target Class: 12 and Predicted Class: 10\n",
            "Index # 9165 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9166 Target Class: 12 and Predicted Class: 11\n",
            "Index # 9168 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9177 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9178 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9180 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9181 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9182 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9183 Target Class: 12 and Predicted Class: 3\n",
            "Index # 9186 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9193 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9195 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9196 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9200 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9201 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9204 Target Class: 12 and Predicted Class: 3\n",
            "Index # 9205 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9208 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9210 Target Class: 12 and Predicted Class: 3\n",
            "Index # 9216 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9217 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9220 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9221 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9222 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9237 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9240 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9244 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9250 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9251 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9252 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9257 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9259 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9260 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9266 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9268 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9272 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9273 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9280 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9288 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9292 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9295 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9296 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9297 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9305 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9308 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9315 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9316 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9321 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9322 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9325 Target Class: 12 and Predicted Class: 2\n",
            "Index # 9332 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9337 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9339 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9341 Target Class: 12 and Predicted Class: 18\n",
            "Index # 9342 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9354 Target Class: 12 and Predicted Class: 17\n",
            "Index # 9356 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9357 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9359 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9362 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9363 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9364 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9365 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9366 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9368 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9378 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9380 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9385 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9386 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9387 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9399 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9404 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9408 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9415 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9418 Target Class: 12 and Predicted Class: 3\n",
            "Index # 9421 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9423 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9429 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9430 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9431 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9440 Target Class: 12 and Predicted Class: 2\n",
            "Index # 9441 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9443 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9445 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9455 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9456 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9457 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9458 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9461 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9463 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9471 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9480 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9481 Target Class: 12 and Predicted Class: 8\n",
            "Index # 9482 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9485 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9486 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9487 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9488 Target Class: 12 and Predicted Class: 3\n",
            "Index # 9492 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9499 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9500 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9504 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9505 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9511 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9512 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9518 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9520 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9528 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9530 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9533 Target Class: 12 and Predicted Class: 8\n",
            "Index # 9536 Target Class: 12 and Predicted Class: 8\n",
            "Index # 9540 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9542 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9546 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9547 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9548 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9552 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9562 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9563 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9564 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9566 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9567 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9571 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9575 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9576 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9579 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9584 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9585 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9586 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9588 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9589 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9594 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9598 Target Class: 12 and Predicted Class: 9\n",
            "Index # 9898 Target Class: 13 and Predicted Class: 14\n",
            "Index # 9913 Target Class: 13 and Predicted Class: 8\n",
            "Index # 10043 Target Class: 13 and Predicted Class: 23\n",
            "Index # 10123 Target Class: 13 and Predicted Class: 14\n",
            "Index # 10162 Target Class: 13 and Predicted Class: 11\n",
            "Index # 10166 Target Class: 13 and Predicted Class: 14\n",
            "Index # 10377 Target Class: 13 and Predicted Class: 16\n",
            "Index # 10404 Target Class: 14 and Predicted Class: 13\n",
            "Index # 10451 Target Class: 14 and Predicted Class: 22\n",
            "Index # 10508 Target Class: 14 and Predicted Class: 8\n",
            "Index # 10531 Target Class: 14 and Predicted Class: 10\n",
            "Index # 10571 Target Class: 14 and Predicted Class: 22\n",
            "Index # 10602 Target Class: 14 and Predicted Class: 16\n",
            "Index # 10685 Target Class: 14 and Predicted Class: 18\n",
            "Index # 10688 Target Class: 14 and Predicted Class: 13\n",
            "Index # 10708 Target Class: 14 and Predicted Class: 4\n",
            "Index # 10721 Target Class: 14 and Predicted Class: 22\n",
            "Index # 10803 Target Class: 14 and Predicted Class: 13\n",
            "Index # 10826 Target Class: 14 and Predicted Class: 1\n",
            "Index # 10874 Target Class: 14 and Predicted Class: 13\n",
            "Index # 10893 Target Class: 14 and Predicted Class: 13\n",
            "Index # 10900 Target Class: 14 and Predicted Class: 13\n",
            "Index # 10923 Target Class: 14 and Predicted Class: 13\n",
            "Index # 10930 Target Class: 14 and Predicted Class: 23\n",
            "Index # 10934 Target Class: 14 and Predicted Class: 8\n",
            "Index # 10969 Target Class: 14 and Predicted Class: 8\n",
            "Index # 11001 Target Class: 14 and Predicted Class: 10\n",
            "Index # 11007 Target Class: 14 and Predicted Class: 24\n",
            "Index # 11042 Target Class: 14 and Predicted Class: 11\n",
            "Index # 11051 Target Class: 14 and Predicted Class: 8\n",
            "Index # 11053 Target Class: 14 and Predicted Class: 18\n",
            "Index # 11090 Target Class: 14 and Predicted Class: 24\n",
            "Index # 11092 Target Class: 14 and Predicted Class: 11\n",
            "Index # 11110 Target Class: 14 and Predicted Class: 10\n",
            "Index # 11112 Target Class: 14 and Predicted Class: 18\n",
            "Index # 11152 Target Class: 14 and Predicted Class: 13\n",
            "Index # 11178 Target Class: 14 and Predicted Class: 1\n",
            "Index # 11205 Target Class: 15 and Predicted Class: 7\n",
            "Index # 11213 Target Class: 15 and Predicted Class: 21\n",
            "Index # 11237 Target Class: 15 and Predicted Class: 3\n",
            "Index # 11247 Target Class: 15 and Predicted Class: 21\n",
            "Index # 11273 Target Class: 15 and Predicted Class: 1\n",
            "Index # 11324 Target Class: 15 and Predicted Class: 3\n",
            "Index # 11373 Target Class: 15 and Predicted Class: 4\n",
            "Index # 11417 Target Class: 15 and Predicted Class: 14\n",
            "Index # 11583 Target Class: 15 and Predicted Class: 1\n",
            "Index # 11646 Target Class: 15 and Predicted Class: 21\n",
            "Index # 11662 Target Class: 15 and Predicted Class: 4\n",
            "Index # 11697 Target Class: 15 and Predicted Class: 4\n",
            "Index # 11712 Target Class: 15 and Predicted Class: 17\n",
            "Index # 11772 Target Class: 15 and Predicted Class: 4\n",
            "Index # 11777 Target Class: 15 and Predicted Class: 3\n",
            "Index # 11791 Target Class: 15 and Predicted Class: 2\n",
            "Index # 11792 Target Class: 15 and Predicted Class: 4\n",
            "Index # 11863 Target Class: 15 and Predicted Class: 14\n",
            "Index # 11878 Target Class: 15 and Predicted Class: 21\n",
            "Index # 11946 Target Class: 15 and Predicted Class: 1\n",
            "Index # 12022 Target Class: 16 and Predicted Class: 17\n",
            "Index # 12088 Target Class: 16 and Predicted Class: 18\n",
            "Index # 12179 Target Class: 16 and Predicted Class: 18\n",
            "Index # 12184 Target Class: 16 and Predicted Class: 4\n",
            "Index # 12229 Target Class: 16 and Predicted Class: 18\n",
            "Index # 12430 Target Class: 16 and Predicted Class: 12\n",
            "Index # 12463 Target Class: 16 and Predicted Class: 4\n",
            "Index # 12465 Target Class: 16 and Predicted Class: 4\n",
            "Index # 12478 Target Class: 16 and Predicted Class: 4\n",
            "Index # 12492 Target Class: 16 and Predicted Class: 5\n",
            "Index # 12517 Target Class: 16 and Predicted Class: 17\n",
            "Index # 12552 Target Class: 16 and Predicted Class: 17\n",
            "Index # 12568 Target Class: 16 and Predicted Class: 18\n",
            "Index # 12612 Target Class: 16 and Predicted Class: 12\n",
            "Index # 12614 Target Class: 16 and Predicted Class: 4\n",
            "Index # 12668 Target Class: 16 and Predicted Class: 2\n",
            "Index # 12715 Target Class: 16 and Predicted Class: 2\n",
            "Index # 12727 Target Class: 16 and Predicted Class: 7\n",
            "Index # 12762 Target Class: 16 and Predicted Class: 14\n",
            "Index # 12802 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12808 Target Class: 17 and Predicted Class: 1\n",
            "Index # 12811 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12812 Target Class: 17 and Predicted Class: 1\n",
            "Index # 12820 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12822 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12827 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12829 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12835 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12836 Target Class: 17 and Predicted Class: 5\n",
            "Index # 12839 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12843 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12844 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12860 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12862 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12864 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12869 Target Class: 17 and Predicted Class: 1\n",
            "Index # 12870 Target Class: 17 and Predicted Class: 26\n",
            "Index # 12874 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12875 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12877 Target Class: 17 and Predicted Class: 18\n",
            "Index # 12882 Target Class: 17 and Predicted Class: 1\n",
            "Index # 12889 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12904 Target Class: 17 and Predicted Class: 1\n",
            "Index # 12907 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12920 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12941 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12947 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12950 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12951 Target Class: 17 and Predicted Class: 1\n",
            "Index # 12956 Target Class: 17 and Predicted Class: 5\n",
            "Index # 12959 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12967 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12972 Target Class: 17 and Predicted Class: 1\n",
            "Index # 12977 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12980 Target Class: 17 and Predicted Class: 15\n",
            "Index # 12982 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12989 Target Class: 17 and Predicted Class: 1\n",
            "Index # 12991 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12994 Target Class: 17 and Predicted Class: 7\n",
            "Index # 12999 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13016 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13017 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13025 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13029 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13040 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13048 Target Class: 17 and Predicted Class: 2\n",
            "Index # 13049 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13050 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13061 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13071 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13073 Target Class: 17 and Predicted Class: 25\n",
            "Index # 13080 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13081 Target Class: 17 and Predicted Class: 15\n",
            "Index # 13087 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13091 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13093 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13111 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13114 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13116 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13117 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13119 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13128 Target Class: 17 and Predicted Class: 5\n",
            "Index # 13131 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13141 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13160 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13205 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13222 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13237 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13241 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13250 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13254 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13261 Target Class: 17 and Predicted Class: 21\n",
            "Index # 13263 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13266 Target Class: 17 and Predicted Class: 15\n",
            "Index # 13267 Target Class: 17 and Predicted Class: 9\n",
            "Index # 13273 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13277 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13278 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13281 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13284 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13286 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13290 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13319 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13320 Target Class: 17 and Predicted Class: 25\n",
            "Index # 13321 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13322 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13325 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13327 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13330 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13338 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13339 Target Class: 17 and Predicted Class: 14\n",
            "Index # 13359 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13362 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13369 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13372 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13413 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13439 Target Class: 17 and Predicted Class: 15\n",
            "Index # 13440 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13456 Target Class: 17 and Predicted Class: 2\n",
            "Index # 13465 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13467 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13473 Target Class: 17 and Predicted Class: 6\n",
            "Index # 13477 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13486 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13505 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13509 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13511 Target Class: 17 and Predicted Class: 12\n",
            "Index # 13513 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13518 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13531 Target Class: 17 and Predicted Class: 1\n",
            "Index # 13533 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13537 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13542 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13547 Target Class: 17 and Predicted Class: 2\n",
            "Index # 13552 Target Class: 17 and Predicted Class: 18\n",
            "Index # 13567 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13583 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13584 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13597 Target Class: 17 and Predicted Class: 7\n",
            "Index # 13606 Target Class: 18 and Predicted Class: 14\n",
            "Index # 13612 Target Class: 18 and Predicted Class: 26\n",
            "Index # 13613 Target Class: 18 and Predicted Class: 3\n",
            "Index # 13766 Target Class: 18 and Predicted Class: 1\n",
            "Index # 13769 Target Class: 18 and Predicted Class: 11\n",
            "Index # 13771 Target Class: 18 and Predicted Class: 9\n",
            "Index # 13786 Target Class: 18 and Predicted Class: 5\n",
            "Index # 13803 Target Class: 18 and Predicted Class: 2\n",
            "Index # 13845 Target Class: 18 and Predicted Class: 22\n",
            "Index # 13847 Target Class: 18 and Predicted Class: 14\n",
            "Index # 13864 Target Class: 18 and Predicted Class: 20\n",
            "Index # 13880 Target Class: 18 and Predicted Class: 22\n",
            "Index # 13887 Target Class: 18 and Predicted Class: 22\n",
            "Index # 13947 Target Class: 18 and Predicted Class: 17\n",
            "Index # 13970 Target Class: 18 and Predicted Class: 16\n",
            "Index # 13972 Target Class: 18 and Predicted Class: 26\n",
            "Index # 14014 Target Class: 18 and Predicted Class: 5\n",
            "Index # 14048 Target Class: 18 and Predicted Class: 1\n",
            "Index # 14077 Target Class: 18 and Predicted Class: 24\n",
            "Index # 14099 Target Class: 18 and Predicted Class: 8\n",
            "Index # 14114 Target Class: 18 and Predicted Class: 9\n",
            "Index # 14151 Target Class: 18 and Predicted Class: 9\n",
            "Index # 14163 Target Class: 18 and Predicted Class: 16\n",
            "Index # 14196 Target Class: 18 and Predicted Class: 1\n",
            "Index # 14202 Target Class: 18 and Predicted Class: 22\n",
            "Index # 14218 Target Class: 18 and Predicted Class: 2\n",
            "Index # 14222 Target Class: 18 and Predicted Class: 22\n",
            "Index # 14229 Target Class: 18 and Predicted Class: 11\n",
            "Index # 14235 Target Class: 18 and Predicted Class: 22\n",
            "Index # 14236 Target Class: 18 and Predicted Class: 11\n",
            "Index # 14237 Target Class: 18 and Predicted Class: 1\n",
            "Index # 14271 Target Class: 18 and Predicted Class: 22\n",
            "Index # 14274 Target Class: 18 and Predicted Class: 22\n",
            "Index # 14278 Target Class: 18 and Predicted Class: 16\n",
            "Index # 14299 Target Class: 18 and Predicted Class: 25\n",
            "Index # 14315 Target Class: 18 and Predicted Class: 9\n",
            "Index # 14368 Target Class: 18 and Predicted Class: 3\n",
            "Index # 14371 Target Class: 18 and Predicted Class: 12\n",
            "Index # 14385 Target Class: 18 and Predicted Class: 16\n",
            "Index # 14397 Target Class: 18 and Predicted Class: 24\n",
            "Index # 14468 Target Class: 19 and Predicted Class: 1\n",
            "Index # 14595 Target Class: 19 and Predicted Class: 10\n",
            "Index # 14606 Target Class: 19 and Predicted Class: 10\n",
            "Index # 14622 Target Class: 19 and Predicted Class: 7\n",
            "Index # 14665 Target Class: 19 and Predicted Class: 10\n",
            "Index # 14690 Target Class: 19 and Predicted Class: 7\n",
            "Index # 14727 Target Class: 19 and Predicted Class: 7\n",
            "Index # 14733 Target Class: 19 and Predicted Class: 7\n",
            "Index # 14780 Target Class: 19 and Predicted Class: 7\n",
            "Index # 14793 Target Class: 19 and Predicted Class: 8\n",
            "Index # 14836 Target Class: 19 and Predicted Class: 10\n",
            "Index # 14848 Target Class: 19 and Predicted Class: 10\n",
            "Index # 14877 Target Class: 19 and Predicted Class: 10\n",
            "Index # 14888 Target Class: 19 and Predicted Class: 10\n",
            "Index # 14931 Target Class: 19 and Predicted Class: 5\n",
            "Index # 14998 Target Class: 19 and Predicted Class: 7\n",
            "Index # 15056 Target Class: 19 and Predicted Class: 1\n",
            "Index # 15068 Target Class: 19 and Predicted Class: 7\n",
            "Index # 15133 Target Class: 19 and Predicted Class: 1\n",
            "Index # 15188 Target Class: 19 and Predicted Class: 14\n",
            "Index # 15209 Target Class: 20 and Predicted Class: 4\n",
            "Index # 15212 Target Class: 20 and Predicted Class: 11\n",
            "Index # 15228 Target Class: 20 and Predicted Class: 11\n",
            "Index # 15302 Target Class: 20 and Predicted Class: 12\n",
            "Index # 15334 Target Class: 20 and Predicted Class: 24\n",
            "Index # 15337 Target Class: 20 and Predicted Class: 24\n",
            "Index # 15340 Target Class: 20 and Predicted Class: 11\n",
            "Index # 15341 Target Class: 20 and Predicted Class: 1\n",
            "Index # 15350 Target Class: 20 and Predicted Class: 10\n",
            "Index # 15377 Target Class: 20 and Predicted Class: 15\n",
            "Index # 15415 Target Class: 20 and Predicted Class: 6\n",
            "Index # 15425 Target Class: 20 and Predicted Class: 5\n",
            "Index # 15437 Target Class: 20 and Predicted Class: 10\n",
            "Index # 15446 Target Class: 20 and Predicted Class: 5\n",
            "Index # 15481 Target Class: 20 and Predicted Class: 11\n",
            "Index # 15543 Target Class: 20 and Predicted Class: 18\n",
            "Index # 15547 Target Class: 20 and Predicted Class: 18\n",
            "Index # 15564 Target Class: 20 and Predicted Class: 9\n",
            "Index # 15579 Target Class: 20 and Predicted Class: 9\n",
            "Index # 15585 Target Class: 20 and Predicted Class: 14\n",
            "Index # 15704 Target Class: 20 and Predicted Class: 5\n",
            "Index # 15742 Target Class: 20 and Predicted Class: 7\n",
            "Index # 15779 Target Class: 20 and Predicted Class: 25\n",
            "Index # 15800 Target Class: 20 and Predicted Class: 8\n",
            "Index # 15823 Target Class: 20 and Predicted Class: 18\n",
            "Index # 15898 Target Class: 20 and Predicted Class: 2\n",
            "Index # 15910 Target Class: 20 and Predicted Class: 24\n",
            "Index # 15938 Target Class: 20 and Predicted Class: 26\n",
            "Index # 15986 Target Class: 20 and Predicted Class: 2\n",
            "Index # 15999 Target Class: 20 and Predicted Class: 5\n",
            "Index # 16016 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16030 Target Class: 21 and Predicted Class: 25\n",
            "Index # 16034 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16059 Target Class: 21 and Predicted Class: 11\n",
            "Index # 16068 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16073 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16083 Target Class: 21 and Predicted Class: 14\n",
            "Index # 16086 Target Class: 21 and Predicted Class: 25\n",
            "Index # 16091 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16112 Target Class: 21 and Predicted Class: 8\n",
            "Index # 16141 Target Class: 21 and Predicted Class: 23\n",
            "Index # 16149 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16150 Target Class: 21 and Predicted Class: 12\n",
            "Index # 16164 Target Class: 21 and Predicted Class: 13\n",
            "Index # 16171 Target Class: 21 and Predicted Class: 14\n",
            "Index # 16201 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16215 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16229 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16232 Target Class: 21 and Predicted Class: 25\n",
            "Index # 16234 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16235 Target Class: 21 and Predicted Class: 8\n",
            "Index # 16260 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16273 Target Class: 21 and Predicted Class: 3\n",
            "Index # 16281 Target Class: 21 and Predicted Class: 23\n",
            "Index # 16314 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16325 Target Class: 21 and Predicted Class: 14\n",
            "Index # 16329 Target Class: 21 and Predicted Class: 8\n",
            "Index # 16337 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16344 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16345 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16352 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16365 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16387 Target Class: 21 and Predicted Class: 19\n",
            "Index # 16393 Target Class: 21 and Predicted Class: 4\n",
            "Index # 16398 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16406 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16411 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16413 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16428 Target Class: 21 and Predicted Class: 23\n",
            "Index # 16432 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16439 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16452 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16454 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16462 Target Class: 21 and Predicted Class: 1\n",
            "Index # 16474 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16525 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16532 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16553 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16559 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16574 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16575 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16579 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16582 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16598 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16600 Target Class: 21 and Predicted Class: 15\n",
            "Index # 16602 Target Class: 21 and Predicted Class: 8\n",
            "Index # 16617 Target Class: 21 and Predicted Class: 4\n",
            "Index # 16633 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16642 Target Class: 21 and Predicted Class: 1\n",
            "Index # 16668 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16671 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16673 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16697 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16699 Target Class: 21 and Predicted Class: 10\n",
            "Index # 16733 Target Class: 21 and Predicted Class: 23\n",
            "Index # 16734 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16754 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16757 Target Class: 21 and Predicted Class: 25\n",
            "Index # 16766 Target Class: 21 and Predicted Class: 25\n",
            "Index # 16792 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16796 Target Class: 21 and Predicted Class: 22\n",
            "Index # 16800 Target Class: 22 and Predicted Class: 21\n",
            "Index # 16824 Target Class: 22 and Predicted Class: 18\n",
            "Index # 16885 Target Class: 22 and Predicted Class: 10\n",
            "Index # 16903 Target Class: 22 and Predicted Class: 18\n",
            "Index # 16930 Target Class: 22 and Predicted Class: 21\n",
            "Index # 16995 Target Class: 22 and Predicted Class: 14\n",
            "Index # 16998 Target Class: 22 and Predicted Class: 9\n",
            "Index # 17029 Target Class: 22 and Predicted Class: 21\n",
            "Index # 17077 Target Class: 22 and Predicted Class: 18\n",
            "Index # 17164 Target Class: 22 and Predicted Class: 21\n",
            "Index # 17166 Target Class: 22 and Predicted Class: 21\n",
            "Index # 17213 Target Class: 22 and Predicted Class: 21\n",
            "Index # 17227 Target Class: 22 and Predicted Class: 18\n",
            "Index # 17240 Target Class: 22 and Predicted Class: 21\n",
            "Index # 17252 Target Class: 22 and Predicted Class: 21\n",
            "Index # 17253 Target Class: 22 and Predicted Class: 25\n",
            "Index # 17265 Target Class: 22 and Predicted Class: 20\n",
            "Index # 17273 Target Class: 22 and Predicted Class: 21\n",
            "Index # 17284 Target Class: 22 and Predicted Class: 4\n",
            "Index # 17293 Target Class: 22 and Predicted Class: 25\n",
            "Index # 17317 Target Class: 22 and Predicted Class: 18\n",
            "Index # 17333 Target Class: 22 and Predicted Class: 26\n",
            "Index # 17381 Target Class: 22 and Predicted Class: 21\n",
            "Index # 17393 Target Class: 22 and Predicted Class: 24\n",
            "Index # 17402 Target Class: 22 and Predicted Class: 25\n",
            "Index # 17411 Target Class: 22 and Predicted Class: 18\n",
            "Index # 17459 Target Class: 22 and Predicted Class: 18\n",
            "Index # 17523 Target Class: 22 and Predicted Class: 25\n",
            "Index # 17537 Target Class: 22 and Predicted Class: 14\n",
            "Index # 17552 Target Class: 22 and Predicted Class: 21\n",
            "Index # 17569 Target Class: 22 and Predicted Class: 21\n",
            "Index # 17640 Target Class: 23 and Predicted Class: 8\n",
            "Index # 17652 Target Class: 23 and Predicted Class: 22\n",
            "Index # 17663 Target Class: 23 and Predicted Class: 14\n",
            "Index # 17689 Target Class: 23 and Predicted Class: 21\n",
            "Index # 17702 Target Class: 23 and Predicted Class: 14\n",
            "Index # 17764 Target Class: 23 and Predicted Class: 14\n",
            "Index # 17776 Target Class: 23 and Predicted Class: 13\n",
            "Index # 17802 Target Class: 23 and Predicted Class: 14\n",
            "Index # 17839 Target Class: 23 and Predicted Class: 21\n",
            "Index # 17912 Target Class: 23 and Predicted Class: 10\n",
            "Index # 17974 Target Class: 23 and Predicted Class: 9\n",
            "Index # 18010 Target Class: 23 and Predicted Class: 22\n",
            "Index # 18072 Target Class: 23 and Predicted Class: 13\n",
            "Index # 18133 Target Class: 23 and Predicted Class: 8\n",
            "Index # 18200 Target Class: 23 and Predicted Class: 14\n",
            "Index # 18210 Target Class: 23 and Predicted Class: 14\n",
            "Index # 18215 Target Class: 23 and Predicted Class: 14\n",
            "Index # 18374 Target Class: 23 and Predicted Class: 14\n",
            "Index # 18407 Target Class: 24 and Predicted Class: 22\n",
            "Index # 18471 Target Class: 24 and Predicted Class: 13\n",
            "Index # 18480 Target Class: 24 and Predicted Class: 25\n",
            "Index # 18497 Target Class: 24 and Predicted Class: 11\n",
            "Index # 18537 Target Class: 24 and Predicted Class: 18\n",
            "Index # 18549 Target Class: 24 and Predicted Class: 18\n",
            "Index # 18569 Target Class: 24 and Predicted Class: 6\n",
            "Index # 18582 Target Class: 24 and Predicted Class: 11\n",
            "Index # 18595 Target Class: 24 and Predicted Class: 26\n",
            "Index # 18612 Target Class: 24 and Predicted Class: 25\n",
            "Index # 18685 Target Class: 24 and Predicted Class: 25\n",
            "Index # 18728 Target Class: 24 and Predicted Class: 8\n",
            "Index # 18772 Target Class: 24 and Predicted Class: 21\n",
            "Index # 18815 Target Class: 24 and Predicted Class: 25\n",
            "Index # 18848 Target Class: 24 and Predicted Class: 11\n",
            "Index # 18866 Target Class: 24 and Predicted Class: 25\n",
            "Index # 18886 Target Class: 24 and Predicted Class: 11\n",
            "Index # 18918 Target Class: 24 and Predicted Class: 8\n",
            "Index # 18964 Target Class: 24 and Predicted Class: 11\n",
            "Index # 18977 Target Class: 24 and Predicted Class: 10\n",
            "Index # 18989 Target Class: 24 and Predicted Class: 14\n",
            "Index # 19018 Target Class: 24 and Predicted Class: 11\n",
            "Index # 19085 Target Class: 24 and Predicted Class: 13\n",
            "Index # 19115 Target Class: 24 and Predicted Class: 25\n",
            "Index # 19147 Target Class: 24 and Predicted Class: 11\n",
            "Index # 19176 Target Class: 24 and Predicted Class: 20\n",
            "Index # 19192 Target Class: 24 and Predicted Class: 11\n",
            "Index # 19207 Target Class: 25 and Predicted Class: 22\n",
            "Index # 19232 Target Class: 25 and Predicted Class: 17\n",
            "Index # 19246 Target Class: 25 and Predicted Class: 18\n",
            "Index # 19294 Target Class: 25 and Predicted Class: 22\n",
            "Index # 19309 Target Class: 25 and Predicted Class: 24\n",
            "Index # 19321 Target Class: 25 and Predicted Class: 17\n",
            "Index # 19322 Target Class: 25 and Predicted Class: 20\n",
            "Index # 19325 Target Class: 25 and Predicted Class: 18\n",
            "Index # 19340 Target Class: 25 and Predicted Class: 22\n",
            "Index # 19352 Target Class: 25 and Predicted Class: 24\n",
            "Index # 19369 Target Class: 25 and Predicted Class: 22\n",
            "Index # 19396 Target Class: 25 and Predicted Class: 24\n",
            "Index # 19419 Target Class: 25 and Predicted Class: 22\n",
            "Index # 19450 Target Class: 25 and Predicted Class: 18\n",
            "Index # 19460 Target Class: 25 and Predicted Class: 22\n",
            "Index # 19472 Target Class: 25 and Predicted Class: 7\n",
            "Index # 19497 Target Class: 25 and Predicted Class: 10\n",
            "Index # 19509 Target Class: 25 and Predicted Class: 22\n",
            "Index # 19518 Target Class: 25 and Predicted Class: 24\n",
            "Index # 19532 Target Class: 25 and Predicted Class: 24\n",
            "Index # 19539 Target Class: 25 and Predicted Class: 24\n",
            "Index # 19561 Target Class: 25 and Predicted Class: 7\n",
            "Index # 19601 Target Class: 25 and Predicted Class: 7\n",
            "Index # 19605 Target Class: 25 and Predicted Class: 16\n",
            "Index # 19664 Target Class: 25 and Predicted Class: 24\n",
            "Index # 19682 Target Class: 25 and Predicted Class: 20\n",
            "Index # 19684 Target Class: 25 and Predicted Class: 4\n",
            "Index # 19695 Target Class: 25 and Predicted Class: 22\n",
            "Index # 19766 Target Class: 25 and Predicted Class: 22\n",
            "Index # 19787 Target Class: 25 and Predicted Class: 24\n",
            "Index # 19794 Target Class: 25 and Predicted Class: 7\n",
            "Index # 19811 Target Class: 25 and Predicted Class: 18\n",
            "Index # 19822 Target Class: 25 and Predicted Class: 18\n",
            "Index # 19834 Target Class: 25 and Predicted Class: 7\n",
            "Index # 19898 Target Class: 25 and Predicted Class: 24\n",
            "Index # 19940 Target Class: 25 and Predicted Class: 20\n",
            "Index # 19947 Target Class: 25 and Predicted Class: 22\n",
            "Index # 19954 Target Class: 25 and Predicted Class: 21\n",
            "Index # 19955 Target Class: 25 and Predicted Class: 24\n",
            "Index # 19976 Target Class: 25 and Predicted Class: 17\n",
            "Index # 20192 Target Class: 26 and Predicted Class: 20\n",
            "Index # 20216 Target Class: 26 and Predicted Class: 7\n",
            "Index # 20303 Target Class: 26 and Predicted Class: 12\n",
            "Index # 20327 Target Class: 26 and Predicted Class: 12\n",
            "Index # 20364 Target Class: 26 and Predicted Class: 7\n",
            "Index # 20374 Target Class: 26 and Predicted Class: 5\n",
            "Index # 20484 Target Class: 26 and Predicted Class: 9\n",
            "Index # 20528 Target Class: 26 and Predicted Class: 7\n",
            "Index # 20716 Target Class: 26 and Predicted Class: 24\n",
            "Index # 20732 Target Class: 26 and Predicted Class: 9\n",
            "Index # 20740 Target Class: 26 and Predicted Class: 5\n",
            "Mispredictions: 1367\n"
          ]
        }
      ],
      "source": [
        "count = 0 \n",
        "classDict = dict.fromkeys([1,2,3,4,5,6,7,8,9,10,11,12,13,\n",
        "                           14,15,16,17,18,19,20,21,22,23,24,25,26], 0)\n",
        "\n",
        "print()\n",
        "print(\"Misclassified test images\")\n",
        "for i in range(0, len(test_images)):\n",
        "  if answers_array[i] != prediction_array[i]:\n",
        "    count += 1\n",
        "    for key in classDict.keys():\n",
        "      if(key == answers_array[i]):\n",
        "        classDict[key] += 1\n",
        "    print(\"Index #\", i,\"Target Class:\", answers_array[i], \"and Predicted Class:\", prediction_array[i])\n",
        "print(\"Mispredictions:\", count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFwsSwXSJLKm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e9e5a41e-2219-4c51-d699-8656c709cc21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff64f6a0d90>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "testLetter = test_images[44].reshape(28,28)\n",
        "plt.imshow(testLetter, cmap='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwHitafKSffz"
      },
      "source": [
        "* As shown below, the above image was predicted as \"u\", when it actually was \"a\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwsXINFlJMo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2cf74f2-99ca-4757-d6db-af1aef007885"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "answers_array[44]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYHY6dvlJNuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ce16da-384f-4129-e635-4739d145a7f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "prediction_array[44]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QICGOnoTJsyZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ba3e78c9-1d9a-43dc-980b-33d5f168c7a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff64f621090>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "testLetter2 = test_images[9500].reshape(28,28)\n",
        "plt.imshow(testLetter2, cmap='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSVKUBpTSuAr"
      },
      "source": [
        "* As shown below, the above image was predicted as \"i\", when it actually was \"l\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kddnw26YJtPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "886a6a41-f1a0-42dc-8223-044c256b04a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "answers_array[9500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh6NBK_gJtdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f19753b-5a40-4b44-a812-52d3e26fb806"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "prediction_array[9500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOrrSEwh_c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a2434019-c897-43f7-b8ed-284b900aa48f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff64f57c190>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "testLetter3 = test_images[5143].reshape(28,28)\n",
        "plt.imshow(testLetter3, cmap='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOol0s5w_tlz"
      },
      "source": [
        "* As shown below, the above image was predicted to be \"q\", when it actually was \"g\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpV-ucoU_bY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93ac3f5a-f0fa-4842-cc7f-93d033bf0208"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "answers_array[5143]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzijqJoq_b9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95254cdf-8310-414a-ec7e-d6a202139979"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "prediction_array[5143]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08vPNvfDS0jN"
      },
      "source": [
        "* The following is a dictionary that contains how many times each class of letters was misclassified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VsTs7B1M-lJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84cba91e-3382-4a66-afda-462278f4067d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 43,\n",
              " 2: 31,\n",
              " 3: 21,\n",
              " 4: 58,\n",
              " 5: 27,\n",
              " 6: 43,\n",
              " 7: 143,\n",
              " 8: 46,\n",
              " 9: 139,\n",
              " 10: 47,\n",
              " 11: 34,\n",
              " 12: 251,\n",
              " 13: 7,\n",
              " 14: 30,\n",
              " 15: 20,\n",
              " 16: 19,\n",
              " 17: 120,\n",
              " 18: 40,\n",
              " 19: 20,\n",
              " 20: 30,\n",
              " 21: 71,\n",
              " 22: 31,\n",
              " 23: 18,\n",
              " 24: 27,\n",
              " 25: 40,\n",
              " 26: 11}"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "classDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9dc2ev7SAwA"
      },
      "source": [
        "**13b. Describe what you think might have gone wrong:**\n",
        "> * There were handwritten letters that closely resembled other letters in the alphabet, resulting in around 1367 total mispredictions from one run of our experiment. \"G/g\" and \"Q/q\", \"I/i\" and \"L/l\" were the ones with the most mispredictions"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Project 2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}